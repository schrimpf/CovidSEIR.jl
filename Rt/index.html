<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Reproductive number - CovidSEIR.jl</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">CovidSEIR.jl</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Package Docs</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">SEIR Model and Results <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../covid/" class="dropdown-item">Model</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Results</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../canada/" class="dropdown-item">Canada</a>
</li>
            
<li>
    <a href="../italy/" class="dropdown-item">Italy</a>
</li>
            
<li>
    <a href="../korea/" class="dropdown-item">South Korea</a>
</li>
            
<li>
    <a href="../china/" class="dropdown-item">China</a>
</li>
            
<li>
    <a href="../us/" class="dropdown-item">United States</a>
</li>
    </ul>
  </li>
                                    
<li>
    <a href="../state/" class="dropdown-item">US States</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">Reproductive number</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../license/" class="dropdown-item">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../state/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../license/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/schrimpf/CovidSEIR.jl/edit/master/docs/Rt.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#model" class="nav-link">Model</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#data" class="nav-link">Data</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#statistical-model" class="nav-link">Statistical Model</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#systroms-approach" class="nav-link">Systrom’s approach</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#an-alternative-approach" class="nav-link">An alternative approach</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#state-space-model" class="nav-link">State space model</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h1 id="model">Model<a class="headerlink" href="#model" title="Permanent link">&para;</a></h1>
<p>Following <a href="http://systrom.com/blog/the-metric-we-need-to-manage-covid-19/">Kevin
Systrom</a>,
we adapt the approach of (Bettencourt <a href="#ref-bettencourt2008">2008</a>) to
compute real-time rolling estimates of pandemic parameters. (Bettencourt
<a href="#ref-bettencourt2008">2008</a>) begin from a SIR model,</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
\dot{S} & = -\frac{S}{N} \beta I \\
\dot{I} & = \frac{S}{N} \beta I - \gamma I \\
\dot{R} & = \gamma I
\end{align*}
</script>
</p>
<p>To this we add the possibility that not all cases are known. Cases get
get detected at rate $I$, so cumulative confirmed cases, $C$, evolves as</p>
<p>
<script type="math/tex; mode=display">
\dot{C} = \tau I
</script>
</p>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Should we add other states to this model? If yes, how? I think
using death and hospitalization numbers in estimation makes sense.</p>
</div>
<p>The number of new confirmed cases from time $t$ to $t+\delta$ is then:</p>
<p>We will allow for the testing rate, $\tau$, and infection rate, $\beta$,
to vary over time.</p>
<p>
<script type="math/tex; mode=display">
k_t \equiv \frac{C(t+\delta) - C(t)}{\delta} = \int_t^{t+\delta} \tau(s) I(s) ds
\approx \tau(t) I(t)
</script>
</p>
<p>As in (Bettencourt <a href="#ref-bettencourt2008">2008</a>),</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
I(t) = & I(t-\delta) \int_{t-\delta}^{t} e^{\frac{S(s)}{N} \beta(s) -
\gamma} ds \\
\approx & I(t-\delta) e^{\delta \left( \frac{S(t-\delta)}{N}
\beta(t-\delta) - \gamma \right)}
\end{align*}
</script>
</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The reproductive number is:
$R_t \equiv \frac{S(t)}{N}\frac{\beta(t)}{\gamma}$.</p>
</div>
<p>Substituting the expression for $I_t$ into $k_t$, we have</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
k_t \approx & \tau(t) I(t-\delta) e^{\delta \left(
\frac{S(t-\delta)}{N} \beta(t-\delta) - \gamma\right)} \\
\approx & k_{t-\delta} \frac{\tau(t)}{\tau(t-\delta)}
e^{\delta \left(\frac{S(t-\delta)}{N} \beta(t-\delta) - \gamma \right)}
\end{align*}
</script>
</p>
<h1 id="data">Data<a class="headerlink" href="#data" title="Permanent link">&para;</a></h1>
<p>We use the same data as the <a href="../state/">US state model</a>.</p>
<p>The data combines information on</p>
<ul>
<li>Daily case counts and deaths from JHU CSSE</li>
<li>Daily Hospitalizations, recoveries, and testing from the Covid
    Tracking Project</li>
<li>Covid related policy changes from Raifman et al</li>
<li>Movements from Google Mobility Reports</li>
<li>Hourly workers from Hoembase</li>
</ul>
<h1 id="statistical-model">Statistical Model<a class="headerlink" href="#statistical-model" title="Permanent link">&para;</a></h1>
<p>The above theoretical model gives a deterministic relationship between
$k_t$ and $k_{t-1}$ given the parameters. To bring it to data we must
add stochasticity.</p>
<h2 id="systroms-approach">Systrom’s approach<a class="headerlink" href="#systroms-approach" title="Permanent link">&para;</a></h2>
<p>First we describe what Systrom does. He assumes that
$R_{0} \sim Gamma(4,1)$. Then for $t=1, &hellip;, T$, he computes
$P(R_t|k_{t}, k_{t-1}, &hellip; ,k_0)$ iteratively using Bayes’ rules.
Specifically, he assumes <script type="math/tex; mode=display">
k_t | R_t, k_{t-1}, ... \sim Poisson(k_{t-1} e^{\gamma(R_t - 1)})
</script> and that $R_t$ follows a random walk, so the prior of $R_t | R_{t-1}$
is <script type="math/tex; mode=display">
R_t | R_{t-1} \sim N(R_{t-1}, \sigma^2)
</script>
</p>
<p>so that</p>
<p>
<script type="math/tex; mode=display">
P(R_t|k_{t}, k_{t-1}, ... ,k_0) = \frac{P(k_t | R_t, k_{t-1}) P(R_t |
R_{t-1}) P(R_{t-1} | k_{t-1}, ...)} {P(k_t)}
</script>
</p>
<p>Note that this computes posteriors of $R_t$ given current and past
cases. Future cases are also informative of $R_t$, and you could instead
compute $P(R_t | k_0, k_1, &hellip;, k_T)$.</p>
<p>The notebook makes some mentions of Gaussian processes. There’s likely
some way to recast the random walk assumption as a Gaussian process
prior (the kernel would be $\kappa(t,t&rsquo;) = \min{t,t&rsquo;} \sigma^2$), but
that seems to me like an unusual way to describe it.</p>
<h3 id="code">Code<a class="headerlink" href="#code" title="Permanent link">&para;</a></h3>
<p>Let’s see how Systrom’s method works.</p>
<p>First the load data.</p>
<pre><code class="julia">using DataFrames, Plots, StatsPlots, CovidSEIR
Plots.pyplot()

df = CovidSEIR.statedata()
df = filter(x-&gt;x.fips&lt;60, df)
# focus on 10 states with most cases as of April 1, 2020
sdf = select(df[df[!,:date].==Dates.Date(&quot;2020-04-01&quot;),:], :cases, :state) |&gt;
    x-&gt;sort(x,:cases, rev=true)
states=sdf[1:10,:state]
sdf = select(filter(r-&gt;r[:state] ∈ states, df), :cases, :state, :date)
sdf = sort(sdf, [:state, :date])
sdf[!,:newcases] = by(sdf, :state, newcases = :cases =&gt; x-&gt;(vcat(missing, diff(x))))[!,:newcases]

figs = []
for gdf in groupby(sdf, :state)
  @show unique(gdf.state)
  f = @df gdf plot(:date, :newcases, legend=:none, linewidth=2, title=unique(gdf.state)[1])
  global figs = vcat(figs,f)
end
</code></pre>

<pre><code>unique(gdf.state) = ["California"]
unique(gdf.state) = ["Florida"]
unique(gdf.state) = ["Illinois"]
unique(gdf.state) = ["Louisiana"]
unique(gdf.state) = ["Massachusetts"]
unique(gdf.state) = ["Michigan"]
unique(gdf.state) = ["New Jersey"]
unique(gdf.state) = ["New York"]
unique(gdf.state) = ["Pennsylvania"]
unique(gdf.state) = ["Washington"]
</code></pre>
<pre><code class="julia">display(plot(figs[1:9]..., layout=(3,3)))
</code></pre>

<p><img alt="" src="../figures/Rt_1_1.png" /></p>
<p>From this we can see that new cases are very noisy. This is especially
problematic when cases jump from near 0 to very high values, such as in
Illinois. The median value of and variance of new cases, $k_t$, are both
$k_{t-1} e^{\gamma(R_t - 1)}$. Only huge changes in $R_t$ can
rationalize huge jumps in new cases.</p>
<p>Let’s compute posteriors for each state.</p>
<pre><code class="julia">using Interpolations, Distributions

function rtpost(cases, γ, σ, prior0, casepdf)
  (rgrid, postgrid, ll) = rtpostgrid(cases)(γ, σ, prior0, casepdf)
  w = rgrid[2] - rgrid[1]
  T = length(cases)
  p = [LinearInterpolation(rgrid, postgrid[:,t]) for t in 1:T]
  coverage = 0.9
  cr = zeros(T,2)
  mu = vec(rgrid' * postgrid*w)
  for t in 1:T
    l = findfirst(cumsum(postgrid[:,t].*w).&gt;(1-coverage)/2)
    h = findlast(cumsum(postgrid[:,t].*w).&lt;(1-(1-coverage)/2))
    if !(l === nothing || h === nothing)
      cr[t,:] = [rgrid[l], rgrid[h]]
    end
  end
  return(p, mu, cr)
end

function rtpostgrid(cases)
  # We'll compute the posterior on these values of R_t
  rlo = 0
  rhi = 8
  steps = 500
  rgrid = range(rlo, rhi, length=steps)
  Δgrid = range(0.05, 0.95, length=10)
  w = rgrid[2] - rgrid[1]
  dr = rgrid .- rgrid'
  fn=function(γ, σ, prior0, casepdf)
    prr = pdf.(Normal(0,σ), dr) # P(r_{t+1} | r_t)
    for i in 1:size(prr,1)
      prr[i, : ] ./= sum(prr[i,:].*w)
    end
    postgrid = Matrix{typeof(σ)}(undef,length(rgrid), length(cases)) # P(R_t | k_t, k_{t-1},...)
    like = similar(postgrid, length(cases))
    for t in 1:length(cases)
      if (t==1)
        postgrid[:,t] .= prior0.(rgrid)
      else
        if (cases[t-1]===missing || cases[t]===missing)
          pkr = 1  # P(k_t | R_t)
        else
          λ = max(cases[t-1],1).* exp.(γ .* (rgrid .- 1))
          #r = λ*nbp/(1-nbp)
          #pkr = pdf.(NegativeBinomial.(r,nbp), cases[t])
          pkr = casepdf.(λ, cases[t])
          if (all(pkr.==0))
            @warn &quot;all pkr=0&quot;
            @show t, cases[t], cases[t-1]
            pkr .= 1
          end
        end
        postgrid[:,t] = pkr.*(prr*postgrid[:,t-1])
        like[t] = sum(postgrid[:,t].*w)
        postgrid[:,t] ./= max(like[t], 1e-15)
      end
    end
    ll = try
      sum(log.(like))
    catch
      -710*length(like)
    end
    return((rgrid, postgrid, ll))
  end
  return(fn)
end

for σ in [0.1, 0.25, 1]
  γ =1/7
  nbp = 0.01
  figs = []
  for gdf in groupby(sdf, :state)
    p, m, cr = rtpost(gdf.newcases, γ, σ, x-&gt;pdf(truncated(Gamma(4,1),0,8), x),
                      (λ,x)-&gt;pdf(Poisson(λ),x))
    f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=&quot;Rₜ&quot;)
    f = hline!(f,[1.0])
    figs = vcat(figs, f)
  end
  l = @layout [a{.1h};grid(1,1)]
  display(plot(plot(annotation=(0.5,0.5, &quot;Poisson &amp; σ=$σ&quot;), framestyle = :none),
               plot(figs[1:9]..., layout=(3,3)), layout=l))
end
</code></pre>

<pre><code>(t, cases[t], cases[t - 1]) = (72, 2052, 215)
(t, cases[t], cases[t - 1]) = (90, 0, 1705)
(t, cases[t], cases[t - 1]) = (91, 3122, 0)
(t, cases[t], cases[t - 1]) = (55, 352, 2)
(t, cases[t], cases[t - 1]) = (89, 6103, 11115)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (91, 449, -141)
(t, cases[t], cases[t - 1]) = (72, 2052, 215)
(t, cases[t], cases[t - 1]) = (90, 0, 1705)
(t, cases[t], cases[t - 1]) = (91, 3122, 0)
(t, cases[t], cases[t - 1]) = (55, 352, 2)
(t, cases[t], cases[t - 1]) = (89, 6103, 11115)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (91, 449, -141)
(t, cases[t], cases[t - 1]) = (72, 2052, 215)
(t, cases[t], cases[t - 1]) = (90, 0, 1705)
(t, cases[t], cases[t - 1]) = (91, 3122, 0)
(t, cases[t], cases[t - 1]) = (55, 352, 2)
(t, cases[t], cases[t - 1]) = (89, 6103, 11115)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (91, 449, -141)
</code></pre>
<p><img alt="" src="../figures/Rt_2_1.png" /> <img alt="" src="../figures/Rt_2_2.png" /> <img alt="" src="../figures/Rt_2_3.png" /></p>
<p>In these results, what is happening is that when new cases fluctuate too
much, the likelihood is identically 0, causing the posterior calculation
to break down. Increasing the variance of changes in $R_t$, widens the
posterior confidence intervals, but does not solve the problem of
vanishing likelihoods.</p>
<p>One thing that can “solve” the problem is choosing a distribution of
$k_t | \lambda, k_{t-1}$ with higher variance. The negative binomial
with parameters $\lambda p/(1-p)$ and $p$ has mean $\lambda$ and
variance $\lambda/p$.</p>
<pre><code class="julia">γ =1/7
σ = 0.25

Plots.closeall()
for σ in [0.1, 0.25, 0.5]
  for nbp in [0.5, 0.1, 0.01]
    figs = []
    for gdf in groupby(sdf, :state)
      p, m, cr = rtpost(gdf.newcases, γ, σ, x-&gt;pdf(truncated(Gamma(4,1),0,8), x),
                      (λ,x)-&gt;pdf(NegativeBinomial(λ*nbp/(1-nbp), nbp),x));
      f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=&quot;Rₜ&quot;)
      f = hline!(f,[1.0])
      figs = vcat(figs, f)
    end
    l = @layout [a{.1h};grid(1,1)]
    display(plot(plot(annotation=(0.5,0.5, &quot;Negative binomial, p=$nbp, &amp; σ=$σ&quot;), framestyle = :none),
                 plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false))
  end
end
</code></pre>

<pre><code>(t, cases[t], cases[t - 1]) = (90, 0, 1705)
(t, cases[t], cases[t - 1]) = (91, 3122, 0)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (90, 0, 1705)
(t, cases[t], cases[t - 1]) = (91, 3122, 0)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (90, 0, 1705)
(t, cases[t], cases[t - 1]) = (91, 3122, 0)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
(t, cases[t], cases[t - 1]) = (54, -39, 74)
(t, cases[t], cases[t - 1]) = (90, -141, 479)
</code></pre>
<p><img alt="" src="../figures/Rt_3_1.png" /> <img alt="" src="../figures/Rt_3_2.png" /> <img alt="" src="../figures/Rt_3_3.png" />
<img alt="" src="../figures/Rt_3_4.png" /> <img alt="" src="../figures/Rt_3_5.png" /> <img alt="" src="../figures/Rt_3_6.png" />
<img alt="" src="../figures/Rt_3_7.png" /> <img alt="" src="../figures/Rt_3_8.png" /> <img alt="" src="../figures/Rt_3_9.png" /></p>
<p>What Systrom did was smooth the new cases before using the Poisson
distribution. He used a window width of $7$ and Gaussian weights with
standard deviation $2$.</p>
<pre><code class="julia">using RollingFunctions
σ = 0.25
Plots.closeall()
for w in [3, 7, 11]
  for s in [0.5, 2, 4]
    γ =1/7
    nbp = 0.01
    figs = []
    for gdf in groupby(sdf, :state)
      windowsize = w
      weights = pdf(Normal(0, s), -floor(windowsize/2):floor(windowsize/2))
      weights = weights/sum(weights)
      smoothcases = Int.(round.(runmean(gdf.newcases[2:end], windowsize, weights*windowsize)))
      p, m, cr = rtpost(smoothcases, γ, σ, x-&gt;pdf(truncated(Gamma(4,1),0,8), x),
                        (λ,x)-&gt;pdf(Poisson(λ),x))
      f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=&quot;Rₜ&quot;)
      f = hline!(f,[1.0])
      figs = vcat(figs, f)
    end
    l = @layout [a{.1h};grid(1,1)]
    display(plot(plot(annotation=(0.5,0.5, &quot;Poisson &amp; σ=$σ, s=$s, w=$w&quot;), framestyle = :none),
                 plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false))
  end
end
</code></pre>

<pre><code>(t, cases[t], cases[t - 1]) = (54, -4, 68)
(t, cases[t], cases[t - 1]) = (90, -12, 390)
(t, cases[t], cases[t - 1]) = (56, -4, 68)
(t, cases[t], cases[t - 1]) = (58, -4, 68)
</code></pre>
<p><img alt="" src="../figures/Rt_4_1.png" /> <img alt="" src="../figures/Rt_4_2.png" /> <img alt="" src="../figures/Rt_4_3.png" />
<img alt="" src="../figures/Rt_4_4.png" /> <img alt="" src="../figures/Rt_4_5.png" /> <img alt="" src="../figures/Rt_4_6.png" />
<img alt="" src="../figures/Rt_4_7.png" /> <img alt="" src="../figures/Rt_4_8.png" /> <img alt="" src="../figures/Rt_4_9.png" /></p>
<p>Here we see that we can get a variety of results depending on the
smoothing used. All of these posteriors ignore the uncertainty in the
choice of smoothing parameters (and procedure).</p>
<h1 id="an-alternative-approach">An alternative approach<a class="headerlink" href="#an-alternative-approach" title="Permanent link">&para;</a></h1>
<p>Here we follow an approach similar in spirit to Systrom, with a few
modifications and additions. The primary modification is that we alter
the model of $k_t|k_{t-1}, R_t$ to allow measurement error in both $k_t$
and $k_{t-1}$. We make four additions. First, we utilize data on
movement and business operations as auxillary noisy measures of $R_t$.
Second, we allow state policies to shift the mean of $R_t$. Third, we
combine data from all states to improve precision in each. Fourth, we
incorporate testing numbers into the data.</p>
<p>As above, we begin from the approximation</p>
<p>
<script type="math/tex; mode=display">
k^*_{s,t} \approx k^*_{s,t-1} \frac{\tau_{s,t}}{\tau_{s,t-1}} e^{\gamma(R_{st} - 1)})
</script>
</p>
<p>where $k^*$ is the true, unobserved number of new cases. Taking logs and
rearranging we have</p>
<p>
<script type="math/tex; mode=display">
\log(k^*_{s,t}) - \log(k^*_{s,t-1}) = \gamma(R_{s,t} - 1) +
\log\left(\frac{\tau_{s,t}}{\tau_{s,t-1}}\right)
</script>
</p>
<p>Let $k_{s,t}$ be the noisy observed value of $k^*_{s,t}$, then</p>
<p>
<script type="math/tex; mode=display">
\log(k_{s,t}) - \log(k_{s,t-1}) = \gamma(R_{s,t} - 1) +
\log\left(\frac{\tau_{s,t}}{\tau_{s,t-1}}\right) - \epsilon_{s,t} + \epsilon_{s,t-1}
</script>
</p>
<p>where <script type="math/tex; mode=display">
 \log(k^*_{s,t}) =  \log(k_{s,t}) +\epsilon_{s,t}
</script> and $\epsilon_{s,t}$ is measurement error.</p>
<p>With appropriate assumptions on $\epsilon$, $\tau$, $R$ and other
observables, we can then use regression to estimate $R$.</p>
<p>As a simple example, let’s assume</p>
<ol>
<li>$R_{s,t} = R_{s,0} + \alpha d_{s,t}$ where $d_{s,t}$ are indicators
    for NPI’s being in place.</li>
<li>That $\tau_{s,t}$ is constant over time for each $s$</li>
<li>$E[\epsilon_{s,t} - \epsilon_{s,t-1}|d] = 0$ and
    $\epsilon_{s,t} - \epsilon_{s,t-1}$ is uncorrelated over time (just
    to simplify; this is not a good assumption).</li>
</ol>
<p>```{=html}
<!-- --></p>
<pre><code>``` julia
using GLM, RegressionTables
pvars = [Symbol(&quot;Stay.at.home..shelter.in.place&quot;),
         Symbol(&quot;State.of.emergency&quot;),
         Symbol(&quot;Date.closed.K.12.schools&quot;),
         Symbol(&quot;Closed.gyms&quot;),
         Symbol(&quot;Closed.movie.theaters&quot;),
         Symbol(&quot;Closed.day.cares&quot;),
         Symbol(&quot;Date.banned.visitors.to.nursing.homes&quot;),
         Symbol(&quot;Closed.non.essential.businesses&quot;),
         Symbol(&quot;Closed.restaurants.except.take.out&quot;)]
sdf = copy(df)
for p in pvars
  sdf[!,p] = by(sdf, :state, (:date, p) =&gt; x-&gt;(!ismissing(unique(x[p])[1]) .&amp; (x.date .&gt;= unique(x[p])[1]))).x1
end
sdf = sort(sdf, [:state, :date])
sdf[!,:newcases] = by(sdf, :state, newcases = :cases =&gt; x-&gt;(vcat(missing, diff(x))))[!,:newcases]
sdf[!,:dlogk] = by(sdf, :state, dlogk = :newcases =&gt; x-&gt;(vcat(missing, diff(log.(max.(x,0.1))))))[!,:dlogk]

fmla = FormulaTerm(Term(:dlogk), Tuple(Term.(vcat(pvars,:state))))
reg = lm(fmla, sdf)
regtable(reg, renderSettings=asciiOutput())
</code></pre>

<pre><code>-----------------------------------------------
                                         dlogk
                                        -------
                                            (1)
-----------------------------------------------
(Intercept)                               0.047
                                        (0.155)
Stay.at.home..shelter.in.place           -0.160
                                        (0.094)
State.of.emergency                       0.200*
                                        (0.080)
Date.closed.K.12.schools                 0.246*
                                        (0.118)
Closed.gyms                              -0.208
                                        (0.200)
Closed.movie.theaters                     0.128
                                        (0.204)
Closed.day.cares                          0.031
                                        (0.100)
Date.banned.visitors.to.nursing.homes    -0.050
                                        (0.083)
Closed.non.essential.businesses          -0.102
                                        (0.110)
Closed.restaurants.except.take.out       -0.143
                                        (0.159)
state: Alaska                            -0.033
                                        (0.219)
state: Arizona                           -0.036
                                        (0.221)
state: Arkansas                          -0.030
                                        (0.226)
state: California                         0.015
                                        (0.222)
state: Colorado                           0.069
                                        (0.217)
state: Connecticut                        0.006
                                        (0.218)
state: Delaware                           0.016
                                        (0.216)
state: District of Columbia               0.002
                                        (0.219)
state: Florida                           -0.006
                                        (0.218)
state: Georgia                           -0.044
                                        (0.218)
state: Hawaii                            -0.117
                                        (0.229)
state: Idaho                              0.006
                                        (0.218)
state: Illinois                           0.036
                                        (0.215)
state: Indiana                            0.020
                                        (0.219)
state: Iowa                               0.034
                                        (0.220)
state: Kansas                            -0.118
                                        (0.221)
state: Kentucky                          -0.061
                                        (0.216)
state: Louisiana                          0.049
                                        (0.217)
state: Maine                              0.017
                                        (0.219)
state: Maryland                           0.009
                                        (0.214)
state: Massachusetts                      0.053
                                        (0.213)
state: Michigan                           0.043
                                        (0.213)
state: Minnesota                          0.030
                                        (0.216)
state: Mississippi                       -0.011
                                        (0.218)
state: Missouri                          -0.098
                                        (0.218)
state: Montana                           -0.022
                                        (0.216)
state: Nebraska                          -0.075
                                        (0.218)
state: Nevada                            -0.006
                                        (0.219)
state: New Hampshire                      0.012
                                        (0.216)
state: New Jersey                         0.051
                                        (0.216)
state: New Mexico                        -0.050
                                        (0.216)
state: New York                           0.082
                                        (0.217)
state: North Carolina                     0.009
                                        (0.216)
state: North Dakota                      -0.090
                                        (0.218)
state: Ohio                               0.046
                                        (0.213)
state: Oklahoma                          -0.054
                                        (0.217)
state: Oregon                            -0.019
                                        (0.215)
state: Pennsylvania                       0.022
                                        (0.213)
state: Rhode Island                       0.012
                                        (0.213)
state: South Carolina                    -0.091
                                        (0.216)
state: South Dakota                      -0.165
                                        (0.220)
state: Tennessee                          0.005
                                        (0.216)
state: Texas                              0.033
                                        (0.217)
state: Utah                              -0.112
                                        (0.218)
state: Vermont                           -0.019
                                        (0.213)
state: Virginia                          -0.031
                                        (0.220)
state: Washington                         0.029
                                        (0.217)
state: West Virginia                     -0.016
                                        (0.216)
state: Wisconsin                          0.013
                                        (0.219)
state: Wyoming                           -0.077
                                        (0.218)
-----------------------------------------------
Estimator                                   OLS
-----------------------------------------------
N                                         4,539
R2                                        0.006
-----------------------------------------------
</code></pre>
<p>From this we get that if we assume $\gamma = 1/7$, then the the baseline
estimate of $R$ in Illinois is $7(0.046 + 0.034) + 1\approx 1.56$ with a
stay at home order, $R$ in Illinois becomes
$7(0.046 + 0.035 - 0.147) + 1 \approx 0.53$.</p>
<p>Some of the policies have positive coefficient estimates, which is
strange. This is likely due to assumption 1 being incorrect. There is
likely an unobserved component of $R_{s,t}$ that is positively
correlated with policy indicators.</p>
<h2 id="state-space-model">State space model<a class="headerlink" href="#state-space-model" title="Permanent link">&para;</a></h2>
<p>A direct analog of Systrom’s approach is to treat $R_{s,t}$ as an
unobserved latent process. Specifically, we will assume that <script type="math/tex; mode=display">
\begin{align*}
R_{s,0} & \sim N(\mu_{R,0}, \sigma^2_{R,0}) \\
R_{s,t} & = \rho R_{s,t} + u_{s,t} \;,\; u_{s,t} \sim N(0, \sigma^2_R) \\
\Delta \log(k)_{s,t} & = \gamma (R_{s,t} - 1) + \epsilon_{s,t} -
\epsilon_{s,t-1} \;, \; \epsilon_{s,t} \sim N(0, \sigma^2_k)
\end{align*}
</script>
</p>
<p>Note that the Poisson assumption on the distribution of $k_{s,t}$ used
by Systrom implies an extremely small $\sigma^2_k$, since the variance
of log Poisson($\lambda$) distribution is $1/\lambda$.</p>
<p>If $\epsilon_{s,t} - \epsilon_{s,t-1}$ weere independent over $t$, we
could compute the likelihood and posteriors of $R_{s,t}$ through the
standard Kalman filter. Of course, $\epsilon_{s,t} - \epsilon_{s,t-1}$
is not independent over time, so we must adjust the Kalman filter
accordingly. We follow the approach of (Kurtz and Lin
<a href="#ref-kurtz2019">2019</a>) to make this adjustment.</p>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Is there a better reference? I&rsquo;m sure someone did this much
earlier than 2019&hellip;</p>
</div>
<p>We estimate the parameters using data from US states. We set time 0 as
the first day in which a state had at least 10 cumulative cases. We then
compute posteriors for the parameters by MCMC. We place the following
priors on the parameters.</p>
<pre><code class="julia">using Distributions, TransformVariables, DynamicHMC, MCMCChains, Plots, StatsPlots,
  LogDensityProblems, Random, LinearAlgebra
include(&quot;jmd/rtmod.jl&quot;)

rlo=-1
rhi=1.1
priors = (γ = truncated(Normal(1/7,1/7), 1/28, 1/1),
          σR0 = truncated(Normal(1, 3), 0, Inf),
          μR0 = truncated(Normal(1, 3), 0, Inf),
          σR = truncated(Normal(0.25,1),0,Inf),
          σk = truncated(Normal(0.1, 5), 0, Inf),
          #ρ = Uniform(-1,1.1))
          ρ = Uniform(rlo, rhi))
</code></pre>

<pre><code>(γ = Truncated(Normal{Float64}(μ=0.14285714285714285, σ=0.14285714285714285
), range=(0.03571428571428571, 1.0)), σR0 = Truncated(Normal{Float64}(μ=1.0
, σ=3.0), range=(0.0, Inf)), μR0 = Truncated(Normal{Float64}(μ=1.0, σ=3.0),
 range=(0.0, Inf)), σR = Truncated(Normal{Float64}(μ=0.25, σ=1.0), range=(0
.0, Inf)), σk = Truncated(Normal{Float64}(μ=0.1, σ=5.0), range=(0.0, Inf)),
 ρ = Uniform{Float64}(a=-1.0, b=1.1))
</code></pre>
<p>The estimation is fast and the chain appears to mix well.</p>
<pre><code class="julia">sdf = sort(sdf, (:state, :date));
dlogk = [filter(x-&gt;((x.state==st) .&amp;
                    (x.cases .&gt;=10)),
                sdf).dlogk for st in unique(sdf.state)];
dates = [filter(x-&gt;((x.state==st) .&amp;
                    (x.cases .&gt;=10)),
                sdf).date for st in unique(sdf.state)];

mdl = RT.RtRW(dlogk, priors)
trans = as( (γ = asℝ₊, σR0 = asℝ₊, μR0 = asℝ₊,
             σR = asℝ₊, σk = asℝ₊, ρ=as(Real, rlo, rhi)) )
P = TransformedLogDensity(trans, mdl)
∇P = ADgradient(:ForwardDiff, P)
p0 = (γ = 1/7, σR0=1.0, μR0=4.0,σR=0.25, σk=2.0, ρ=0.9)
x0 = inverse(trans,p0)
@time LogDensityProblems.logdensity_and_gradient(∇P, x0);
</code></pre>

<pre><code>1.537403 seconds (2.46 M allocations: 121.086 MiB, 16.43% gc time)
</code></pre>
<pre><code class="julia">rng = MersenneTwister()
steps = 100
warmup=default_warmup_stages(local_optimization=nothing,
                             stepsize_search=nothing,
                             init_steps=steps, middle_steps=steps,
                             terminating_steps=2*steps,  doubling_stages=3, M=Symmetric)
x0 = x0
res = DynamicHMC.mcmc_keep_warmup(rng, ∇P, 2000;initialization = (q = x0, ϵ=0.1),
                                  reporter = LogProgressReport(nothing, 25, 15),
                                  warmup_stages =warmup);
post = transform.(trans,res.inference.chain)
p = post[1]
vals = hcat([vcat([length(v)==1 ? v : vec(v) for v in values(p)]...) for p in post]...)'
vals = reshape(vals, size(vals)..., 1)
names = vcat([length(p[s])==1 ? String(s) : String.(s).*&quot;[&quot;.*string.(1:length(p[s])).*&quot;]&quot; for s in keys(p)]...)
cc = MCMCChains.Chains(vals, names)
display(cc)
</code></pre>

<pre><code>Object of type Chains, with data of type 2000×6×1 reshape(::Adjoint{Float64
,Array{Float64,2}}, 2000, 6, 1) with eltype Float64

Iterations        = 1:2000
Thinning interval = 1
Chains            = 1
Samples per chain = 2000
parameters        = γ, σR0, μR0, σR, σk, ρ

2-element Array{ChainDataFrame,1}

Summary Statistics
  parameters    mean     std  naive_se    mcse        ess   r_hat
  ──────────  ──────  ──────  ────────  ──────  ─────────  ──────
           γ  0.1001  0.0357    0.0008  0.0014   797.9978  1.0004
         σR0  0.9812  0.8103    0.0181  0.0273  1082.6121  1.0004
         μR0  6.2236  1.7622    0.0394  0.0603  1226.1912  1.0004
          σR  0.1108  0.0965    0.0022  0.0024  1796.4505  1.0001
          σk  1.0524  0.0165    0.0004  0.0003  2990.9421  0.9995
           ρ  0.9402  0.0117    0.0003  0.0004  1318.8002  0.9996

Quantiles
  parameters    2.5%   25.0%   50.0%   75.0%    97.5%
  ──────────  ──────  ──────  ──────  ──────  ───────
           γ  0.0537  0.0753  0.0925  0.1168   0.1910
         σR0  0.0437  0.3704  0.7710  1.4055   3.0404
         μR0  3.2775  4.9078  6.1123  7.3255  10.2025
          σR  0.0037  0.0396  0.0849  0.1563   0.3551
          σk  1.0214  1.0413  1.0522  1.0635   1.0842
           ρ  0.9170  0.9325  0.9404  0.9484   0.9623
</code></pre>
<pre><code class="julia">display(plot(cc))
</code></pre>

<p><img alt="" src="../figures/Rt_7_1.png" /></p>
<p>The posterior for the initial distribution of $R_{0,s}$ is not very
precise. The other parameters have fairly precise posteriors. Systrom
fixed all these parameters, except $\sigma_R$, which he estimated by
maximum likelihood to be 0.25. In these posteriors, a 95% credible
region for $\sigma_R$ contains his estimate. The posterior of $\rho$ is
not far from his imposed value of $1$, although $1$ is out of the 95%
credible region. A 95% posterior region for $\gamma$ contains Systrom’s
calibrated value of $1/7$.</p>
<p>It is worth noting that the estimate of $\sigma_k$ is large compared to
$\sigma_r$. This will cause new observations of $\Delta \log k$ will
have a small effect on the posterior mean of $R$.</p>
<p>Given values of the parameters, we can compute state and time specific
posterior estimates of $R_{s,t}$.</p>
<pre><code class="julia">states = unique(sdf.state)
s = findfirst(states.==&quot;New York&quot;)
function plotpostr(dates, dlogk, post)
  k = [RT.kalman(dlogk, p.σR, p.σk, p.σR0, p.μR0, p.γ, p.ρ) for p in post];
  γ = [p.γ for p in post];
  meanR = hcat([x[1] for x in k]...);
  varR = hcat([x[2] for x in k]...);
  zhat = hcat([x[3] for x in k]...);
  c = &quot;black&quot;
  figr = plot(dates, mean(meanR, dims=2), ribbon=1.64*mean(sqrt.(varR),dims=2), color=c, fillalpha=0.2,
              linewidth=1.5, legend=:none, ylab=&quot;Rₜ&quot;)
  r=([quantile(meanR[t,:] - 1.64*sqrt.(varR[t,:]), 0.05) for t in 1:size(meanR,1)],
     [quantile(meanR[t,:] + 1.64*sqrt.(varR[t,:]), 0.95) for t in 1:size(meanR,1)])
  figr = plot!(figr, dates, zeros(length(r[1])), ribbon=(-r[1], r[2]), color=c,
               linewidth=0, ylim=nothing, fillalpha=0.2)
  figr = hline!(figr, [1.], color=&quot;red&quot;, linewidth=1.5, linestyle=:dash)
  gr = copy(meanR)
  for i=1:length(γ)
    gr[:,i] .= γ[i]*(meanR[:,i].-1)
  end
  figk = plot(dates, [dlogk mean(gr, dims=2) mean(zhat,dims=2).-mean(γ)],
              labels=[&quot;Δlog(newcases)&quot; &quot;γ(R-1)&quot; &quot;Eₜ[Δlog(newcases)]&quot;],
              legend=:topright, linewidth=2)

  return(figr, figk)
end
figr, figk = plotpostr(dates[s],dlogk[s],post)
l = @layout [a{.1h};
             grid(2,1)]
plot(plot(annotation=(0.5,0.5, states[s]), framestyle = :none),
     figr, figk, layout=l)
</code></pre>

<p><img alt="" src="../figures/Rt_8_1.png" /></p>
<p>The top panel of this figure shows the posterior distribution of
$R_{s,t}$ in New York. The black line is the posterior mean. The dark
grey region is the average (over model parameters) of a 90% credible
region conditional on the model parameters. This is comparable to what
Systrom (and many others) report, and ignores uncertainty in the model
parameters. The light grey region is a 90% credile region taking into
account parameter uncertainty.</p>
<p>The lower panel shows the observed $\Delta log k$, the prediction of it
attributable to $R_t$, and the prediction of it from the full model. The
full preduction uses the negatively correlated $MA(1)$ errors in
$\Delta log k$ in addition to $R_t$ to forecast
$E[\Delta \log k_{t+1} | \mathcal{I}_t]$.</p>
<h3 id="posteriors-for-all-states">Posteriors for all States<a class="headerlink" href="#posteriors-for-all-states" title="Permanent link">&para;</a></h3>
<pre><code class="julia">S = length(states)
figs = fill(plot(), 9*(S ÷ 9 + 1))
for s in 1:S
  figr, figk = plotpostr(dates[s],dlogk[s],post)
  l = @layout [a{.1h};
               grid(1,1)]
  figs[s] = plot(plot(annotation=(0.5,0.5, states[s]), framestyle = :none),
                 figr, layout=l)
  if ((s % 9) ==0 || ( s==length(states)))
    display(plot(figs[(s-8):s]..., layout=(3,3), reuse=false))
  end
end
</code></pre>

<p><img alt="" src="../figures/Rt_9_1.png" /> <img alt="" src="../figures/Rt_9_2.png" /> <img alt="" src="../figures/Rt_9_3.png" />
<img alt="" src="../figures/Rt_9_4.png" /> <img alt="" src="../figures/Rt_9_5.png" /> <img alt="" src="../figures/Rt_9_6.png" /></p>
<p>We can see that the posteriors vary very little from state to state. The
model picks up a general downward trend in $\Delta \log k$ through the
slightly less than 1 estimate of $\rho$. This drives the posteriors of
$R_{s,t}$ in every state to decrease over time. Since
$\sigma_k &gt;&gt; \sigma_R$, the actual realizations of $\Delta \log k$ do
not affect the state-specific posteriors very much.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I also tried fixing $\rho=1$. This gives similar results in terms
of $\sigma_k &gt;&gt; \sigma_R$, and gives posterior $R_{s,t}$ that
approximately constant over time.</p>
</div>
<div class="references hanging-indent" id="refs">
<div id="ref-bettencourt2008">
<p>Bettencourt, Ruy M., Luís M. A. AND Ribeiro. 2008. “Real Time Bayesian
Estimation of the Epidemic Potential of Emerging Infectious Diseases.”
<em>PLOS ONE</em> 3 (5): 1–9. <a href="https://doi.org/10.1371/journal.pone.0002185">https://doi.org/10.1371/journal.pone.0002185</a>.</p>
</div>
<div id="ref-kurtz2019">
<p>Kurtz, Vince, and Hai Lin. 2019. “Kalman Filtering with Gaussian
Processes Measurement Noise.”</p>
</div>
</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

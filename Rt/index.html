<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <meta name="author" content="Paul Schrimpf">
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>Systrom Approach - CovidSEIR.jl</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atelier-forest-light.min.css">
        <link href="../assets/Documenter.css" rel="stylesheet">
        <link href="../assets/extra.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">CovidSEIR.jl</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Package Docs</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">SEIR Model and Results <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../covid/" class="dropdown-item">Model</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Results</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../canada/" class="dropdown-item">Canada</a>
</li>
            
<li>
    <a href="../italy/" class="dropdown-item">Italy</a>
</li>
            
<li>
    <a href="../korea/" class="dropdown-item">South Korea</a>
</li>
            
<li>
    <a href="../china/" class="dropdown-item">China</a>
</li>
            
<li>
    <a href="../us/" class="dropdown-item">United States</a>
</li>
    </ul>
  </li>
                                    
<li>
    <a href="../state/" class="dropdown-item">US States</a>
</li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Reproductive number</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="./" class="dropdown-item active">Systrom Approach</a>
</li>
            
<li>
    <a href="../rt_longdiff/" class="dropdown-item">Long-differening</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../license/" class="dropdown-item">License</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../state/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../rt_longdiff/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li class="nav-item">
                                <a href="https://github.com/schrimpf/CovidSEIR.jl/edit/master/docs/Rt.md" class="nav-link"><i class="fa fa-github"></i> Edit on GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#model" class="nav-link">Model</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#data" class="nav-link">Data</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#statistical-model" class="nav-link">Statistical Model</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#systroms-approach" class="nav-link">Systrom’s approach</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#an-alternative-approach" class="nav-link">An alternative approach</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#state-space-model" class="nav-link">State space model</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#posteriors-for-additional-states" class="nav-link">Posteriors for additional states</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a></p>
<p>This work is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike
4.0 International
License</a></p>
<h1 id="model">Model<a class="headerlink" href="#model" title="Permanent link">&para;</a></h1>
<p>Following <a href="http://systrom.com/blog/the-metric-we-need-to-manage-covid-19/">Kevin
Systrom</a>,
we adapt the approach of (Bettencourt <a href="#ref-bettencourt2008">2008</a>) to
compute real-time rolling estimates of pandemic parameters. (Bettencourt
<a href="#ref-bettencourt2008">2008</a>) begin from a SIR model,</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
\dot{S} & = -\frac{S}{N} \beta I \\
\dot{I} & = \frac{S}{N} \beta I - \gamma I \\
\dot{R} & = \gamma I
\end{align*}
</script>
</p>
<p>To this we add the possibility that not all cases are known. Cases get
get detected at rate $I$, so cumulative confirmed cases, $C$, evolves as</p>
<p>
<script type="math/tex; mode=display">
\dot{C} = \tau I
</script>
</p>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Should we add other states to this model? If yes, how? I think
using death and hospitalization numbers in estimation makes sense.</p>
</div>
<p>The number of new confirmed cases from time $t$ to $t+\delta$ is then:</p>
<p>We will allow for the testing rate, $\tau$, and infection rate, $\beta$,
to vary over time.</p>
<p>
<script type="math/tex; mode=display">
k_t \equiv \frac{C(t+\delta) - C(t)}{\delta} = \int_t^{t+\delta} \tau(s) I(s) ds
\approx \tau(t) I(t)
</script>
</p>
<p>As in (Bettencourt <a href="#ref-bettencourt2008">2008</a>),</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
I(t) = & I(t-\delta) \int_{t-\delta}^{t} e^{\frac{S(s)}{N} \beta(s) -
\gamma} ds \\
\approx & I(t-\delta) e^{\delta \left( \frac{S(t-\delta)}{N}
\beta(t-\delta) - \gamma \right)}
\end{align*}
</script>
</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The reproductive number is:
$R_t \equiv \frac{S(t)}{N}\frac{\beta(t)}{\gamma}$.</p>
</div>
<p>Substituting the expression for $I_t$ into $k_t$, we have</p>
<p>
<script type="math/tex; mode=display">
\begin{align*}
k_t \approx & \tau(t) I(t-\delta) e^{\delta \left(
\frac{S(t-\delta)}{N} \beta(t-\delta) - \gamma\right)} \\
\approx & k_{t-\delta} \frac{\tau(t)}{\tau(t-\delta)}
e^{\delta \left(\frac{S(t-\delta)}{N} \beta(t-\delta) - \gamma \right)}
\end{align*}
</script>
</p>
<h1 id="data">Data<a class="headerlink" href="#data" title="Permanent link">&para;</a></h1>
<p>We use the same data as the <a href="../state/">US state model</a>.</p>
<p>The data combines information on</p>
<ul>
<li>Daily case counts and deaths from JHU CSSE</li>
<li>Daily Hospitalizations, recoveries, and testing from the Covid
    Tracking Project</li>
<li>Covid related policy changes from Raifman et al</li>
<li>Movements from Google Mobility Reports</li>
<li>Hourly workers from Hoembase</li>
</ul>
<h1 id="statistical-model">Statistical Model<a class="headerlink" href="#statistical-model" title="Permanent link">&para;</a></h1>
<p>The above theoretical model gives a deterministic relationship between
$k_t$ and $k_{t-1}$ given the parameters. To bring it to data we must
add stochasticity.</p>
<h2 id="systroms-approach">Systrom’s approach<a class="headerlink" href="#systroms-approach" title="Permanent link">&para;</a></h2>
<p>First we describe what Systrom does. He assumes that
$R_{0} \sim Gamma(4,1)$. Then for $t=1, &hellip;, T$, he computes
$P(R_t|k_{t}, k_{t-1}, &hellip; ,k_0)$ iteratively using Bayes’ rules.
Specifically, he assumes <script type="math/tex; mode=display">
k_t | R_t, k_{t-1}, ... \sim Poisson(k_{t-1} e^{\gamma(R_t - 1)})
</script> and that $R_t$ follows a random walk, so the prior of $R_t | R_{t-1}$
is <script type="math/tex; mode=display">
R_t | R_{t-1} \sim N(R_{t-1}, \sigma^2)
</script>
</p>
<p>so that</p>
<p>
<script type="math/tex; mode=display">
P(R_t|k_{t}, k_{t-1}, ... ,k_0) = \frac{P(k_t | R_t, k_{t-1}) P(R_t |
R_{t-1}) P(R_{t-1} | k_{t-1}, ...)} {P(k_t)}
</script>
</p>
<p>Note that this computes posteriors of $R_t$ given current and past
cases. Future cases are also informative of $R_t$, and you could instead
compute $P(R_t | k_0, k_1, &hellip;, k_T)$.</p>
<p>The notebook makes some mentions of Gaussian processes. There’s likely
some way to recast the random walk assumption as a Gaussian process
prior (the kernel would be $\kappa(t,t&rsquo;) = \min{t,t&rsquo;} \sigma^2$), but
that seems to me like an unusual way to describe it.</p>
<h3 id="code">Code<a class="headerlink" href="#code" title="Permanent link">&para;</a></h3>
<p>Let’s see how Systrom’s method works.</p>
<p>First the load data.</p>
<pre><code class="julia">using DataFrames, Plots, StatsPlots, CovidSEIR
Plots.pyplot()

df = CovidSEIR.statedata()
df = filter(x-&gt;x.fips&lt;60, df)
# focus on 10 states with most cases as of April 1, 2020
sdf = select(df[df[!,:date].==Dates.Date(&quot;2020-04-01&quot;),:], Symbol(&quot;cases.nyt&quot;), :state) |&gt;
    x-&gt;sort(x,Symbol(&quot;cases.nyt&quot;), rev=true)
states=sdf[1:10,:state]
sdf = select(filter(r-&gt;r[:state] ∈ states, df), Symbol(&quot;cases.nyt&quot;), :state, :date)
sdf = sort(sdf, [:state, :date])
sdf[!,:newcases] = by(sdf, :state, newcases = Symbol(&quot;cases.nyt&quot;) =&gt; x-&gt;(vcat(missing, diff(x))))[!,:newcases]

figs = []
for gdf in groupby(sdf, :state)
  f = @df gdf plot(:date, :newcases, legend=:none, linewidth=2, title=unique(gdf.state)[1])
  global figs = vcat(figs,f)
end
display(plot(figs[1:9]..., layout=(3,3)))
</code></pre>

<p><img alt="" src="../figures/Rt_1_1.png" /></p>
<p>From this we can see that new cases are very noisy. This is especially
problematic when cases jump from near 0 to very high values, such as in
Illinois. The median value of and variance of new cases, $k_t$, are both
$k_{t-1} e^{\gamma(R_t - 1)}$. Only huge changes in $R_t$ can
rationalize huge jumps in new cases.</p>
<p>Let’s compute posteriors for each state.</p>
<pre><code class="julia">using Interpolations, Distributions

function rtpost(cases, γ, σ, prior0, casepdf)
  (rgrid, postgrid, ll) = rtpostgrid(cases)(γ, σ, prior0, casepdf)
  w = rgrid[2] - rgrid[1]
  T = length(cases)
  p = [LinearInterpolation(rgrid, postgrid[:,t]) for t in 1:T]
  coverage = 0.9
  cr = zeros(T,2)
  mu = vec(rgrid' * postgrid*w)
  for t in 1:T
    l = findfirst(cumsum(postgrid[:,t].*w).&gt;(1-coverage)/2)
    h = findlast(cumsum(postgrid[:,t].*w).&lt;(1-(1-coverage)/2))
    if !(l === nothing || h === nothing)
      cr[t,:] = [rgrid[l], rgrid[h]]
    end
  end
  return(p, mu, cr)
end

function rtpostgrid(cases)
  # We'll compute the posterior on these values of R_t
  rlo = 0
  rhi = 8
  steps = 500
  rgrid = range(rlo, rhi, length=steps)
  Δgrid = range(0.05, 0.95, length=10)
  w = rgrid[2] - rgrid[1]
  dr = rgrid .- rgrid'
  fn=function(γ, σ, prior0, casepdf)
    prr = pdf.(Normal(0,σ), dr) # P(r_{t+1} | r_t)
    for i in 1:size(prr,1)
      prr[i, : ] ./= sum(prr[i,:].*w)
    end
    postgrid = Matrix{typeof(σ)}(undef,length(rgrid), length(cases)) # P(R_t | k_t, k_{t-1},...)
    like = similar(postgrid, length(cases))
    for t in 1:length(cases)
      if (t==1)
        postgrid[:,t] .= prior0.(rgrid)
      else
        if (cases[t-1]===missing || cases[t]===missing)
          pkr = 1  # P(k_t | R_t)
        else
          λ = max(cases[t-1],1).* exp.(γ .* (rgrid .- 1))
          #r = λ*nbp/(1-nbp)
          #pkr = pdf.(NegativeBinomial.(r,nbp), cases[t])
          pkr = casepdf.(λ, cases[t])
          if (all(pkr.==0))
            @warn &quot;all pkr=0&quot;
            #@show t, cases[t], cases[t-1]
            pkr .= 1
          end
        end
        postgrid[:,t] = pkr.*(prr*postgrid[:,t-1])
        like[t] = sum(postgrid[:,t].*w)
        postgrid[:,t] ./= max(like[t], 1e-15)
      end
    end
    ll = try
      sum(log.(like))
    catch
      -710*length(like)
    end
    return((rgrid, postgrid, ll))
  end
  return(fn)
end

for σ in [0.1, 0.25, 1]
  γ =1/7
  nbp = 0.01
  figs = []
  for gdf in groupby(sdf, :state)
    p, m, cr = rtpost(gdf.newcases, γ, σ, x-&gt;pdf(truncated(Gamma(4,1),0,8), x),
                      (λ,x)-&gt;pdf(Poisson(λ),x))
    f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=&quot;Rₜ&quot;)
    f = hline!(f,[1.0])
    figs = vcat(figs, f)
  end
  l = @layout [a{.1h};grid(1,1)]
  display(plot(plot(annotation=(0.5,0.5, &quot;Poisson &amp; σ=$σ&quot;), framestyle = :none),
               plot(figs[1:9]..., layout=(3,3)), layout=l))
end
</code></pre>

<p><img alt="" src="../figures/Rt_2_1.png" /> <img alt="" src="../figures/Rt_2_2.png" /> <img alt="" src="../figures/Rt_2_3.png" /></p>
<p>In these results, what is happening is that when new cases fluctuate too
much, the likelihood is identically 0, causing the posterior calculation
to break down. Increasing the variance of changes in $R_t$, widens the
posterior confidence intervals, but does not solve the problem of
vanishing likelihoods.</p>
<p>One thing that can “solve” the problem is choosing a distribution of
$k_t | \lambda, k_{t-1}$ with higher variance. The negative binomial
with parameters $\lambda p/(1-p)$ and $p$ has mean $\lambda$ and
variance $\lambda/p$.</p>
<pre><code class="julia">γ =1/7
σ = 0.25

Plots.closeall()
for σ in [0.1, 0.25, 0.5]
  for nbp in [0.5, 0.1, 0.01]
    figs = []
    for gdf in groupby(sdf, :state)
      p, m, cr = rtpost(gdf.newcases, γ, σ, x-&gt;pdf(truncated(Gamma(4,1),0,8), x),
                      (λ,x)-&gt;pdf(NegativeBinomial(λ*nbp/(1-nbp), nbp),x));
      f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=&quot;Rₜ&quot;)
      f = hline!(f,[1.0])
      figs = vcat(figs, f)
    end
    l = @layout [a{.1h};grid(1,1)]
    display(plot(plot(annotation=(0.5,0.5, &quot;Negative binomial, p=$nbp, &amp; σ=$σ&quot;), framestyle = :none),
                 plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false))
  end
end
</code></pre>

<p><img alt="" src="../figures/Rt_3_1.png" /> <img alt="" src="../figures/Rt_3_2.png" /> <img alt="" src="../figures/Rt_3_3.png" />
<img alt="" src="../figures/Rt_3_4.png" /> <img alt="" src="../figures/Rt_3_5.png" /> <img alt="" src="../figures/Rt_3_6.png" />
<img alt="" src="../figures/Rt_3_7.png" /> <img alt="" src="../figures/Rt_3_8.png" /> <img alt="" src="../figures/Rt_3_9.png" /></p>
<p>What Systrom did was smooth the new cases before using the Poisson
distribution. He used a window width of $7$ and Gaussian weights with
standard deviation $2$.</p>
<pre><code class="julia">include(&quot;jmd/rtmod.jl&quot;)
σ = 0.25
Plots.closeall()
for w in [3, 7, 11]
  for s in [0.5, 2, 4]
    γ =1/7
    nbp = 0.01
    figs = []
    for gdf in groupby(sdf, :state)
      windowsize = w
      weights = pdf(Normal(0, s), -floor(windowsize/2):floor(windowsize/2))
      weights = weights/sum(weights)
      smoothcases = RT.smoother(gdf.newcases, w=weights)
      p, m, cr = rtpost(smoothcases, γ, σ, x-&gt;pdf(truncated(Gamma(4,1),0,8), x),
                        (λ,x)-&gt;pdf(Poisson(λ),x))
      f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=&quot;Rₜ&quot;)
      f = hline!(f,[1.0])
      figs = vcat(figs, f)
    end
    l = @layout [a{.1h};grid(1,1)]
    display(plot(plot(annotation=(0.5,0.5, &quot;Poisson &amp; σ=$σ, s=$s, w=$w&quot;), framestyle = :none),
                 plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false))
  end
end
</code></pre>

<p><img alt="" src="../figures/Rt_4_1.png" /> <img alt="" src="../figures/Rt_4_2.png" /> <img alt="" src="../figures/Rt_4_3.png" />
<img alt="" src="../figures/Rt_4_4.png" /> <img alt="" src="../figures/Rt_4_5.png" /> <img alt="" src="../figures/Rt_4_6.png" />
<img alt="" src="../figures/Rt_4_7.png" /> <img alt="" src="../figures/Rt_4_8.png" /> <img alt="" src="../figures/Rt_4_9.png" /></p>
<p>Here we see that we can get a variety of results depending on the
smoothing used. All of these posteriors ignore the uncertainty in the
choice of smoothing parameters (and procedure).</p>
<h1 id="an-alternative-approach">An alternative approach<a class="headerlink" href="#an-alternative-approach" title="Permanent link">&para;</a></h1>
<p>Here we follow an approach similar in spirit to Systrom, with a few
modifications and additions. The primary modification is that we alter
the model of $k_t|k_{t-1}, R_t$ to allow measurement error in both $k_t$
and $k_{t-1}$. We make four additions. First, we utilize data on
movement and business operations as auxillary noisy measures of $R_t$.
Second, we allow state policies to shift the mean of $R_t$. Third, we
combine data from all states to improve precision in each. Fourth, we
incorporate testing numbers into the data.</p>
<p>As above, we begin from the approximation</p>
<p>
<script type="math/tex; mode=display">
k^*_{s,t} \approx k^*_{s,t-1} \frac{\tau_{s,t}}{\tau_{s,t-1}} e^{\gamma(R_{st} - 1)})
</script>
</p>
<p>where $k^*$ is the true, unobserved number of new cases. Taking logs and
rearranging we have</p>
<p>
<script type="math/tex; mode=display">
\log(k^*_{s,t}) - \log(k^*_{s,t-1}) = \gamma(R_{s,t} - 1) +
\log\left(\frac{\tau_{s,t}}{\tau_{s,t-1}}\right)
</script>
</p>
<p>Let $k_{s,t}$ be the noisy observed value of $k^*_{s,t}$, then</p>
<p>
<script type="math/tex; mode=display">
\log(k_{s,t}) - \log(k_{s,t-1}) = \gamma(R_{s,t} - 1) +
\log\left(\frac{\tau_{s,t}}{\tau_{s,t-1}}\right) - \epsilon_{s,t} + \epsilon_{s,t-1}
</script>
</p>
<p>where <script type="math/tex; mode=display">
 \log(k^*_{s,t}) =  \log(k_{s,t}) +\epsilon_{s,t}
</script> and $\epsilon_{s,t}$ is measurement error.</p>
<p>With appropriate assumptions on $\epsilon$, $\tau$, $R$ and other
observables, we can then use regression to estimate $R$.</p>
<p>As a simple example, let’s assume</p>
<ol>
<li>$R_{s,t} = R_{s,0} + \alpha d_{s,t}$ where $d_{s,t}$ are indicators
    for NPI’s being in place.</li>
<li>That $\tau_{s,t}$ is constant over time for each $s$</li>
<li>$E[\epsilon_{s,t} - \epsilon_{s,t-1}|d] = 0$ and
    $\epsilon_{s,t} - \epsilon_{s,t-1}$ is uncorrelated over time (just
    to simplify; this is not a good assumption).</li>
</ol>
<p>```{=html}
<!-- --></p>
<pre><code>``` julia
using GLM, RegressionTables
pvars = [Symbol(&quot;Stay.at.home..shelter.in.place&quot;),
         Symbol(&quot;State.of.emergency&quot;),
         Symbol(&quot;Date.closed.K.12.schools&quot;),
         Symbol(&quot;Closed.gyms&quot;),
         Symbol(&quot;Closed.movie.theaters&quot;),
         Symbol(&quot;Closed.day.cares&quot;),
         Symbol(&quot;Date.banned.visitors.to.nursing.homes&quot;),
         Symbol(&quot;Closed.non.essential.businesses&quot;),
         Symbol(&quot;Closed.restaurants.except.take.out&quot;)]
sdf = copy(df)
for p in pvars
  sdf[!,p] = by(sdf, :state, (:date, p) =&gt; x-&gt;(!ismissing(unique(x[p])[1]) .&amp; (x.date .&gt;= unique(x[p])[1]))).x1
end
sdf = sort(sdf, [:state, :date])
sdf[!,:newcases] = by(sdf, :state, newcases = Symbol(&quot;cases.nyt&quot;) =&gt; x-&gt;(vcat(missing, diff(x))))[!,:newcases]
sdf[!,:dlogk] = by(sdf, :state, dlogk = :newcases =&gt; x-&gt;(vcat(missing, diff(log.(max.(x,0.1))))))[!,:dlogk]

fmla = FormulaTerm(Term(:dlogk), Tuple(Term.(vcat(pvars,:state))))
reg = lm(fmla, sdf)
regtable(reg, renderSettings=asciiOutput())
</code></pre>

<pre><code>-----------------------------------------------
                                         dlogk 
                                        -------
                                            (1)
-----------------------------------------------
(Intercept)                               0.185
                                        (0.184)
Stay.at.home..shelter.in.place           -0.057
                                        (0.067)
State.of.emergency                        0.037
                                        (0.080)
Date.closed.K.12.schools                -0.174*
                                        (0.087)
Closed.gyms                              -0.086
                                        (0.129)
Closed.movie.theaters                     0.074
                                        (0.136)
Closed.day.cares                         -0.012
                                        (0.063)
Date.banned.visitors.to.nursing.homes     0.042
                                        (0.052)
Closed.non.essential.businesses           0.040
                                        (0.079)
Closed.restaurants.except.take.out       -0.006
                                        (0.114)
state: Alaska                            -0.032
                                        (0.249)
state: Arizona                           -0.009
                                        (0.214)
state: Arkansas                           0.005
                                        (0.247)
state: California                        -0.032
                                        (0.214)
state: Colorado                          -0.014
                                        (0.239)
state: Connecticut                        0.051
                                        (0.243)
state: Delaware                          -0.005
                                        (0.247)
state: District of Columbia               0.065
                                        (0.242)
state: Florida                            0.078
                                        (0.235)
state: Georgia                            0.073
                                        (0.236)
state: Hawaii                            -0.031
                                        (0.240)
state: Idaho                             -0.058
                                        (0.250)
state: Illinois                          -0.020
                                        (0.213)
state: Indiana                            0.062
                                        (0.241)
state: Iowa                              -0.040
                                        (0.243)
state: Kansas                             0.071
                                        (0.242)
state: Kentucky                           0.046
                                        (0.241)
state: Louisiana                         -0.012
                                        (0.244)
state: Maine                             -0.021
                                        (0.249)
state: Maryland                           0.091
                                        (0.239)
state: Massachusetts                      0.011
                                        (0.216)
state: Michigan                           0.119
                                        (0.246)
state: Minnesota                          0.068
                                        (0.241)
state: Mississippi                        0.105
                                        (0.247)
state: Missouri                           0.091
                                        (0.242)
state: Montana                           -0.055
                                        (0.250)
state: Nebraska                           0.039
                                        (0.225)
state: Nevada                             0.077
                                        (0.239)
state: New Hampshire                      0.007
                                        (0.236)
state: New Jersey                         0.106
                                        (0.238)
state: New Mexico                         0.042
                                        (0.247)
state: New York                           0.136
                                        (0.235)
state: North Carolina                     0.095
                                        (0.237)
state: North Dakota                       0.069
                                        (0.247)
state: Ohio                               0.135
                                        (0.244)
state: Oklahoma                           0.083
                                        (0.240)
state: Oregon                             0.038
                                        (0.233)
state: Pennsylvania                       0.072
                                        (0.241)
state: Rhode Island                       0.079
                                        (0.235)
state: South Carolina                     0.082
                                        (0.241)
state: South Dakota                       0.010
                                        (0.246)
state: Tennessee                          0.093
                                        (0.239)
state: Texas                             -0.004
                                        (0.222)
state: Utah                               0.024
                                        (0.231)
state: Vermont                           -0.027
                                        (0.242)
state: Virginia                           0.052
                                        (0.242)
state: Washington                        -0.032
                                        (0.212)
state: West Virginia                      0.025
                                        (0.257)
state: Wisconsin                         -0.008
                                        (0.218)
state: Wyoming                            0.003
                                        (0.247)
-----------------------------------------------
Estimator                                   OLS
-----------------------------------------------
N                                         2,621
R2                                        0.007
-----------------------------------------------
</code></pre>
<p>From this we get that if we assume $\gamma = 1/7$, then the the baseline
estimate of $R$ in Illinois is $7(0.046 + 0.034) + 1\approx 1.56$ with a
stay at home order, $R$ in Illinois becomes
$7(0.046 + 0.035 - 0.147) + 1 \approx 0.53$.</p>
<p>Some of the policies have positive coefficient estimates, which is
strange. This is likely due to assumption 1 being incorrect. There is
likely an unobserved component of $R_{s,t}$ that is positively
correlated with policy indicators.</p>
<h1 id="state-space-model">State space model<a class="headerlink" href="#state-space-model" title="Permanent link">&para;</a></h1>
<p>A direct analog of Systrom’s approach is to treat $R_{s,t}$ as an
unobserved latent process. Specifically, we will assume that <script type="math/tex; mode=display">
\begin{align*}
\tilde{R}_{s,0} & \sim N(\alpha_0, \sigma^2_{R,0}) \\
\tilde{R}_{s,t} & = \rho \tilde{R}_{s,t} + u_{s,t} \;,\; u_{s,t} \sim
N(0, \sigma^2_R) \\
R_{s,t} = \alpha + \tilde{R}_{s,t}
\Delta \log(k)_{s,t} & = \gamma (R_{s,t} - 1) + \epsilon_{s,t} -
\epsilon_{s,t-1} \;, \; \epsilon_{s,t} \sim N(0, \sigma^2_k)
\end{align*}
</script>
</p>
<p>Note that the Poisson assumption on the distribution of $k_{s,t}$ used
by Systrom implies an extremely small $\sigma^2_k$, since the variance
of log Poisson($\lambda$) distribution is $1/\lambda$.</p>
<p>If $\epsilon_{s,t} - \epsilon_{s,t-1}$ weere independent over $t$, we
could compute the likelihood and posteriors of $R_{s,t}$ through the
standard Kalman filter. Of course, $\epsilon_{s,t} - \epsilon_{s,t-1}$
is not independent over time, so we must adjust the Kalman filter
accordingly. We follow the approach of (Kurtz and Lin
<a href="#ref-kurtz2019">2019</a>) to make this adjustment.</p>
<div class="admonition question">
<p class="admonition-title">Question</p>
<p>Is there a better reference? I&rsquo;m sure someone did this much
earlier than 2019&hellip;</p>
</div>
<p>We estimate the parameters using data from US states. We set time 0 as
the first day in which a state had at least 10 cumulative cases. We then
compute posteriors for the parameters by MCMC. We place the following
priors on the parameters.</p>
<pre><code class="julia">using Distributions, TransformVariables, DynamicHMC, MCMCChains, Plots, StatsPlots,
  LogDensityProblems, Random, LinearAlgebra, JLD2
include(&quot;jmd/rtmod.jl&quot;)

rlo=-1
rhi=1.1
priors = (γ = truncated(Normal(1/7,1/7), 1/28, 1/1),
          σR0 = truncated(Normal(1, 3), 0, Inf),
          α0 = MvNormal([1], 3),
          σR = truncated(Normal(0.25,1),0,Inf),
          σk = truncated(Normal(0.1, 5), 0, Inf),
          α = MvNormal([1], 3),
          ρ = Uniform(rlo, rhi))
</code></pre>

<pre><code>(γ = Truncated(Normal{Float64}(μ=0.14285714285714285, σ=0.14285714285714285
), range=(0.03571428571428571, 1.0)), σR0 = Truncated(Normal{Float64}(μ=1.0
, σ=3.0), range=(0.0, Inf)), α0 = IsoNormal(
dim: 1
μ: [1.0]
Σ: [9.0]
)
, σR = Truncated(Normal{Float64}(μ=0.25, σ=1.0), range=(0.0, Inf)), σk = Tr
uncated(Normal{Float64}(μ=0.1, σ=5.0), range=(0.0, Inf)), α = IsoNormal(
dim: 1
μ: [1.0]
Σ: [9.0]
)
, ρ = Uniform{Float64}(a=-1.0, b=1.1))
</code></pre>
<p>The estimation is fast and the chain appears to mix well.</p>
<pre><code class="julia">reestimate=false
sdf = sort(sdf, (:state, :date));
dlogk = [filter(x-&gt;((x.state==st) .&amp;
                    (x.cases .&gt;=10)),
                sdf).dlogk for st in unique(sdf.state)];
dates = [filter(x-&gt;((x.state==st) .&amp;
                    (x.cases .&gt;=10)),
                sdf).date for st in unique(sdf.state)];

mdl = RT.RtRW(dlogk, priors)
trans = as( (γ = asℝ₊, σR0 = asℝ₊, α0 = as(Array, 1),
             σR = asℝ₊, σk = asℝ₊, α = as(Array,1),
             ρ=as(Real, rlo, rhi)) )
P = TransformedLogDensity(trans, mdl)
∇P = ADgradient(:ForwardDiff, P)
p0 = (γ = 1/7, σR0=1.0, α0=[4.0],σR=0.25, σk=2.0, α=[1], ρ=0.9)
x0 = inverse(trans,p0)
@time LogDensityProblems.logdensity_and_gradient(∇P, x0);
</code></pre>

<pre><code>1.901263 seconds (3.89 M allocations: 190.595 MiB)
</code></pre>
<pre><code class="julia">rng = MersenneTwister()
steps = 100
warmup=default_warmup_stages(local_optimization=nothing,
                             stepsize_search=nothing,
                             init_steps=steps, middle_steps=steps,
                             terminating_steps=2*steps,  doubling_stages=3, M=Symmetric)
x0 = x0
if (!isfile(&quot;rt1.jld2&quot;) || reestimate)
  res = DynamicHMC.mcmc_keep_warmup(rng, ∇P, 2000;initialization = (q = x0, ϵ=0.1),
                                    reporter = LogProgressReport(nothing, 25, 15),
                                    warmup_stages =warmup);
  post = transform.(trans,res.inference.chain)
  @save &quot;rt1.jld2&quot; post
end
@load &quot;rt1.jld2&quot; post
p = post[1]
vals = hcat([vcat([length(v)==1 ? v : vec(v) for v in values(p)]...) for p in post]...)'
vals = reshape(vals, size(vals)..., 1)
names = vcat([length(p[s])==1 ? String(s) : String.(s).*&quot;[&quot;.*string.(1:length(p[s])).*&quot;]&quot; for s in keys(p)]...)
cc = MCMCChains.Chains(vals, names)
display(cc)
</code></pre>

<pre><code>Object of type Chains, with data of type 2000×7×1 reshape(::Adjoint{Float64
,Array{Float64,2}}, 2000, 7, 1) with eltype Float64

Iterations        = 1:2000
Thinning interval = 1
Chains            = 1
Samples per chain = 2000
parameters        = γ, σR0, α0, σR, σk, α, ρ

2-element Array{ChainDataFrame,1}

Summary Statistics
  parameters    mean     std  naive_se    mcse        ess   r_hat
  ──────────  ──────  ──────  ────────  ──────  ─────────  ──────
           γ  0.0931  0.0381    0.0009  0.0023   194.3582  1.0034
         σR0  1.1247  0.7666    0.0171  0.0361   515.4800  1.0000
          α0  5.0630  1.8530    0.0414  0.0870   344.8905  1.0025
          σR  0.0957  0.0855    0.0019  0.0022  1213.6056  0.9996
          σk  0.5685  0.0087    0.0002  0.0002  2659.9467  0.9999
           α  0.6724  0.4373    0.0098  0.0181   498.8290  1.0004
           ρ  0.9337  0.0144    0.0003  0.0005   672.3568  0.9997

Quantiles
  parameters     2.5%   25.0%   50.0%   75.0%   97.5%
  ──────────  ───────  ──────  ──────  ──────  ──────
           γ   0.0438  0.0648  0.0828  0.1129  0.1883
         σR0   0.0525  0.5365  0.9818  1.5750  2.8887
          α0   2.2124  3.6443  4.8462  6.2334  9.1984
          σR   0.0030  0.0336  0.0725  0.1313  0.3281
          σk   0.5519  0.5626  0.5684  0.5744  0.5861
           α  -0.4498  0.4618  0.7480  0.9520  1.3733
           ρ   0.9037  0.9249  0.9350  0.9435  0.9598
</code></pre>
<pre><code class="julia">display(plot(cc))
</code></pre>

<p><img alt="" src="../figures/Rt_7_1.png" /></p>
<p>The posterior for the initial distribution of $R_{0,s}$ is not very
precise. The other parameters have fairly precise posteriors. Systrom
fixed all these parameters, except $\sigma_R$, which he estimated by
maximum likelihood to be 0.25. In these posteriors, a 95% credible
region for $\sigma_R$ contains his estimate. The posterior of $\rho$ is
not far from his imposed value of $1$, although $1$ is out of the 95%
credible region. A 95% posterior region for $\gamma$ contains Systrom’s
calibrated value of $1/7$.</p>
<p>It is worth noting that the estimate of $\sigma_k$ is large compared to
$\sigma_r$. This will cause new observations of $\Delta \log k$ will
have a small effect on the posterior mean of $R$.</p>
<p>Given values of the parameters, we can compute state and time specific
posterior estimates of $R_{s,t}$.</p>
<pre><code class="julia">states = unique(sdf.state)
s = findfirst(states.==&quot;New York&quot;)
figr = RT.plotpostr(dates[s],dlogk[s],post, ones(length(dlogk[s]),1), [1])
display(plot(figr, ylim=(-1,10)))
</code></pre>

<p><img alt="" src="../figures/Rt_8_1.png" /></p>
<p>This figure shows the posterior distribution of $R_{s,t}$ in New York.
The black line is the posterior mean. The dark grey region is the
average (over model parameters) of a 90% credible region conditional on
the model parameters. This is comparable to what Systrom (and many
others) report, and ignores uncertainty in the model parameters. The
light grey region is a 90% credile region taking into account parameter
uncertainty. The points and error bars are mean and 90% credible regions
for <script type="math/tex; mode=display">
\Delta \log k_{t}/\gamma + 1 = R_{t} + \epsilon_t/\gamma
</script>
</p>
<h2 id="posteriors-for-additional-states">Posteriors for additional states<a class="headerlink" href="#posteriors-for-additional-states" title="Permanent link">&para;</a></h2>
<pre><code class="julia">states_to_plot = [&quot;New Jersey&quot;,&quot;Massachusetts&quot;,&quot;California&quot;,
                  &quot;Georgia&quot;,&quot;Illinois&quot;,&quot;Michigan&quot;,
                  &quot;Ohio&quot;,&quot;Wisconsin&quot;,&quot;Washington&quot;]
S = length(states_to_plot)
figs = fill(plot(), 9*(S ÷ 9 + 1))
for (i,st) in enumerate(states_to_plot)
  s = findfirst(states.==st)
  figr = RT.plotpostr(dates[s],dlogk[s],post, ones(length(dlogk[s]),1),[1])
  l = @layout [a{.1h}; grid(1,1)]
  figs[i] = plot(plot(annotation=(0.5,0.5, st), framestyle = :none),
                 plot(figr, ylim=(-1,10)), layout=l)
  if ((i % 9) ==0 || ( i==length(states_to_plot)))
    display(plot(figs[(i-8):i]..., layout=(3,3), reuse=false))
  end
end
</code></pre>

<p><img alt="" src="../figures/Rt_9_1.png" /></p>
<p>We can see that the posteriors vary very little from state to state. The
model picks up a general downward trend in $\Delta \log k$ through the
slightly less than 1 estimate of $\rho$. This drives the posteriors of
$R_{s,t}$ in every state to decrease over time. Since
$\sigma_k &gt;&gt; \sigma_R$, the actual realizations of $\Delta \log k$ do
not affect the state-specific posteriors very much.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>I also tried fixing $\rho=1$. This gives similar results in terms
of $\sigma_k &gt;&gt; \sigma_R$, and gives a posterior for $R_{s,t}$ that is
approximately constant over time.</p>
</div>
<div class="references hanging-indent" id="refs">
<div id="ref-bettencourt2008">
<p>Bettencourt, Ruy M., Luís M. A. AND Ribeiro. 2008. “Real Time Bayesian
Estimation of the Epidemic Potential of Emerging Infectious Diseases.”
<em>PLOS ONE</em> 3 (5): 1–9. <a href="https://doi.org/10.1371/journal.pone.0002185">https://doi.org/10.1371/journal.pone.0002185</a>.</p>
</div>
<div id="ref-kurtz2019">
<p>Kurtz, Vince, and Hai Lin. 2019. “Kalman Filtering with Gaussian
Processes Measurement Noise.”</p>
</div>
</div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
                <p>Paul Schrimpf</p>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../assets/mathjaxhelper.js" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>

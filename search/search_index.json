{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CovidSEIR.jl \u00b6 Index \u00b6 CovidSEIR.countrymodel CovidSEIR.covidjhudata CovidSEIR.odeSEIR CovidSEIR.paramvars CovidSEIR.paramvec CovidSEIR.plotvars CovidSEIR.priorreport CovidSEIR.simtrajectories CovidSEIR.systemvars CovidSEIR.systemvec","title":"Package Docs"},{"location":"#covidseirjl","text":"","title":"CovidSEIR.jl"},{"location":"#index","text":"CovidSEIR.countrymodel CovidSEIR.covidjhudata CovidSEIR.odeSEIR CovidSEIR.paramvars CovidSEIR.paramvec CovidSEIR.plotvars CovidSEIR.priorreport CovidSEIR.simtrajectories CovidSEIR.systemvars CovidSEIR.systemvec","title":"Index"},{"location":"Rt/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License Model \u00b6 Following Kevin Systrom , we adapt the approach of (Bettencourt 2008 ) to compute real-time rolling estimates of pandemic parameters. (Bettencourt 2008 ) begin from a SIR model, \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I \\\\ \\dot{R} & = \\gamma I \\end{align*} To this we add the possibility that not all cases are known. Cases get get detected at rate $I$, so cumulative confirmed cases, $C$, evolves as \\dot{C} = \\tau I Question Should we add other states to this model? If yes, how? I think using death and hospitalization numbers in estimation makes sense. The number of new confirmed cases from time $t$ to $t+\\delta$ is then: We will allow for the testing rate, $\\tau$, and infection rate, $\\beta$, to vary over time. k_t \\equiv \\frac{C(t+\\delta) - C(t)}{\\delta} = \\int_t^{t+\\delta} \\tau(s) I(s) ds \\approx \\tau(t) I(t) As in (Bettencourt 2008 ), \\begin{align*} I(t) = & I(t-\\delta) \\int_{t-\\delta}^{t} e^{\\frac{S(s)}{N} \\beta(s) - \\gamma} ds \\\\ \\approx & I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*} Note The reproductive number is: $R_t \\equiv \\frac{S(t)}{N}\\frac{\\beta(t)}{\\gamma}$. Substituting the expression for $I_t$ into $k_t$, we have \\begin{align*} k_t \\approx & \\tau(t) I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma\\right)} \\\\ \\approx & k_{t-\\delta} \\frac{\\tau(t)}{\\tau(t-\\delta)} e^{\\delta \\left(\\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*} Data \u00b6 We use the same data as the US state model . The data combines information on Daily case counts and deaths from JHU CSSE Daily Hospitalizations, recoveries, and testing from the Covid Tracking Project Covid related policy changes from Raifman et al Movements from Google Mobility Reports Hourly workers from Hoembase Statistical Model \u00b6 The above theoretical model gives a deterministic relationship between $k_t$ and $k_{t-1}$ given the parameters. To bring it to data we must add stochasticity. Systrom\u2019s approach \u00b6 First we describe what Systrom does. He assumes that $R_{0} \\sim Gamma(4,1)$. Then for $t=1, \u2026, T$, he computes $P(R_t|k_{t}, k_{t-1}, \u2026 ,k_0)$ iteratively using Bayes\u2019 rules. Specifically, he assumes k_t | R_t, k_{t-1}, ... \\sim Poisson(k_{t-1} e^{\\gamma(R_t - 1)}) and that $R_t$ follows a random walk, so the prior of $R_t | R_{t-1}$ is R_t | R_{t-1} \\sim N(R_{t-1}, \\sigma^2) so that P(R_t|k_{t}, k_{t-1}, ... ,k_0) = \\frac{P(k_t | R_t, k_{t-1}) P(R_t | R_{t-1}) P(R_{t-1} | k_{t-1}, ...)} {P(k_t)} Note that this computes posteriors of $R_t$ given current and past cases. Future cases are also informative of $R_t$, and you could instead compute $P(R_t | k_0, k_1, \u2026, k_T)$. The notebook makes some mentions of Gaussian processes. There\u2019s likely some way to recast the random walk assumption as a Gaussian process prior (the kernel would be $\\kappa(t,t\u2019) = \\min{t,t\u2019} \\sigma^2$), but that seems to me like an unusual way to describe it. Code \u00b6 Let\u2019s see how Systrom\u2019s method works. First the load data. using DataFrames, Plots, StatsPlots, CovidSEIR Plots.pyplot() df = CovidSEIR.statedata() df = filter(x->x.fips<60, df) # focus on 10 states with most cases as of April 1, 2020 sdf = select(df[df[!,:date].==Dates.Date(\"2020-04-01\"),:], :cases, :state) |> x->sort(x,:cases, rev=true) states=sdf[1:10,:state] sdf = select(filter(r->r[:state] \u2208 states, df), :cases, :state, :date) sdf = sort(sdf, [:state, :date]) sdf[!,:newcases] = by(sdf, :state, newcases = :cases => x->(vcat(missing, diff(x))))[!,:newcases] figs = [] for gdf in groupby(sdf, :state) @show unique(gdf.state) f = @df gdf plot(:date, :newcases, legend=:none, linewidth=2, title=unique(gdf.state)[1]) global figs = vcat(figs,f) end unique(gdf.state) = [\"California\"] unique(gdf.state) = [\"Florida\"] unique(gdf.state) = [\"Illinois\"] unique(gdf.state) = [\"Louisiana\"] unique(gdf.state) = [\"Massachusetts\"] unique(gdf.state) = [\"Michigan\"] unique(gdf.state) = [\"New Jersey\"] unique(gdf.state) = [\"New York\"] unique(gdf.state) = [\"Pennsylvania\"] unique(gdf.state) = [\"Washington\"] display(plot(figs[1:9]..., layout=(3,3))) From this we can see that new cases are very noisy. This is especially problematic when cases jump from near 0 to very high values, such as in Illinois. The median value of and variance of new cases, $k_t$, are both $k_{t-1} e^{\\gamma(R_t - 1)}$. Only huge changes in $R_t$ can rationalize huge jumps in new cases. Let\u2019s compute posteriors for each state. using Interpolations, Distributions function rtpost(cases, \u03b3, \u03c3, prior0, casepdf) (rgrid, postgrid, ll) = rtpostgrid(cases)(\u03b3, \u03c3, prior0, casepdf) w = rgrid[2] - rgrid[1] T = length(cases) p = [LinearInterpolation(rgrid, postgrid[:,t]) for t in 1:T] coverage = 0.9 cr = zeros(T,2) mu = vec(rgrid' * postgrid*w) for t in 1:T l = findfirst(cumsum(postgrid[:,t].*w).>(1-coverage)/2) h = findlast(cumsum(postgrid[:,t].*w).<(1-(1-coverage)/2)) if !(l === nothing || h === nothing) cr[t,:] = [rgrid[l], rgrid[h]] end end return(p, mu, cr) end function rtpostgrid(cases) # We'll compute the posterior on these values of R_t rlo = 0 rhi = 8 steps = 500 rgrid = range(rlo, rhi, length=steps) \u0394grid = range(0.05, 0.95, length=10) w = rgrid[2] - rgrid[1] dr = rgrid .- rgrid' fn=function(\u03b3, \u03c3, prior0, casepdf) prr = pdf.(Normal(0,\u03c3), dr) # P(r_{t+1} | r_t) for i in 1:size(prr,1) prr[i, : ] ./= sum(prr[i,:].*w) end postgrid = Matrix{typeof(\u03c3)}(undef,length(rgrid), length(cases)) # P(R_t | k_t, k_{t-1},...) like = similar(postgrid, length(cases)) for t in 1:length(cases) if (t==1) postgrid[:,t] .= prior0.(rgrid) else if (cases[t-1]===missing || cases[t]===missing) pkr = 1 # P(k_t | R_t) else \u03bb = max(cases[t-1],1).* exp.(\u03b3 .* (rgrid .- 1)) #r = \u03bb*nbp/(1-nbp) #pkr = pdf.(NegativeBinomial.(r,nbp), cases[t]) pkr = casepdf.(\u03bb, cases[t]) if (all(pkr.==0)) @warn \"all pkr=0\" @show t, cases[t], cases[t-1] pkr .= 1 end end postgrid[:,t] = pkr.*(prr*postgrid[:,t-1]) like[t] = sum(postgrid[:,t].*w) postgrid[:,t] ./= max(like[t], 1e-15) end end ll = try sum(log.(like)) catch -710*length(like) end return((rgrid, postgrid, ll)) end return(fn) end for \u03c3 in [0.1, 0.25, 1] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l)) end (t, cases[t], cases[t - 1]) = (72, 2052, 215) (t, cases[t], cases[t - 1]) = (77, 9, 1003) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (55, 352, 2) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (72, 2052, 215) (t, cases[t], cases[t - 1]) = (77, 9, 1003) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (55, 352, 2) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (72, 2052, 215) (t, cases[t], cases[t - 1]) = (77, 9, 1003) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (55, 352, 2) (t, cases[t], cases[t - 1]) = (54, -39, 74) In these results, what is happening is that when new cases fluctuate too much, the likelihood is identically 0, causing the posterior calculation to break down. Increasing the variance of changes in $R_t$, widens the posterior confidence intervals, but does not solve the problem of vanishing likelihoods. One thing that can \u201csolve\u201d the problem is choosing a distribution of $k_t | \\lambda, k_{t-1}$ with higher variance. The negative binomial with parameters $\\lambda p/(1-p)$ and $p$ has mean $\\lambda$ and variance $\\lambda/p$. \u03b3 =1/7 \u03c3 = 0.25 Plots.closeall() for \u03c3 in [0.1, 0.25, 0.5] for nbp in [0.5, 0.1, 0.01] figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(NegativeBinomial(\u03bb*nbp/(1-nbp), nbp),x)); f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Negative binomial, p=$nbp, & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) What Systrom did was smooth the new cases before using the Poisson distribution. He used a window width of $7$ and Gaussian weights with standard deviation $2$. using RollingFunctions \u03c3 = 0.25 Plots.closeall() for w in [3, 7, 11] for s in [0.5, 2, 4] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) windowsize = w weights = pdf(Normal(0, s), -floor(windowsize/2):floor(windowsize/2)) weights = weights/sum(weights) smoothcases = Int.(round.(runmean(gdf.newcases[2:end], windowsize, weights*windowsize))) p, m, cr = rtpost(smoothcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3, s=$s, w=$w\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end (t, cases[t], cases[t - 1]) = (54, -4, 68) (t, cases[t], cases[t - 1]) = (56, -4, 68) (t, cases[t], cases[t - 1]) = (58, -4, 68) Here we see that we can get a variety of results depending on the smoothing used. All of these posteriors ignore the uncertainty in the choice of smoothing parameters (and procedure). An alternative approach \u00b6 Here we follow an approach similar in spirit to Systrom, with a few additions. First, we utilize data on movement and business operations as auxillary noisy measures of $R_t$. Second, we allow state policies to shift the mean of $R_t$. Third, we combine data from all states to improve precision in each. Fourth, we incorporate testing numbers into the data. As above, we assume that k_{st} | R_{st}, k_{s,t-1}, ... \\sim Poisson(k_{s,t-1} \\frac{\\tau_{s,t}}{\\tau_{s,t-1}} e^{\\gamma(R_{st} - 1)}) Question Any distribution with mean $k_{t-1} \\frac{\\tau{t}}{\\tau{t-1}} e^{\\gamma(R_t - 1)}$ makes sense here. What other choice could incorporate measurement error so that cases don\u2019t need to be smoothed in advance? We will allow state policies, $d_{s,t}$ to affect the mean of $R_t$. Specifically, we\u2019ll assume that R_{st} | R_{s,t-1}, d_{st} \\sim N(\\alpha_r R_{t-1} + d_{s,t} \\alpha, \\sigma^2) Measures of movement and business operations are used as noisy measures of $R_{s,t}$ m_{s,t} ~ N(\\lambda_r R_{s,t} + x_{st} \\lambda, \\Sigma_m) where $x_{st}$ could include e.g. state demographics and day of week indicators. Question Should $x_{st}$ include policies? I think yes. Question What to do about $\\tau$? One idea is to assume $\\frac{\\tau_{s,t}}{\\tau_{s,t-1}}$ is a function of test numbers. However, numbers of tests are likely responding to policies, $d_{st}$ and cases $k_{st}$. The parameters $\\gamma$, $\\alpha$, $\\lambda$, $\\sigma$, and $\\Sigma_m$ are assumed to be common across states. Code \u00b6 The model using Turing, CovidSEIR, Plots, PrettyTables, Dates using LinearAlgebra: dot, diagm, Symmetric, I @model rt(cases, m, d, x, ::Type{Rtype}=Float64) where {Rtype <: Real} = begin # Priors \u03b3 ~ truncated(Normal(1/7, 1/2), 1/21, 1/3) \u03c3 ~ truncated(Normal(0.25,1), 1e-6, Inf) meanR0 ~ truncated(Normal(3, 2), 0, Inf) sigR0 ~ truncated(Normal(1,1), 1e-2, Inf) \u03b1R ~ truncated(Normal(0.5, 2), -0.9, 0.9) \u03b1 ~ MvNormal(zeros(size(d, 1)), 1.0) \u03bbR ~ MvNormal(zeros(size(m, 1)), 1.0) \u03bb ~ MvNormal(zeros(size(m,1)*size(x,1)), 1.0) \u03bb = reshape(\u03bb, size(m,1), size(x,1)) J = size(m,1) #Cm ~ LKJ(J, 2.0) #m = diagm(ones(J)) sm ~ MvNormal(zeros(J), 1) \u03a3m = diagm(exp.(sm)) + I*1e-4 #\u03a3m = Cm.*(exp.(sm)*exp.(sm)') #\u03a3m ~ Wishart(J+2, diagm(ones(J))*1/(2*0.001)) if (cases === missing) # for simulating the model cases = Matrix{Rtype}(undef, T, S) end J, T, S = size(m) @assert (T,S) == size(cases) @assert size(x,2) == T && size(d,2) == T @assert size(x,3) == S && size(d,3) == S R = Matrix{Rtype}(undef, T, S) e = Matrix{Rtype}(undef, T, S) for s in 1:S R[1,s] = meanR0 e[1,s] ~ Normal(0, sigR0) for t in 2:T e[t,s] ~ Normal(\u03b1R*e[t-1,s], \u03c3) R[t,s] = e[t,s] + dot(\u03b1, d[:,t,s]) #R[t,s] ~ truncated(Normal(\u03b1R*R[t-1,s] + dot(\u03b1,d[:,t,s]), \u03c3), 0, 20) if (t>2) # cases[1,s] is missing because cases is the diff of cumulative cases meank = max(cases[t-1, s], 1e-1)*exp(\u03b3*(R[t,s]-1)) #@show t, meank, cases[t-1,s], R[t,s], meanR0, sigR0, \u03b1R cases[t, s] ~ Poisson(meank) #cases[t,s] ~ truncated(Normal(meank, meank), 0, Inf) end if !any(ismissing.(m[:,t,s])) m[:,t,s] ~ MvNormal(\u03bbR*R[t,s] + \u03bb*x[:,t,s], Symmetric(\u03a3m)) end end end return(cases, R) # return only matters when simulating model end Prepare the data. df = CovidSEIR.statedata() df = df[df[!,:fips].<60,:] # get ride of non-states (AS, GU, etc) df[!, :weekend] = 1*(Dates.dayofweek.(df[!,:date]) .>= 6) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), #Symbol(\"Closed.day.cares\"), #Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] dvars= [:weekend] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, #:parks_percent_change_from_baseline, #:transit_stations_percent_change_from_baseline, #:workplaces_percent_change_from_baseline, #:residential_percent_change_from_baseline, #:percentchangehours, :percentchangebusinesses] xvars = dvars states = unique(df[!,:state]) dates = sort(unique(df[!,:date])) S = length(states) T = length(dates) d = Array{Float64,3}(undef, length(dvars) + length(pvars), T, S) x = Array{Float64,3}(undef, length(xvars) + length(pvars), T, S) m = Array{Union{Missing,Float64},3}(missing, length(mvars), T, S) cc = Matrix{Union{Missing,Float64}}(missing, T,S) cases = Matrix{Union{Missing,Float64}}(missing, T,S) for (s, st) in enumerate(states) for (t, dt) in enumerate(dates) inc = findall((df[!,:state] .== st) .& (df[!,:date] .==dt)) @assert length(inc)==1 i = inc[1] p = convert(Array, df[i,pvars]) .< dt p[ismissing.(p)] .= false d[:,t,s] .= vcat(p, convert(Array, df[i, dvars])) x[:,t,s] .= vcat(p, convert(Array, df[i, xvars])) m[:,t,s] .= convert(Array, df[i, mvars])./100 cc[t,s] = df[i, :cases] if (t>1) cases[t,s] = max(0.0,cc[t,s] - cc[t-1,s]) end end end Estimation mdl = rt(cases, m, d, x) #@time chain=Turing.sample(mdl, HMC(1e-6, 3), 50); #using Turing.Variational #q0 = Variational.meanfield(mdl); #advi = ADVI(10, 10_000) #@time q = vi(mdl, ADVI(10,100), q0, optimizer=Variational.DecayedADAGrad(1e-2, 1.1, 0.9)); #chain = Turing.sample(mdl, NUTS(500, 0.65, max_depth=4, init_\u03f5=1e-4), 1000) Bettencourt, Ruy M., Lu\u00eds M. A. AND Ribeiro. 2008. \u201cReal Time Bayesian Estimation of the Epidemic Potential of Emerging Infectious Diseases.\u201d PLOS ONE 3 (5): 1\u20139. https://doi.org/10.1371/journal.pone.0002185 .","title":"Reproductive number"},{"location":"Rt/#model","text":"Following Kevin Systrom , we adapt the approach of (Bettencourt 2008 ) to compute real-time rolling estimates of pandemic parameters. (Bettencourt 2008 ) begin from a SIR model, \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\beta I \\\\ \\dot{I} & = \\frac{S}{N} \\beta I - \\gamma I \\\\ \\dot{R} & = \\gamma I \\end{align*} To this we add the possibility that not all cases are known. Cases get get detected at rate $I$, so cumulative confirmed cases, $C$, evolves as \\dot{C} = \\tau I Question Should we add other states to this model? If yes, how? I think using death and hospitalization numbers in estimation makes sense. The number of new confirmed cases from time $t$ to $t+\\delta$ is then: We will allow for the testing rate, $\\tau$, and infection rate, $\\beta$, to vary over time. k_t \\equiv \\frac{C(t+\\delta) - C(t)}{\\delta} = \\int_t^{t+\\delta} \\tau(s) I(s) ds \\approx \\tau(t) I(t) As in (Bettencourt 2008 ), \\begin{align*} I(t) = & I(t-\\delta) \\int_{t-\\delta}^{t} e^{\\frac{S(s)}{N} \\beta(s) - \\gamma} ds \\\\ \\approx & I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*} Note The reproductive number is: $R_t \\equiv \\frac{S(t)}{N}\\frac{\\beta(t)}{\\gamma}$. Substituting the expression for $I_t$ into $k_t$, we have \\begin{align*} k_t \\approx & \\tau(t) I(t-\\delta) e^{\\delta \\left( \\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma\\right)} \\\\ \\approx & k_{t-\\delta} \\frac{\\tau(t)}{\\tau(t-\\delta)} e^{\\delta \\left(\\frac{S(t-\\delta)}{N} \\beta(t-\\delta) - \\gamma \\right)} \\end{align*}","title":"Model"},{"location":"Rt/#data","text":"We use the same data as the US state model . The data combines information on Daily case counts and deaths from JHU CSSE Daily Hospitalizations, recoveries, and testing from the Covid Tracking Project Covid related policy changes from Raifman et al Movements from Google Mobility Reports Hourly workers from Hoembase","title":"Data"},{"location":"Rt/#statistical-model","text":"The above theoretical model gives a deterministic relationship between $k_t$ and $k_{t-1}$ given the parameters. To bring it to data we must add stochasticity.","title":"Statistical Model"},{"location":"Rt/#systroms-approach","text":"First we describe what Systrom does. He assumes that $R_{0} \\sim Gamma(4,1)$. Then for $t=1, \u2026, T$, he computes $P(R_t|k_{t}, k_{t-1}, \u2026 ,k_0)$ iteratively using Bayes\u2019 rules. Specifically, he assumes k_t | R_t, k_{t-1}, ... \\sim Poisson(k_{t-1} e^{\\gamma(R_t - 1)}) and that $R_t$ follows a random walk, so the prior of $R_t | R_{t-1}$ is R_t | R_{t-1} \\sim N(R_{t-1}, \\sigma^2) so that P(R_t|k_{t}, k_{t-1}, ... ,k_0) = \\frac{P(k_t | R_t, k_{t-1}) P(R_t | R_{t-1}) P(R_{t-1} | k_{t-1}, ...)} {P(k_t)} Note that this computes posteriors of $R_t$ given current and past cases. Future cases are also informative of $R_t$, and you could instead compute $P(R_t | k_0, k_1, \u2026, k_T)$. The notebook makes some mentions of Gaussian processes. There\u2019s likely some way to recast the random walk assumption as a Gaussian process prior (the kernel would be $\\kappa(t,t\u2019) = \\min{t,t\u2019} \\sigma^2$), but that seems to me like an unusual way to describe it.","title":"Systrom\u2019s approach"},{"location":"Rt/#code","text":"Let\u2019s see how Systrom\u2019s method works. First the load data. using DataFrames, Plots, StatsPlots, CovidSEIR Plots.pyplot() df = CovidSEIR.statedata() df = filter(x->x.fips<60, df) # focus on 10 states with most cases as of April 1, 2020 sdf = select(df[df[!,:date].==Dates.Date(\"2020-04-01\"),:], :cases, :state) |> x->sort(x,:cases, rev=true) states=sdf[1:10,:state] sdf = select(filter(r->r[:state] \u2208 states, df), :cases, :state, :date) sdf = sort(sdf, [:state, :date]) sdf[!,:newcases] = by(sdf, :state, newcases = :cases => x->(vcat(missing, diff(x))))[!,:newcases] figs = [] for gdf in groupby(sdf, :state) @show unique(gdf.state) f = @df gdf plot(:date, :newcases, legend=:none, linewidth=2, title=unique(gdf.state)[1]) global figs = vcat(figs,f) end unique(gdf.state) = [\"California\"] unique(gdf.state) = [\"Florida\"] unique(gdf.state) = [\"Illinois\"] unique(gdf.state) = [\"Louisiana\"] unique(gdf.state) = [\"Massachusetts\"] unique(gdf.state) = [\"Michigan\"] unique(gdf.state) = [\"New Jersey\"] unique(gdf.state) = [\"New York\"] unique(gdf.state) = [\"Pennsylvania\"] unique(gdf.state) = [\"Washington\"] display(plot(figs[1:9]..., layout=(3,3))) From this we can see that new cases are very noisy. This is especially problematic when cases jump from near 0 to very high values, such as in Illinois. The median value of and variance of new cases, $k_t$, are both $k_{t-1} e^{\\gamma(R_t - 1)}$. Only huge changes in $R_t$ can rationalize huge jumps in new cases. Let\u2019s compute posteriors for each state. using Interpolations, Distributions function rtpost(cases, \u03b3, \u03c3, prior0, casepdf) (rgrid, postgrid, ll) = rtpostgrid(cases)(\u03b3, \u03c3, prior0, casepdf) w = rgrid[2] - rgrid[1] T = length(cases) p = [LinearInterpolation(rgrid, postgrid[:,t]) for t in 1:T] coverage = 0.9 cr = zeros(T,2) mu = vec(rgrid' * postgrid*w) for t in 1:T l = findfirst(cumsum(postgrid[:,t].*w).>(1-coverage)/2) h = findlast(cumsum(postgrid[:,t].*w).<(1-(1-coverage)/2)) if !(l === nothing || h === nothing) cr[t,:] = [rgrid[l], rgrid[h]] end end return(p, mu, cr) end function rtpostgrid(cases) # We'll compute the posterior on these values of R_t rlo = 0 rhi = 8 steps = 500 rgrid = range(rlo, rhi, length=steps) \u0394grid = range(0.05, 0.95, length=10) w = rgrid[2] - rgrid[1] dr = rgrid .- rgrid' fn=function(\u03b3, \u03c3, prior0, casepdf) prr = pdf.(Normal(0,\u03c3), dr) # P(r_{t+1} | r_t) for i in 1:size(prr,1) prr[i, : ] ./= sum(prr[i,:].*w) end postgrid = Matrix{typeof(\u03c3)}(undef,length(rgrid), length(cases)) # P(R_t | k_t, k_{t-1},...) like = similar(postgrid, length(cases)) for t in 1:length(cases) if (t==1) postgrid[:,t] .= prior0.(rgrid) else if (cases[t-1]===missing || cases[t]===missing) pkr = 1 # P(k_t | R_t) else \u03bb = max(cases[t-1],1).* exp.(\u03b3 .* (rgrid .- 1)) #r = \u03bb*nbp/(1-nbp) #pkr = pdf.(NegativeBinomial.(r,nbp), cases[t]) pkr = casepdf.(\u03bb, cases[t]) if (all(pkr.==0)) @warn \"all pkr=0\" @show t, cases[t], cases[t-1] pkr .= 1 end end postgrid[:,t] = pkr.*(prr*postgrid[:,t-1]) like[t] = sum(postgrid[:,t].*w) postgrid[:,t] ./= max(like[t], 1e-15) end end ll = try sum(log.(like)) catch -710*length(like) end return((rgrid, postgrid, ll)) end return(fn) end for \u03c3 in [0.1, 0.25, 1] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l)) end (t, cases[t], cases[t - 1]) = (72, 2052, 215) (t, cases[t], cases[t - 1]) = (77, 9, 1003) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (55, 352, 2) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (72, 2052, 215) (t, cases[t], cases[t - 1]) = (77, 9, 1003) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (55, 352, 2) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (72, 2052, 215) (t, cases[t], cases[t - 1]) = (77, 9, 1003) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (55, 352, 2) (t, cases[t], cases[t - 1]) = (54, -39, 74) In these results, what is happening is that when new cases fluctuate too much, the likelihood is identically 0, causing the posterior calculation to break down. Increasing the variance of changes in $R_t$, widens the posterior confidence intervals, but does not solve the problem of vanishing likelihoods. One thing that can \u201csolve\u201d the problem is choosing a distribution of $k_t | \\lambda, k_{t-1}$ with higher variance. The negative binomial with parameters $\\lambda p/(1-p)$ and $p$ has mean $\\lambda$ and variance $\\lambda/p$. \u03b3 =1/7 \u03c3 = 0.25 Plots.closeall() for \u03c3 in [0.1, 0.25, 0.5] for nbp in [0.5, 0.1, 0.01] figs = [] for gdf in groupby(sdf, :state) p, m, cr = rtpost(gdf.newcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(NegativeBinomial(\u03bb*nbp/(1-nbp), nbp),x)); f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Negative binomial, p=$nbp, & \u03c3=$\u03c3\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (78, 2807, 9) (t, cases[t], cases[t - 1]) = (79, 1, 2807) (t, cases[t], cases[t - 1]) = (80, 2808, 1) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) (t, cases[t], cases[t - 1]) = (54, -39, 74) What Systrom did was smooth the new cases before using the Poisson distribution. He used a window width of $7$ and Gaussian weights with standard deviation $2$. using RollingFunctions \u03c3 = 0.25 Plots.closeall() for w in [3, 7, 11] for s in [0.5, 2, 4] \u03b3 =1/7 nbp = 0.01 figs = [] for gdf in groupby(sdf, :state) windowsize = w weights = pdf(Normal(0, s), -floor(windowsize/2):floor(windowsize/2)) weights = weights/sum(weights) smoothcases = Int.(round.(runmean(gdf.newcases[2:end], windowsize, weights*windowsize))) p, m, cr = rtpost(smoothcases, \u03b3, \u03c3, x->pdf(truncated(Gamma(4,1),0,8), x), (\u03bb,x)->pdf(Poisson(\u03bb),x)) f = plot(gdf.date, m, ribbon=(m-cr[:,1], cr[:,2] - m), title=unique(gdf.state)[1], legend=:none, ylabel=\"R\u209c\") f = hline!(f,[1.0]) figs = vcat(figs, f) end l = @layout [a{.1h};grid(1,1)] display(plot(plot(annotation=(0.5,0.5, \"Poisson & \u03c3=$\u03c3, s=$s, w=$w\"), framestyle = :none), plot(figs[1:9]..., layout=(3,3)), layout=l, reuse=false)) end end (t, cases[t], cases[t - 1]) = (54, -4, 68) (t, cases[t], cases[t - 1]) = (56, -4, 68) (t, cases[t], cases[t - 1]) = (58, -4, 68) Here we see that we can get a variety of results depending on the smoothing used. All of these posteriors ignore the uncertainty in the choice of smoothing parameters (and procedure).","title":"Code"},{"location":"Rt/#an-alternative-approach","text":"Here we follow an approach similar in spirit to Systrom, with a few additions. First, we utilize data on movement and business operations as auxillary noisy measures of $R_t$. Second, we allow state policies to shift the mean of $R_t$. Third, we combine data from all states to improve precision in each. Fourth, we incorporate testing numbers into the data. As above, we assume that k_{st} | R_{st}, k_{s,t-1}, ... \\sim Poisson(k_{s,t-1} \\frac{\\tau_{s,t}}{\\tau_{s,t-1}} e^{\\gamma(R_{st} - 1)}) Question Any distribution with mean $k_{t-1} \\frac{\\tau{t}}{\\tau{t-1}} e^{\\gamma(R_t - 1)}$ makes sense here. What other choice could incorporate measurement error so that cases don\u2019t need to be smoothed in advance? We will allow state policies, $d_{s,t}$ to affect the mean of $R_t$. Specifically, we\u2019ll assume that R_{st} | R_{s,t-1}, d_{st} \\sim N(\\alpha_r R_{t-1} + d_{s,t} \\alpha, \\sigma^2) Measures of movement and business operations are used as noisy measures of $R_{s,t}$ m_{s,t} ~ N(\\lambda_r R_{s,t} + x_{st} \\lambda, \\Sigma_m) where $x_{st}$ could include e.g. state demographics and day of week indicators. Question Should $x_{st}$ include policies? I think yes. Question What to do about $\\tau$? One idea is to assume $\\frac{\\tau_{s,t}}{\\tau_{s,t-1}}$ is a function of test numbers. However, numbers of tests are likely responding to policies, $d_{st}$ and cases $k_{st}$. The parameters $\\gamma$, $\\alpha$, $\\lambda$, $\\sigma$, and $\\Sigma_m$ are assumed to be common across states.","title":"An alternative approach"},{"location":"Rt/#code_1","text":"The model using Turing, CovidSEIR, Plots, PrettyTables, Dates using LinearAlgebra: dot, diagm, Symmetric, I @model rt(cases, m, d, x, ::Type{Rtype}=Float64) where {Rtype <: Real} = begin # Priors \u03b3 ~ truncated(Normal(1/7, 1/2), 1/21, 1/3) \u03c3 ~ truncated(Normal(0.25,1), 1e-6, Inf) meanR0 ~ truncated(Normal(3, 2), 0, Inf) sigR0 ~ truncated(Normal(1,1), 1e-2, Inf) \u03b1R ~ truncated(Normal(0.5, 2), -0.9, 0.9) \u03b1 ~ MvNormal(zeros(size(d, 1)), 1.0) \u03bbR ~ MvNormal(zeros(size(m, 1)), 1.0) \u03bb ~ MvNormal(zeros(size(m,1)*size(x,1)), 1.0) \u03bb = reshape(\u03bb, size(m,1), size(x,1)) J = size(m,1) #Cm ~ LKJ(J, 2.0) #m = diagm(ones(J)) sm ~ MvNormal(zeros(J), 1) \u03a3m = diagm(exp.(sm)) + I*1e-4 #\u03a3m = Cm.*(exp.(sm)*exp.(sm)') #\u03a3m ~ Wishart(J+2, diagm(ones(J))*1/(2*0.001)) if (cases === missing) # for simulating the model cases = Matrix{Rtype}(undef, T, S) end J, T, S = size(m) @assert (T,S) == size(cases) @assert size(x,2) == T && size(d,2) == T @assert size(x,3) == S && size(d,3) == S R = Matrix{Rtype}(undef, T, S) e = Matrix{Rtype}(undef, T, S) for s in 1:S R[1,s] = meanR0 e[1,s] ~ Normal(0, sigR0) for t in 2:T e[t,s] ~ Normal(\u03b1R*e[t-1,s], \u03c3) R[t,s] = e[t,s] + dot(\u03b1, d[:,t,s]) #R[t,s] ~ truncated(Normal(\u03b1R*R[t-1,s] + dot(\u03b1,d[:,t,s]), \u03c3), 0, 20) if (t>2) # cases[1,s] is missing because cases is the diff of cumulative cases meank = max(cases[t-1, s], 1e-1)*exp(\u03b3*(R[t,s]-1)) #@show t, meank, cases[t-1,s], R[t,s], meanR0, sigR0, \u03b1R cases[t, s] ~ Poisson(meank) #cases[t,s] ~ truncated(Normal(meank, meank), 0, Inf) end if !any(ismissing.(m[:,t,s])) m[:,t,s] ~ MvNormal(\u03bbR*R[t,s] + \u03bb*x[:,t,s], Symmetric(\u03a3m)) end end end return(cases, R) # return only matters when simulating model end Prepare the data. df = CovidSEIR.statedata() df = df[df[!,:fips].<60,:] # get ride of non-states (AS, GU, etc) df[!, :weekend] = 1*(Dates.dayofweek.(df[!,:date]) .>= 6) pvars = [Symbol(\"Stay.at.home..shelter.in.place\"), Symbol(\"State.of.emergency\"), Symbol(\"Date.closed.K.12.schools\"), #Symbol(\"Closed.day.cares\"), #Symbol(\"Date.banned.visitors.to.nursing.homes\"), Symbol(\"Closed.non.essential.businesses\"), Symbol(\"Closed.restaurants.except.take.out\")] dvars= [:weekend] mvars = [:retail_and_recreation_percent_change_from_baseline, :grocery_and_pharmacy_percent_change_from_baseline, #:parks_percent_change_from_baseline, #:transit_stations_percent_change_from_baseline, #:workplaces_percent_change_from_baseline, #:residential_percent_change_from_baseline, #:percentchangehours, :percentchangebusinesses] xvars = dvars states = unique(df[!,:state]) dates = sort(unique(df[!,:date])) S = length(states) T = length(dates) d = Array{Float64,3}(undef, length(dvars) + length(pvars), T, S) x = Array{Float64,3}(undef, length(xvars) + length(pvars), T, S) m = Array{Union{Missing,Float64},3}(missing, length(mvars), T, S) cc = Matrix{Union{Missing,Float64}}(missing, T,S) cases = Matrix{Union{Missing,Float64}}(missing, T,S) for (s, st) in enumerate(states) for (t, dt) in enumerate(dates) inc = findall((df[!,:state] .== st) .& (df[!,:date] .==dt)) @assert length(inc)==1 i = inc[1] p = convert(Array, df[i,pvars]) .< dt p[ismissing.(p)] .= false d[:,t,s] .= vcat(p, convert(Array, df[i, dvars])) x[:,t,s] .= vcat(p, convert(Array, df[i, xvars])) m[:,t,s] .= convert(Array, df[i, mvars])./100 cc[t,s] = df[i, :cases] if (t>1) cases[t,s] = max(0.0,cc[t,s] - cc[t-1,s]) end end end Estimation mdl = rt(cases, m, d, x) #@time chain=Turing.sample(mdl, HMC(1e-6, 3), 50); #using Turing.Variational #q0 = Variational.meanfield(mdl); #advi = ADVI(10, 10_000) #@time q = vi(mdl, ADVI(10,100), q0, optimizer=Variational.DecayedADAGrad(1e-2, 1.1, 0.9)); #chain = Turing.sample(mdl, NUTS(500, 0.65, max_depth=4, init_\u03f5=1e-4), 1000) Bettencourt, Ruy M., Lu\u00eds M. A. AND Ribeiro. 2008. \u201cReal Time Bayesian Estimation of the Epidemic Potential of Emerging Infectious Diseases.\u201d PLOS ONE 3 (5): 1\u20139. https://doi.org/10.1371/journal.pone.0002185 .","title":"Code"},{"location":"canada/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License using CovidSEIR, Plots, DataFrames, JLD2, StatsPlots, MCMCChains Plots.pyplot() jmddir = normpath(joinpath(dirname(Base.find_package(\"CovidSEIR\")),\"..\",\"docs\",\"jmd\")) covdf = covidjhudata(); Canada \u00b6 We estimate the model with the following code. It takes about an hour. canada = CountryData(covdf, \"Canada\"); using Turing canmod = CovidSEIR.TimeVarying.countrymodel(canada) cc = Turing.psample(canmod, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/canada_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/canada_dhmc_2020-04-13.jld2\" cc dayt0; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.2357 0.6185 0.0044 0.0434 80.3213 2.7437 sigD 6.5869 0.8252 0.0058 0.0488 84.3120 1.2775 sigC 663.0470 132.2966 0.9355 8.8404 80.3213 2.0702 sigRc 109.1233 8.8844 0.0628 0.4840 122.8527 1.1655 a 0.6428 0.2756 0.0019 0.0193 80.3213 2.8064 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.8518 p[1] 0.0819 0.2048 0.0014 0.0143 80.3213 2.3034 p[2] 0.0054 0.0035 0.0000 0.0002 80.3213 4.0799 \u03b2[1] 0.2341 0.2845 0.0020 0.0186 80.3213 1.3055 \u03b2[2] 0.6854 0.5439 0.0038 0.0373 80.3213 1.8702 \u03b2[3] 3.4579 0.8677 0.0061 0.0608 80.3213 2.7532 \u03b3[1] 2.1268 1.0667 0.0075 0.0754 80.3213 4.6674 \u03b3[2] 0.0439 0.0157 0.0001 0.0011 80.3213 3.1084 \u03c1[1] 0.2345 0.3476 0.0025 0.0244 80.3213 4.3679 \u03c1[2] 56.7301 23.8913 0.1689 1.6324 80.3213 1.8519 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0001 0.0010 2.2230 sigD 5.2897 6.0577 6.3179 7.1150 8.5042 sigC 340.9755 643.1188 676.1973 738.0302 872.2481 sigRc 92.9782 103.0199 110.7701 112.5595 129.1059 a 0.1631 0.3985 0.6762 0.9309 0.9894 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0028 0.0038 0.0044 0.0163 0.8283 p[2] 0.0039 0.0040 0.0041 0.0041 0.0163 \u03b2[1] 0.0000 0.0002 0.0995 0.4113 0.8889 \u03b2[2] 0.0241 0.1801 0.5443 1.3260 1.5558 \u03b2[3] 1.2217 3.3502 3.6691 3.9622 4.6629 \u03b3[1] 0.0171 2.2217 2.6733 2.7457 2.9976 \u03b3[2] 0.0338 0.0380 0.0381 0.0401 0.0932 \u03c1[1] 0.0000 0.0004 0.0050 0.5601 0.9289 \u03c1[2] 24.6373 24.7181 67.2189 71.7995 99.9910 Estimates \u00b6 plot(cc) We can see that there might be convergence issues. There are large differences between the four chains for some parameters. describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.2357 0.6185 0.0044 0.0434 80.3213 2.7437 sigD 6.5869 0.8252 0.0058 0.0488 84.3120 1.2775 sigC 663.0470 132.2966 0.9355 8.8404 80.3213 2.0702 sigRc 109.1233 8.8844 0.0628 0.4840 122.8527 1.1655 a 0.6428 0.2756 0.0019 0.0193 80.3213 2.8064 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.8518 p[1] 0.0819 0.2048 0.0014 0.0143 80.3213 2.3034 p[2] 0.0054 0.0035 0.0000 0.0002 80.3213 4.0799 \u03b2[1] 0.2341 0.2845 0.0020 0.0186 80.3213 1.3055 \u03b2[2] 0.6854 0.5439 0.0038 0.0373 80.3213 1.8702 \u03b2[3] 3.4579 0.8677 0.0061 0.0608 80.3213 2.7532 \u03b3[1] 2.1268 1.0667 0.0075 0.0754 80.3213 4.6674 \u03b3[2] 0.0439 0.0157 0.0001 0.0011 80.3213 3.1084 \u03c1[1] 0.2345 0.3476 0.0025 0.0244 80.3213 4.3679 \u03c1[2] 56.7301 23.8913 0.1689 1.6324 80.3213 1.8519 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0001 0.0010 2.2230 sigD 5.2897 6.0577 6.3179 7.1150 8.5042 sigC 340.9755 643.1188 676.1973 738.0302 872.2481 sigRc 92.9782 103.0199 110.7701 112.5595 129.1059 a 0.1631 0.3985 0.6762 0.9309 0.9894 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0028 0.0038 0.0044 0.0163 0.8283 p[2] 0.0039 0.0040 0.0041 0.0041 0.0163 \u03b2[1] 0.0000 0.0002 0.0995 0.4113 0.8889 \u03b2[2] 0.0241 0.1801 0.5443 1.3260 1.5558 \u03b2[3] 1.2217 3.3502 3.6691 3.9622 4.6629 \u03b3[1] 0.0171 2.2217 2.6733 2.7457 2.9976 \u03b3[2] 0.0338 0.0380 0.0381 0.0401 0.0932 \u03c1[1] 0.0000 0.0004 0.0050 0.5601 0.9289 \u03c1[2] 24.6373 24.7181 67.2189 71.7995 99.9910 The parameter estimates are generally not very precise. Fit \u00b6 sdf = simtrajectories(cc, canada, 1:200) f = plotvars(sdf, canada) f.fit In this figure, solid lines are observed data, dashed lines are posterior means, and the shaded region is a pointwise 90% credible interval. Implications \u00b6 We now look at the model\u2019s projections for some observed and unobserved variables. for fig in f.trajectories display(fig) end In general we see a similar pattern as noted above: the posteriors for observed variables are fairly precise. However, the posteriors for unobserved variables, such as the portion of undetected infections and the portion of mild infections, are very imprecise.","title":"Canada"},{"location":"canada/#canada","text":"We estimate the model with the following code. It takes about an hour. canada = CountryData(covdf, \"Canada\"); using Turing canmod = CovidSEIR.TimeVarying.countrymodel(canada) cc = Turing.psample(canmod, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/canada_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/canada_dhmc_2020-04-13.jld2\" cc dayt0; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.2357 0.6185 0.0044 0.0434 80.3213 2.7437 sigD 6.5869 0.8252 0.0058 0.0488 84.3120 1.2775 sigC 663.0470 132.2966 0.9355 8.8404 80.3213 2.0702 sigRc 109.1233 8.8844 0.0628 0.4840 122.8527 1.1655 a 0.6428 0.2756 0.0019 0.0193 80.3213 2.8064 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.8518 p[1] 0.0819 0.2048 0.0014 0.0143 80.3213 2.3034 p[2] 0.0054 0.0035 0.0000 0.0002 80.3213 4.0799 \u03b2[1] 0.2341 0.2845 0.0020 0.0186 80.3213 1.3055 \u03b2[2] 0.6854 0.5439 0.0038 0.0373 80.3213 1.8702 \u03b2[3] 3.4579 0.8677 0.0061 0.0608 80.3213 2.7532 \u03b3[1] 2.1268 1.0667 0.0075 0.0754 80.3213 4.6674 \u03b3[2] 0.0439 0.0157 0.0001 0.0011 80.3213 3.1084 \u03c1[1] 0.2345 0.3476 0.0025 0.0244 80.3213 4.3679 \u03c1[2] 56.7301 23.8913 0.1689 1.6324 80.3213 1.8519 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0001 0.0010 2.2230 sigD 5.2897 6.0577 6.3179 7.1150 8.5042 sigC 340.9755 643.1188 676.1973 738.0302 872.2481 sigRc 92.9782 103.0199 110.7701 112.5595 129.1059 a 0.1631 0.3985 0.6762 0.9309 0.9894 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0028 0.0038 0.0044 0.0163 0.8283 p[2] 0.0039 0.0040 0.0041 0.0041 0.0163 \u03b2[1] 0.0000 0.0002 0.0995 0.4113 0.8889 \u03b2[2] 0.0241 0.1801 0.5443 1.3260 1.5558 \u03b2[3] 1.2217 3.3502 3.6691 3.9622 4.6629 \u03b3[1] 0.0171 2.2217 2.6733 2.7457 2.9976 \u03b3[2] 0.0338 0.0380 0.0381 0.0401 0.0932 \u03c1[1] 0.0000 0.0004 0.0050 0.5601 0.9289 \u03c1[2] 24.6373 24.7181 67.2189 71.7995 99.9910","title":"Canada"},{"location":"canada/#estimates","text":"plot(cc) We can see that there might be convergence issues. There are large differences between the four chains for some parameters. describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.2357 0.6185 0.0044 0.0434 80.3213 2.7437 sigD 6.5869 0.8252 0.0058 0.0488 84.3120 1.2775 sigC 663.0470 132.2966 0.9355 8.8404 80.3213 2.0702 sigRc 109.1233 8.8844 0.0628 0.4840 122.8527 1.1655 a 0.6428 0.2756 0.0019 0.0193 80.3213 2.8064 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.8518 p[1] 0.0819 0.2048 0.0014 0.0143 80.3213 2.3034 p[2] 0.0054 0.0035 0.0000 0.0002 80.3213 4.0799 \u03b2[1] 0.2341 0.2845 0.0020 0.0186 80.3213 1.3055 \u03b2[2] 0.6854 0.5439 0.0038 0.0373 80.3213 1.8702 \u03b2[3] 3.4579 0.8677 0.0061 0.0608 80.3213 2.7532 \u03b3[1] 2.1268 1.0667 0.0075 0.0754 80.3213 4.6674 \u03b3[2] 0.0439 0.0157 0.0001 0.0011 80.3213 3.1084 \u03c1[1] 0.2345 0.3476 0.0025 0.0244 80.3213 4.3679 \u03c1[2] 56.7301 23.8913 0.1689 1.6324 80.3213 1.8519 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0001 0.0010 2.2230 sigD 5.2897 6.0577 6.3179 7.1150 8.5042 sigC 340.9755 643.1188 676.1973 738.0302 872.2481 sigRc 92.9782 103.0199 110.7701 112.5595 129.1059 a 0.1631 0.3985 0.6762 0.9309 0.9894 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0028 0.0038 0.0044 0.0163 0.8283 p[2] 0.0039 0.0040 0.0041 0.0041 0.0163 \u03b2[1] 0.0000 0.0002 0.0995 0.4113 0.8889 \u03b2[2] 0.0241 0.1801 0.5443 1.3260 1.5558 \u03b2[3] 1.2217 3.3502 3.6691 3.9622 4.6629 \u03b3[1] 0.0171 2.2217 2.6733 2.7457 2.9976 \u03b3[2] 0.0338 0.0380 0.0381 0.0401 0.0932 \u03c1[1] 0.0000 0.0004 0.0050 0.5601 0.9289 \u03c1[2] 24.6373 24.7181 67.2189 71.7995 99.9910 The parameter estimates are generally not very precise.","title":"Estimates"},{"location":"canada/#fit","text":"sdf = simtrajectories(cc, canada, 1:200) f = plotvars(sdf, canada) f.fit In this figure, solid lines are observed data, dashed lines are posterior means, and the shaded region is a pointwise 90% credible interval.","title":"Fit"},{"location":"canada/#implications","text":"We now look at the model\u2019s projections for some observed and unobserved variables. for fig in f.trajectories display(fig) end In general we see a similar pattern as noted above: the posteriors for observed variables are fairly precise. However, the posteriors for unobserved variables, such as the portion of undetected infections and the portion of mild infections, are very imprecise.","title":"Implications"},{"location":"china/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License using CovidSEIR, Plots, DataFrames, JLD2, StatsPlots, MCMCChains Plots.pyplot() jmddir = normpath(joinpath(dirname(Base.find_package(\"CovidSEIR\")),\"..\",\"docs\",\"jmd\")) covdf = covidjhudata(); China \u00b6 using Dates dayt0 = Dates.Date(\"2020-01-22\") - Dates.Day(65) china = CountryData(covdf, \"China\", 65) CovidSEIR.CountryData{Float64,Int64}(1.39273e9, [65, 66, 67, 68, 69, 70, 71 , 72, 73, 74 \u2026 141, 142, 143, 144, 145, 146, 147, 148, 149, 150], [17.0, 18.0, 26.0, 42.0, 56.0, 82.0, 131.0, 133.0, 171.0, 213.0 \u2026 3335.0, 3337.0 , 3339.0, 3340.0, 3343.0, 3343.0, 3345.0, 3345.0, 3346.0, 3346.0], [28.0, 3 0.0, 36.0, 39.0, 49.0, 58.0, 101.0, 120.0, 135.0, 214.0 \u2026 77410.0, 77567. 0, 77679.0, 77791.0, 77877.0, 77956.0, 78039.0, 78200.0, 78311.0, 78401.0], [503.0, 595.0, 858.0, 1325.0, 1970.0, 2737.0, 5277.0, 5834.0, 7835.0, 9375 .0 \u2026 1973.0, 1905.0, 1865.0, 1810.0, 1794.0, 1835.0, 1829.0, 1761.0, 1699 .0, 1656.0]) using Turing mdl = CovidSEIR.TimeVarying.countrymodel(china) cc = Turing.psample(mdl, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/china_$(Dates.today()).jld2\" cc dayt0 JLD2.@load \"$jmddir/china_dhmc_2020-04-13.jld2\" cc dayt0; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 80.3213 1.5862 sigD 90.1865 108.1679 0.7649 7.6652 80.3213 16.4095 sigC 12749.7844 4659.6012 32.9484 322.0747 80.3213 4.5433 sigRc 8238.5858 3466.7500 24.5136 242.3239 80.3213 4.9360 a 0.7721 0.1378 0.0010 0.0069 120.2959 1.1108 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.6474 p[1] 0.0004 0.0005 0.0000 0.0000 80.3213 7.1795 p[2] 0.4376 0.4398 0.0031 0.0309 80.3213 6.8857 \u03b2[1] 0.3384 0.3067 0.0022 0.0213 80.3213 2.0684 \u03b2[2] 0.7464 0.6525 0.0046 0.0298 124.5414 1.1639 \u03b2[3] 1.4304 1.4707 0.0104 0.1042 80.3213 9.1300 \u03b3[1] 1.2668 1.2386 0.0088 0.0878 80.3213 13.3651 \u03b3[2] 0.1599 0.1464 0.0010 0.0081 86.9155 1.3707 \u03c1[1] 0.8703 0.1652 0.0012 0.0117 80.3213 2.2865 \u03c1[2] 87.7994 1.4004 0.0099 0.0850 80.3213 1.5699 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 0.0000 sigD 23.6088 26.6456 28.8155 91.4797 292.9900 sigC 4388.5359 10075.1023 14738.3582 15853.7267 17853.3371 sigRc 4613.6964 5290.9410 6950.5976 10492.7804 14948.0661 a 0.4875 0.6742 0.7763 0.8873 0.9793 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0000 0.0000 0.0001 0.0007 0.0014 p[2] 0.0021 0.0033 0.1933 0.8908 0.9903 \u03b2[1] 0.0269 0.1482 0.2338 0.3377 1.1417 \u03b2[2] 0.0000 0.2806 0.5279 1.1032 2.3880 \u03b2[3] 0.0530 0.1431 0.8618 2.9038 3.8533 \u03b3[1] 0.0819 0.0852 0.6694 2.5336 3.0000 \u03b3[2] 0.0336 0.0461 0.0849 0.2376 0.5292 \u03c1[1] 0.4234 0.7741 0.9711 0.9943 0.9995 \u03c1[2] 85.6977 86.6899 87.6515 88.7356 90.8120 Estimates \u00b6 plot(cc) describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 80.3213 1.5862 sigD 90.1865 108.1679 0.7649 7.6652 80.3213 16.4095 sigC 12749.7844 4659.6012 32.9484 322.0747 80.3213 4.5433 sigRc 8238.5858 3466.7500 24.5136 242.3239 80.3213 4.9360 a 0.7721 0.1378 0.0010 0.0069 120.2959 1.1108 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.6474 p[1] 0.0004 0.0005 0.0000 0.0000 80.3213 7.1795 p[2] 0.4376 0.4398 0.0031 0.0309 80.3213 6.8857 \u03b2[1] 0.3384 0.3067 0.0022 0.0213 80.3213 2.0684 \u03b2[2] 0.7464 0.6525 0.0046 0.0298 124.5414 1.1639 \u03b2[3] 1.4304 1.4707 0.0104 0.1042 80.3213 9.1300 \u03b3[1] 1.2668 1.2386 0.0088 0.0878 80.3213 13.3651 \u03b3[2] 0.1599 0.1464 0.0010 0.0081 86.9155 1.3707 \u03c1[1] 0.8703 0.1652 0.0012 0.0117 80.3213 2.2865 \u03c1[2] 87.7994 1.4004 0.0099 0.0850 80.3213 1.5699 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 0.0000 sigD 23.6088 26.6456 28.8155 91.4797 292.9900 sigC 4388.5359 10075.1023 14738.3582 15853.7267 17853.3371 sigRc 4613.6964 5290.9410 6950.5976 10492.7804 14948.0661 a 0.4875 0.6742 0.7763 0.8873 0.9793 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0000 0.0000 0.0001 0.0007 0.0014 p[2] 0.0021 0.0033 0.1933 0.8908 0.9903 \u03b2[1] 0.0269 0.1482 0.2338 0.3377 1.1417 \u03b2[2] 0.0000 0.2806 0.5279 1.1032 2.3880 \u03b2[3] 0.0530 0.1431 0.8618 2.9038 3.8533 \u03b3[1] 0.0819 0.0852 0.6694 2.5336 3.0000 \u03b3[2] 0.0336 0.0461 0.0849 0.2376 0.5292 \u03c1[1] 0.4234 0.7741 0.9711 0.9943 0.9995 \u03c1[2] 85.6977 86.6899 87.6515 88.7356 90.8120 Fit \u00b6 sdf = simtrajectories(cc, china, 1:150) f = plotvars(sdf, china, dayt0=dayt0) plot(f.fit, xlim=nothing, ylim=(0, maximum(china.active)*2)) Implications \u00b6 for fig in f.trajectories display(plot(fig, xlim=nothing)) end","title":"China"},{"location":"china/#china","text":"using Dates dayt0 = Dates.Date(\"2020-01-22\") - Dates.Day(65) china = CountryData(covdf, \"China\", 65) CovidSEIR.CountryData{Float64,Int64}(1.39273e9, [65, 66, 67, 68, 69, 70, 71 , 72, 73, 74 \u2026 141, 142, 143, 144, 145, 146, 147, 148, 149, 150], [17.0, 18.0, 26.0, 42.0, 56.0, 82.0, 131.0, 133.0, 171.0, 213.0 \u2026 3335.0, 3337.0 , 3339.0, 3340.0, 3343.0, 3343.0, 3345.0, 3345.0, 3346.0, 3346.0], [28.0, 3 0.0, 36.0, 39.0, 49.0, 58.0, 101.0, 120.0, 135.0, 214.0 \u2026 77410.0, 77567. 0, 77679.0, 77791.0, 77877.0, 77956.0, 78039.0, 78200.0, 78311.0, 78401.0], [503.0, 595.0, 858.0, 1325.0, 1970.0, 2737.0, 5277.0, 5834.0, 7835.0, 9375 .0 \u2026 1973.0, 1905.0, 1865.0, 1810.0, 1794.0, 1835.0, 1829.0, 1761.0, 1699 .0, 1656.0]) using Turing mdl = CovidSEIR.TimeVarying.countrymodel(china) cc = Turing.psample(mdl, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/china_$(Dates.today()).jld2\" cc dayt0 JLD2.@load \"$jmddir/china_dhmc_2020-04-13.jld2\" cc dayt0; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 80.3213 1.5862 sigD 90.1865 108.1679 0.7649 7.6652 80.3213 16.4095 sigC 12749.7844 4659.6012 32.9484 322.0747 80.3213 4.5433 sigRc 8238.5858 3466.7500 24.5136 242.3239 80.3213 4.9360 a 0.7721 0.1378 0.0010 0.0069 120.2959 1.1108 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.6474 p[1] 0.0004 0.0005 0.0000 0.0000 80.3213 7.1795 p[2] 0.4376 0.4398 0.0031 0.0309 80.3213 6.8857 \u03b2[1] 0.3384 0.3067 0.0022 0.0213 80.3213 2.0684 \u03b2[2] 0.7464 0.6525 0.0046 0.0298 124.5414 1.1639 \u03b2[3] 1.4304 1.4707 0.0104 0.1042 80.3213 9.1300 \u03b3[1] 1.2668 1.2386 0.0088 0.0878 80.3213 13.3651 \u03b3[2] 0.1599 0.1464 0.0010 0.0081 86.9155 1.3707 \u03c1[1] 0.8703 0.1652 0.0012 0.0117 80.3213 2.2865 \u03c1[2] 87.7994 1.4004 0.0099 0.0850 80.3213 1.5699 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 0.0000 sigD 23.6088 26.6456 28.8155 91.4797 292.9900 sigC 4388.5359 10075.1023 14738.3582 15853.7267 17853.3371 sigRc 4613.6964 5290.9410 6950.5976 10492.7804 14948.0661 a 0.4875 0.6742 0.7763 0.8873 0.9793 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0000 0.0000 0.0001 0.0007 0.0014 p[2] 0.0021 0.0033 0.1933 0.8908 0.9903 \u03b2[1] 0.0269 0.1482 0.2338 0.3377 1.1417 \u03b2[2] 0.0000 0.2806 0.5279 1.1032 2.3880 \u03b2[3] 0.0530 0.1431 0.8618 2.9038 3.8533 \u03b3[1] 0.0819 0.0852 0.6694 2.5336 3.0000 \u03b3[2] 0.0336 0.0461 0.0849 0.2376 0.5292 \u03c1[1] 0.4234 0.7741 0.9711 0.9943 0.9995 \u03c1[2] 85.6977 86.6899 87.6515 88.7356 90.8120","title":"China"},{"location":"china/#estimates","text":"plot(cc) describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 80.3213 1.5862 sigD 90.1865 108.1679 0.7649 7.6652 80.3213 16.4095 sigC 12749.7844 4659.6012 32.9484 322.0747 80.3213 4.5433 sigRc 8238.5858 3466.7500 24.5136 242.3239 80.3213 4.9360 a 0.7721 0.1378 0.0010 0.0069 120.2959 1.1108 pE0 0.0000 0.0000 0.0000 0.0000 80.3213 1.6474 p[1] 0.0004 0.0005 0.0000 0.0000 80.3213 7.1795 p[2] 0.4376 0.4398 0.0031 0.0309 80.3213 6.8857 \u03b2[1] 0.3384 0.3067 0.0022 0.0213 80.3213 2.0684 \u03b2[2] 0.7464 0.6525 0.0046 0.0298 124.5414 1.1639 \u03b2[3] 1.4304 1.4707 0.0104 0.1042 80.3213 9.1300 \u03b3[1] 1.2668 1.2386 0.0088 0.0878 80.3213 13.3651 \u03b3[2] 0.1599 0.1464 0.0010 0.0081 86.9155 1.3707 \u03c1[1] 0.8703 0.1652 0.0012 0.0117 80.3213 2.2865 \u03c1[2] 87.7994 1.4004 0.0099 0.0850 80.3213 1.5699 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0000 0.0000 sigD 23.6088 26.6456 28.8155 91.4797 292.9900 sigC 4388.5359 10075.1023 14738.3582 15853.7267 17853.3371 sigRc 4613.6964 5290.9410 6950.5976 10492.7804 14948.0661 a 0.4875 0.6742 0.7763 0.8873 0.9793 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0000 0.0000 0.0001 0.0007 0.0014 p[2] 0.0021 0.0033 0.1933 0.8908 0.9903 \u03b2[1] 0.0269 0.1482 0.2338 0.3377 1.1417 \u03b2[2] 0.0000 0.2806 0.5279 1.1032 2.3880 \u03b2[3] 0.0530 0.1431 0.8618 2.9038 3.8533 \u03b3[1] 0.0819 0.0852 0.6694 2.5336 3.0000 \u03b3[2] 0.0336 0.0461 0.0849 0.2376 0.5292 \u03c1[1] 0.4234 0.7741 0.9711 0.9943 0.9995 \u03c1[2] 85.6977 86.6899 87.6515 88.7356 90.8120","title":"Estimates"},{"location":"china/#fit","text":"sdf = simtrajectories(cc, china, 1:150) f = plotvars(sdf, china, dayt0=dayt0) plot(f.fit, xlim=nothing, ylim=(0, maximum(china.active)*2))","title":"Fit"},{"location":"china/#implications","text":"for fig in f.trajectories display(plot(fig, xlim=nothing)) end","title":"Implications"},{"location":"covid/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License using CovidSEIR using Plots Plots.pyplot() using DataFrames, JLD2 jmddir = normpath(joinpath(dirname(Base.find_package(\"CovidSEIR\")),\"..\",\"docs\",\"jmd\")) \"/home/paul/.julia/dev/CovidSEIR/docs/jmd\" Introduction \u00b6 Data \u00b6 We will use data from Johns Hopkins University Center for Systems Science and Engineering . It is gathered from a variety of sources and updated daily. JHU CSSE uses the data for this interactive website. . For another course, I wrote some notes using this data in python here. This data has daily cumulative counts of confirmed cases, recoveries, and deaths in each country (and provinces within some countries). covdf = covidjhudata() describe(covdf) 11\u00d78 DataFrames.DataFrame. Omitted printing of 2 columns \u2502 Row \u2502 variable \u2502 mean \u2502 min \u2502 median \u2502 max \u2502 nuni que \u2502 \u2502 \u2502 Symbol \u2502 Union\u2026 \u2502 Any \u2502 Union\u2026 \u2502 Any \u2502 Unio n\u2026 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2524 \u2502 1 \u2502 Date \u2502 \u2502 2020-01-22 \u2502 \u2502 2020-04-15 \u2502 85 \u2502 \u2502 2 \u2502 confirmed \u2502 1481.88 \u2502 -1 \u2502 2.0 \u2502 636350 \u2502 \u2502 \u2502 3 \u2502 Province \u2502 \u2502 Alberta \u2502 \u2502 Zhejiang \u2502 82 \u2502 \u2502 4 \u2502 Country \u2502 \u2502 Afghanistan \u2502 \u2502 Zimbabwe \u2502 185 \u2502 \u2502 5 \u2502 Lat \u2502 21.1709 \u2502 -51.7963 \u2502 22.3 \u2502 71.7069 \u2502 \u2502 \u2502 6 \u2502 Long \u2502 21.7781 \u2502 -135.0 \u2502 20.903 \u2502 178.065 \u2502 \u2502 \u2502 7 \u2502 deaths \u2502 78.9457 \u2502 -1 \u2502 0.0 \u2502 28326 \u2502 \u2502 \u2502 8 \u2502 recovered \u2502 381.939 \u2502 0 \u2502 0.0 \u2502 72600 \u2502 \u2502 \u2502 9 \u2502 iso2c \u2502 \u2502 AD \u2502 \u2502 ZW \u2502 178 \u2502 \u2502 10 \u2502 cpop \u2502 2.25233e8 \u2502 33785.0 \u2502 2.49924e7 \u2502 1.39273e9 \u2502 \u2502 \u2502 11 \u2502 ppop \u2502 2.74801e7 \u2502 41078 \u2502 1.557e7 \u2502 111690000 \u2502 \u2502 Model \u00b6 We will estimate a susceptible, exposed, infectious, recovered (SEIR) epidemiological model of Covid transmission. In particular, we will use a version based on this webapp by Allison Hill . The model contains the following variables, all of which are functions of time $S$: Susceptible individuals $E$: Exposed individuals - infected but not yet infectious or symptomatic $I_i$: Undetected infected individuals in severity class $i$. Severity increaes with $i$ and we assume individuals must pass through all previous classes $I_1$: Mild infection $I_2$: Severe infection $C_i$ confirmed infected individuals in severity class $i$ $R = R_u + R_c$: individuals who have recovered from disease and are now immune $R_u$ recovered individuals whose infection were never detected $R_c$ recovered individuals who were confirmed cases $X$: Dead individuals Compared to Hill\u2019s model, we have reduced the number of severity classes and from 3 to 2, and we have added undetected infections and recoveries. In the data, we observe active confirmed cases $\\approx \\sum_i C_i$, deaths $\\approx X$, and confirmed recoveries $\\approx R_c$. These variables evolve according to the following system of differential equations. \\begin{align*} \\dot{S} & = -S \\left( R(t)(\\beta_1C_1 + (\\beta_1 + \\beta_3)I_1) + C_2 \\beta_2 \\right)/N \\\\ \\dot{E} & = S \\left( R(t)(\\beta_1C_1 + (\\beta_1 + \\beta_3)I_1) + C_2 \\beta_2 \\right)/N - a E \\\\ \\dot{I_1} & = a E - \\gamma_1 I_1 - p_1 I_1 - \\tau C_1 \\\\ \\dot{I_2} & = 0 \\\\ \\dot{C_1} & = \\tau I - \\gamma_1 C_1 - p_1 C_1 \\\\ \\dot{C_2} & = p_1(I_1 + C_1) - \\gamma_2 C_2 - p_2 C_2 \\\\ \\dot{R_u} & = \\sum_i \\gamma_i I_i \\\\ \\dot{R_c} & = \\sum_i \\gamma_i C_i \\\\ \\dot{X} & = p_2 C_2 \\end{align*} Where the parameters are : $\\beta_1$, $\\beta_2$ baseline rate at which confirmed infected individuals in class $i$ contact susceptibles and infect them $\\beta_1+\\beta_3$ baseline rate at which undetected infected individuals infect others $R(t)$ reduction in infection rate due to isolation, quarantine, and/or lockdown $a$ rate of progression from the exposed to infected class $\\gamma_i$ rate at which infected individuals in class $i$ recover from disease and become immune $p_1$ rate at which infected individuals in class $i$ progress to class $i+1$ $p_2$ death rate for individuals in the most severe stage of disease $\\tau$ rate at which infections of class $1$ are detected Note that we are assuming that all severe infections are detected (and hence $I_2 = 0$). We are also assuming that confirmed and unconfirmed cases have the same recovery and progression rates. Empirical Model \u00b6 Our data has country population, $N$, daily cumulative confirmed cases, $c_t$, deaths, $d_t$, and recoveries, $r_t$. We will assume that at a known time 0, there is an unknown portion of exposed individuals, $p_0$, so \\begin{align*} S(0) = & (1-p_0) N \\\\ E(0) = & p_0 N \\end{align*} and all other model variables are 0 at time 0. We assume that the observed data is distributed as \\begin{align*} d_t \\sim & N(X(t), \\sigma_X^2) \\\\ r_t \\sim & N(R_c(t), \\sigma_R^2) \\\\ c_t - d_t - r_t \\sim & N(C_1(t) + C_2(t), \\sigma_C^2) \\end{align*} We parameterize the reduction in infection rates from public policy as R(t) = 1- \\frac{\\rho_1}{1+\\exp(\\rho_2 -t)} This implies that infection rates drop by roughly 100$\\rho_1$ percent in the week centered on $t=\\rho_2$. Model Limitations \u00b6 An important limitation is that the model assumes all other parameters are constant over time. Although we allow changes in the infection rate, efforts have also been made to increase $\\tau$. Innovations in treatment and crowding of the medical system likely lead to variation in $\\gamma$ and $p$. Single Country Estimates \u00b6 Priors \u00b6 We use the follow prior distributions. The means of these are loosely based on Hill\u2019s defaults . using Distributions defaultcountrypriors() = Dict( \"a\" => truncated(Normal(1/5, 3), 1/14, 1.0), \"p[1]\" => truncated(Normal(0.05, 0.3), 0, 1), \"p[2]\" => truncated(Normal(0.05, 0.3), 0, 1), \"\u03b3[1]\" => truncated(Normal(0.133, 0.5), 0, 3), \"\u03b3[2]\" => truncated(Normal(0.05, 0.3), 0, 1), \"\u03b2[1]\" => truncated(Normal(0.5, 1), 0, 10), \"\u03b2[2]\" => truncated(Normal(0.5, 1), 0, 10), \"\u03c4\" => truncated(Normal(0.2, 2), 0, 10), \"pE0\" => truncated(Normal(0.001, 0.1), 0, 1), \"sigD\" => InverseGamma(2,3), \"sigC\" => InverseGamma(2,3), \"sigRc\" => InverseGamma(2,3), \"\u03c1[1]\" => truncated(Normal(0.5, 2), 0, 1), \"\u03c1[2]\" => truncated(Normal(30, 30), 0, 100) Summary statistics of draws from this prior distribution are below. priors = CovidSEIR.TimeVarying.defaultpriors() population=1e6 T = 150 ode = CovidSEIR.TimeVarying.odeSEIR() model=CovidSEIR.TimeVarying.turingmodel1(population, 1:T, missing, missing, missing,ode, priors); pr = CovidSEIR.priorreport(priors, 150,population,model=model) pr.tbl 15\u00d76 DataFrames.DataFrame \u2502 Row \u2502 parameter \u2502 mean \u2502 stddev \u2502 q5 \u2502 q50 \u2502 q95 \u2502 \u2502 \u2502 Any \u2502 Any \u2502 Any \u2502 Any \u2502 Any \u2502 Any \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2524 \u2502 1 \u2502 a \u2502 0.532228 \u2502 0.267655 \u2502 0.116771 \u2502 0.534005 \u2502 0.9516 6 \u2502 \u2502 2 \u2502 pE0 \u2502 0.0797192 \u2502 0.0601517 \u2502 0.00642362 \u2502 0.0676311 \u2502 0.1964 49 \u2502 \u2502 3 \u2502 p[1] \u2502 0.259243 \u2502 0.188619 \u2502 0.0212131 \u2502 0.223932 \u2502 0.6150 81 \u2502 \u2502 4 \u2502 p[2] \u2502 0.255765 \u2502 0.187429 \u2502 0.0199915 \u2502 0.21967 \u2502 0.6183 19 \u2502 \u2502 5 \u2502 sigC \u2502 3.06972 \u2502 7.54916 \u2502 0.635259 \u2502 1.78636 \u2502 8.5077 7 \u2502 \u2502 6 \u2502 sigD \u2502 2.95921 \u2502 6.21134 \u2502 0.622761 \u2502 1.76887 \u2502 8.3176 1 \u2502 \u2502 7 \u2502 sigRc \u2502 2.9368 \u2502 5.06829 \u2502 0.626819 \u2502 1.73917 \u2502 8.3492 8 \u2502 \u2502 8 \u2502 \u03b2[1] \u2502 1.00155 \u2502 0.697947 \u2502 0.0940284 \u2502 0.895416 \u2502 2.2893 \u2502 \u2502 9 \u2502 \u03b2[2] \u2502 1.00996 \u2502 0.698382 \u2502 0.100554 \u2502 0.890034 \u2502 2.3079 8 \u2502 \u2502 10 \u2502 \u03b2[3] \u2502 1.00707 \u2502 0.695008 \u2502 0.0919612 \u2502 0.896013 \u2502 2.3323 8 \u2502 \u2502 11 \u2502 \u03b3[1] \u2502 0.451627 \u2502 0.327572 \u2502 0.0399892 \u2502 0.389729 \u2502 1.0706 3 \u2502 \u2502 12 \u2502 \u03b3[2] \u2502 0.25761 \u2502 0.188806 \u2502 0.021021 \u2502 0.221721 \u2502 0.6254 96 \u2502 \u2502 13 \u2502 \u03c1[1] \u2502 0.500063 \u2502 0.287893 \u2502 0.0505366 \u2502 0.497889 \u2502 0.9526 98 \u2502 \u2502 14 \u2502 \u03c1[2] \u2502 37.6915 \u2502 22.4854 \u2502 4.90265 \u2502 35.701 \u2502 78.667 1 \u2502 \u2502 15 \u2502 \u03c4 \u2502 1.64859 \u2502 1.22829 \u2502 0.135559 \u2502 1.39673 \u2502 4.0162 \u2502 The following plots show the implications of this prior for the observed data. The faint lines on each figure shows 1000 trajectories sampled from the prior distribution. The black line is the prior mean. The shaded region is a pointwise 90% prior credible interval. plot(pr.figs[1], xlabel=\"Days\", ylabel=\"Portion of population\") plot(pr.figs[2], xlabel=\"Days\", ylabel=\"Portion of population\") plot(pr.figs[3], xlabel=\"Days\", ylabel=\"Portion of population\") Subjectively this prior seems reasonable. It is perhaps too concentrated on relatively fast epidemics. I may alter it, but it\u2019s what I used for the current results. Estimation \u00b6 We estimate the model by MCMC. Specifically, we use the Turing.jl package (Ge, Xu, and Ghahramani 2018 ) . For sampling, we use the No-U-Turn-Sampler variant of Hamiltonian Monte Carlo. In the results below we use 4 chains with 1000 warmup iterations, and 4000 iterations for the results. Results \u00b6 Canada Italy South Korea China United States Extensions \u00b6 Improve chain mixing. Estimate a multi-country model with some parameters common across countries and others multi-level distributions. About this document \u00b6 This document was created using Weave.jl. The code is available in on github . Ge, Hong, Kai Xu, and Zoubin Ghahramani. 2018. \u201cTuring: A Language for Flexible Probabilistic Inference.\u201d In International Conference on Artificial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018, Playa Blanca, Lanzarote, Canary Islands, Spain , 1682\u201390. http://proceedings.mlr.press/v84/ge18b.html .","title":"Model"},{"location":"covid/#introduction","text":"","title":"Introduction"},{"location":"covid/#data","text":"We will use data from Johns Hopkins University Center for Systems Science and Engineering . It is gathered from a variety of sources and updated daily. JHU CSSE uses the data for this interactive website. . For another course, I wrote some notes using this data in python here. This data has daily cumulative counts of confirmed cases, recoveries, and deaths in each country (and provinces within some countries). covdf = covidjhudata() describe(covdf) 11\u00d78 DataFrames.DataFrame. Omitted printing of 2 columns \u2502 Row \u2502 variable \u2502 mean \u2502 min \u2502 median \u2502 max \u2502 nuni que \u2502 \u2502 \u2502 Symbol \u2502 Union\u2026 \u2502 Any \u2502 Union\u2026 \u2502 Any \u2502 Unio n\u2026 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2524 \u2502 1 \u2502 Date \u2502 \u2502 2020-01-22 \u2502 \u2502 2020-04-15 \u2502 85 \u2502 \u2502 2 \u2502 confirmed \u2502 1481.88 \u2502 -1 \u2502 2.0 \u2502 636350 \u2502 \u2502 \u2502 3 \u2502 Province \u2502 \u2502 Alberta \u2502 \u2502 Zhejiang \u2502 82 \u2502 \u2502 4 \u2502 Country \u2502 \u2502 Afghanistan \u2502 \u2502 Zimbabwe \u2502 185 \u2502 \u2502 5 \u2502 Lat \u2502 21.1709 \u2502 -51.7963 \u2502 22.3 \u2502 71.7069 \u2502 \u2502 \u2502 6 \u2502 Long \u2502 21.7781 \u2502 -135.0 \u2502 20.903 \u2502 178.065 \u2502 \u2502 \u2502 7 \u2502 deaths \u2502 78.9457 \u2502 -1 \u2502 0.0 \u2502 28326 \u2502 \u2502 \u2502 8 \u2502 recovered \u2502 381.939 \u2502 0 \u2502 0.0 \u2502 72600 \u2502 \u2502 \u2502 9 \u2502 iso2c \u2502 \u2502 AD \u2502 \u2502 ZW \u2502 178 \u2502 \u2502 10 \u2502 cpop \u2502 2.25233e8 \u2502 33785.0 \u2502 2.49924e7 \u2502 1.39273e9 \u2502 \u2502 \u2502 11 \u2502 ppop \u2502 2.74801e7 \u2502 41078 \u2502 1.557e7 \u2502 111690000 \u2502 \u2502","title":"Data"},{"location":"covid/#model","text":"We will estimate a susceptible, exposed, infectious, recovered (SEIR) epidemiological model of Covid transmission. In particular, we will use a version based on this webapp by Allison Hill . The model contains the following variables, all of which are functions of time $S$: Susceptible individuals $E$: Exposed individuals - infected but not yet infectious or symptomatic $I_i$: Undetected infected individuals in severity class $i$. Severity increaes with $i$ and we assume individuals must pass through all previous classes $I_1$: Mild infection $I_2$: Severe infection $C_i$ confirmed infected individuals in severity class $i$ $R = R_u + R_c$: individuals who have recovered from disease and are now immune $R_u$ recovered individuals whose infection were never detected $R_c$ recovered individuals who were confirmed cases $X$: Dead individuals Compared to Hill\u2019s model, we have reduced the number of severity classes and from 3 to 2, and we have added undetected infections and recoveries. In the data, we observe active confirmed cases $\\approx \\sum_i C_i$, deaths $\\approx X$, and confirmed recoveries $\\approx R_c$. These variables evolve according to the following system of differential equations. \\begin{align*} \\dot{S} & = -S \\left( R(t)(\\beta_1C_1 + (\\beta_1 + \\beta_3)I_1) + C_2 \\beta_2 \\right)/N \\\\ \\dot{E} & = S \\left( R(t)(\\beta_1C_1 + (\\beta_1 + \\beta_3)I_1) + C_2 \\beta_2 \\right)/N - a E \\\\ \\dot{I_1} & = a E - \\gamma_1 I_1 - p_1 I_1 - \\tau C_1 \\\\ \\dot{I_2} & = 0 \\\\ \\dot{C_1} & = \\tau I - \\gamma_1 C_1 - p_1 C_1 \\\\ \\dot{C_2} & = p_1(I_1 + C_1) - \\gamma_2 C_2 - p_2 C_2 \\\\ \\dot{R_u} & = \\sum_i \\gamma_i I_i \\\\ \\dot{R_c} & = \\sum_i \\gamma_i C_i \\\\ \\dot{X} & = p_2 C_2 \\end{align*} Where the parameters are : $\\beta_1$, $\\beta_2$ baseline rate at which confirmed infected individuals in class $i$ contact susceptibles and infect them $\\beta_1+\\beta_3$ baseline rate at which undetected infected individuals infect others $R(t)$ reduction in infection rate due to isolation, quarantine, and/or lockdown $a$ rate of progression from the exposed to infected class $\\gamma_i$ rate at which infected individuals in class $i$ recover from disease and become immune $p_1$ rate at which infected individuals in class $i$ progress to class $i+1$ $p_2$ death rate for individuals in the most severe stage of disease $\\tau$ rate at which infections of class $1$ are detected Note that we are assuming that all severe infections are detected (and hence $I_2 = 0$). We are also assuming that confirmed and unconfirmed cases have the same recovery and progression rates.","title":"Model"},{"location":"covid/#empirical-model","text":"Our data has country population, $N$, daily cumulative confirmed cases, $c_t$, deaths, $d_t$, and recoveries, $r_t$. We will assume that at a known time 0, there is an unknown portion of exposed individuals, $p_0$, so \\begin{align*} S(0) = & (1-p_0) N \\\\ E(0) = & p_0 N \\end{align*} and all other model variables are 0 at time 0. We assume that the observed data is distributed as \\begin{align*} d_t \\sim & N(X(t), \\sigma_X^2) \\\\ r_t \\sim & N(R_c(t), \\sigma_R^2) \\\\ c_t - d_t - r_t \\sim & N(C_1(t) + C_2(t), \\sigma_C^2) \\end{align*} We parameterize the reduction in infection rates from public policy as R(t) = 1- \\frac{\\rho_1}{1+\\exp(\\rho_2 -t)} This implies that infection rates drop by roughly 100$\\rho_1$ percent in the week centered on $t=\\rho_2$.","title":"Empirical Model"},{"location":"covid/#model-limitations","text":"An important limitation is that the model assumes all other parameters are constant over time. Although we allow changes in the infection rate, efforts have also been made to increase $\\tau$. Innovations in treatment and crowding of the medical system likely lead to variation in $\\gamma$ and $p$.","title":"Model Limitations"},{"location":"covid/#single-country-estimates","text":"","title":"Single Country Estimates"},{"location":"covid/#priors","text":"We use the follow prior distributions. The means of these are loosely based on Hill\u2019s defaults . using Distributions defaultcountrypriors() = Dict( \"a\" => truncated(Normal(1/5, 3), 1/14, 1.0), \"p[1]\" => truncated(Normal(0.05, 0.3), 0, 1), \"p[2]\" => truncated(Normal(0.05, 0.3), 0, 1), \"\u03b3[1]\" => truncated(Normal(0.133, 0.5), 0, 3), \"\u03b3[2]\" => truncated(Normal(0.05, 0.3), 0, 1), \"\u03b2[1]\" => truncated(Normal(0.5, 1), 0, 10), \"\u03b2[2]\" => truncated(Normal(0.5, 1), 0, 10), \"\u03c4\" => truncated(Normal(0.2, 2), 0, 10), \"pE0\" => truncated(Normal(0.001, 0.1), 0, 1), \"sigD\" => InverseGamma(2,3), \"sigC\" => InverseGamma(2,3), \"sigRc\" => InverseGamma(2,3), \"\u03c1[1]\" => truncated(Normal(0.5, 2), 0, 1), \"\u03c1[2]\" => truncated(Normal(30, 30), 0, 100) Summary statistics of draws from this prior distribution are below. priors = CovidSEIR.TimeVarying.defaultpriors() population=1e6 T = 150 ode = CovidSEIR.TimeVarying.odeSEIR() model=CovidSEIR.TimeVarying.turingmodel1(population, 1:T, missing, missing, missing,ode, priors); pr = CovidSEIR.priorreport(priors, 150,population,model=model) pr.tbl 15\u00d76 DataFrames.DataFrame \u2502 Row \u2502 parameter \u2502 mean \u2502 stddev \u2502 q5 \u2502 q50 \u2502 q95 \u2502 \u2502 \u2502 Any \u2502 Any \u2502 Any \u2502 Any \u2502 Any \u2502 Any \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2524 \u2502 1 \u2502 a \u2502 0.532228 \u2502 0.267655 \u2502 0.116771 \u2502 0.534005 \u2502 0.9516 6 \u2502 \u2502 2 \u2502 pE0 \u2502 0.0797192 \u2502 0.0601517 \u2502 0.00642362 \u2502 0.0676311 \u2502 0.1964 49 \u2502 \u2502 3 \u2502 p[1] \u2502 0.259243 \u2502 0.188619 \u2502 0.0212131 \u2502 0.223932 \u2502 0.6150 81 \u2502 \u2502 4 \u2502 p[2] \u2502 0.255765 \u2502 0.187429 \u2502 0.0199915 \u2502 0.21967 \u2502 0.6183 19 \u2502 \u2502 5 \u2502 sigC \u2502 3.06972 \u2502 7.54916 \u2502 0.635259 \u2502 1.78636 \u2502 8.5077 7 \u2502 \u2502 6 \u2502 sigD \u2502 2.95921 \u2502 6.21134 \u2502 0.622761 \u2502 1.76887 \u2502 8.3176 1 \u2502 \u2502 7 \u2502 sigRc \u2502 2.9368 \u2502 5.06829 \u2502 0.626819 \u2502 1.73917 \u2502 8.3492 8 \u2502 \u2502 8 \u2502 \u03b2[1] \u2502 1.00155 \u2502 0.697947 \u2502 0.0940284 \u2502 0.895416 \u2502 2.2893 \u2502 \u2502 9 \u2502 \u03b2[2] \u2502 1.00996 \u2502 0.698382 \u2502 0.100554 \u2502 0.890034 \u2502 2.3079 8 \u2502 \u2502 10 \u2502 \u03b2[3] \u2502 1.00707 \u2502 0.695008 \u2502 0.0919612 \u2502 0.896013 \u2502 2.3323 8 \u2502 \u2502 11 \u2502 \u03b3[1] \u2502 0.451627 \u2502 0.327572 \u2502 0.0399892 \u2502 0.389729 \u2502 1.0706 3 \u2502 \u2502 12 \u2502 \u03b3[2] \u2502 0.25761 \u2502 0.188806 \u2502 0.021021 \u2502 0.221721 \u2502 0.6254 96 \u2502 \u2502 13 \u2502 \u03c1[1] \u2502 0.500063 \u2502 0.287893 \u2502 0.0505366 \u2502 0.497889 \u2502 0.9526 98 \u2502 \u2502 14 \u2502 \u03c1[2] \u2502 37.6915 \u2502 22.4854 \u2502 4.90265 \u2502 35.701 \u2502 78.667 1 \u2502 \u2502 15 \u2502 \u03c4 \u2502 1.64859 \u2502 1.22829 \u2502 0.135559 \u2502 1.39673 \u2502 4.0162 \u2502 The following plots show the implications of this prior for the observed data. The faint lines on each figure shows 1000 trajectories sampled from the prior distribution. The black line is the prior mean. The shaded region is a pointwise 90% prior credible interval. plot(pr.figs[1], xlabel=\"Days\", ylabel=\"Portion of population\") plot(pr.figs[2], xlabel=\"Days\", ylabel=\"Portion of population\") plot(pr.figs[3], xlabel=\"Days\", ylabel=\"Portion of population\") Subjectively this prior seems reasonable. It is perhaps too concentrated on relatively fast epidemics. I may alter it, but it\u2019s what I used for the current results.","title":"Priors"},{"location":"covid/#estimation","text":"We estimate the model by MCMC. Specifically, we use the Turing.jl package (Ge, Xu, and Ghahramani 2018 ) . For sampling, we use the No-U-Turn-Sampler variant of Hamiltonian Monte Carlo. In the results below we use 4 chains with 1000 warmup iterations, and 4000 iterations for the results.","title":"Estimation"},{"location":"covid/#results","text":"Canada Italy South Korea China United States","title":"Results"},{"location":"covid/#extensions","text":"Improve chain mixing. Estimate a multi-country model with some parameters common across countries and others multi-level distributions.","title":"Extensions"},{"location":"covid/#about-this-document","text":"This document was created using Weave.jl. The code is available in on github . Ge, Hong, Kai Xu, and Zoubin Ghahramani. 2018. \u201cTuring: A Language for Flexible Probabilistic Inference.\u201d In International Conference on Artificial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018, Playa Blanca, Lanzarote, Canary Islands, Spain , 1682\u201390. http://proceedings.mlr.press/v84/ge18b.html .","title":"About this document"},{"location":"functions/","text":"Function Reference \u00b6 # CovidSEIR.countrymodel \u2014 Function . countrymodel(data::CountryData, priors=defaultcountrypriors(), ::Type{R}=Float64) where {R <: Real} = begni Returns Turing model for single country source # CovidSEIR.covidjhudata \u2014 Method . covidjhudata() Downloads most recent JHU CSSE data on covid cases, deaths, and recoveries. Returns a DataFrame source # CovidSEIR.plotvars \u2014 Method . plotvars(simdf::DataFrames.AbstractDataFrame, data::CountryData; dayt0=Dates.Date(\"2020-01-21\"), # one day before JHU data begins colors=ColorSchemes.colorschemes[:Set1_9]) Create plots showing fit and implications of simulated trajectories. source # CovidSEIR.priorreport \u2014 Function . priorreport((priors=defaultcountrypriors(), T=100, population=1e7) Create tables and figures summarizing priors. source # CovidSEIR.simtrajectories \u2014 Method . simtrajectories(cc::AbstractMCMC.AbstractChains, data::CountryData, ts; ic=Iterators.product(StatsBase.sample(1:size(cc,1),300, replace=false), 1:size(cc,3))) Simulate trajectories based on parameter values in chain cc . source # CovidSEIR.odeSEIR \u2014 Method . odeSEIR() Sets up ODE for SEIR model with unconfirmed cases. Returns an ODEProblem source # CovidSEIR.paramvars \u2014 Method . Transfrom ODE parameters to/from vector source # CovidSEIR.paramvec \u2014 Method . Transfrom ODE parameters to/from vector source # CovidSEIR.systemvars \u2014 Method . Transfrom ODE variables to/from vector source # CovidSEIR.systemvec \u2014 Method . Transfrom ODE variables to/from vector source Index \u00b6 CovidSEIR.countrymodel CovidSEIR.covidjhudata CovidSEIR.odeSEIR CovidSEIR.paramvars CovidSEIR.paramvec CovidSEIR.plotvars CovidSEIR.priorreport CovidSEIR.simtrajectories CovidSEIR.systemvars CovidSEIR.systemvec","title":"Functions"},{"location":"functions/#function-reference","text":"# CovidSEIR.countrymodel \u2014 Function . countrymodel(data::CountryData, priors=defaultcountrypriors(), ::Type{R}=Float64) where {R <: Real} = begni Returns Turing model for single country source # CovidSEIR.covidjhudata \u2014 Method . covidjhudata() Downloads most recent JHU CSSE data on covid cases, deaths, and recoveries. Returns a DataFrame source # CovidSEIR.plotvars \u2014 Method . plotvars(simdf::DataFrames.AbstractDataFrame, data::CountryData; dayt0=Dates.Date(\"2020-01-21\"), # one day before JHU data begins colors=ColorSchemes.colorschemes[:Set1_9]) Create plots showing fit and implications of simulated trajectories. source # CovidSEIR.priorreport \u2014 Function . priorreport((priors=defaultcountrypriors(), T=100, population=1e7) Create tables and figures summarizing priors. source # CovidSEIR.simtrajectories \u2014 Method . simtrajectories(cc::AbstractMCMC.AbstractChains, data::CountryData, ts; ic=Iterators.product(StatsBase.sample(1:size(cc,1),300, replace=false), 1:size(cc,3))) Simulate trajectories based on parameter values in chain cc . source # CovidSEIR.odeSEIR \u2014 Method . odeSEIR() Sets up ODE for SEIR model with unconfirmed cases. Returns an ODEProblem source # CovidSEIR.paramvars \u2014 Method . Transfrom ODE parameters to/from vector source # CovidSEIR.paramvec \u2014 Method . Transfrom ODE parameters to/from vector source # CovidSEIR.systemvars \u2014 Method . Transfrom ODE variables to/from vector source # CovidSEIR.systemvec \u2014 Method . Transfrom ODE variables to/from vector source","title":"Function Reference"},{"location":"functions/#index","text":"CovidSEIR.countrymodel CovidSEIR.covidjhudata CovidSEIR.odeSEIR CovidSEIR.paramvars CovidSEIR.paramvec CovidSEIR.plotvars CovidSEIR.priorreport CovidSEIR.simtrajectories CovidSEIR.systemvars CovidSEIR.systemvec","title":"Index"},{"location":"italy/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License using CovidSEIR, Plots, DataFrames, JLD2, StatsPlots, MCMCChains Plots.pyplot() jmddir = normpath(joinpath(dirname(Base.find_package(\"CovidSEIR\")),\"..\",\"docs\",\"jmd\")) covdf = covidjhudata(); Italy \u00b6 italy = CountryData(covdf, \"Italy\"); itmod = CovidSEIR.TimeVarying.countrymodel(italy) cc = Turing.psample(itmod, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/italy_tv_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/italy_dhmc_2020-04-13.jld2\" cc; Error: SystemError: opening file \"/home/paul/.julia/dev/CovidSEIR/docs/jmd/ italy_dhmc_2020-04-13.jld2\": No such file or directory cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Error: UndefVarError: cc not defined Estimates \u00b6 plot(cc) Error: UndefVarError: cc not defined describe(cc) Error: UndefVarError: cc not defined Fit \u00b6 sdf = simtrajectories(cc, italy, 1:200) Error: UndefVarError: cc not defined f = plotvars(sdf, italy) Error: UndefVarError: sdf not defined f.fit Error: UndefVarError: f not defined As with Canada, the fit is very good, and the posterior distribution of observables is very precise. Implications \u00b6 for fig in f.trajectories display(fig) end Error: UndefVarError: f not defined","title":"Italy"},{"location":"italy/#italy","text":"italy = CountryData(covdf, \"Italy\"); itmod = CovidSEIR.TimeVarying.countrymodel(italy) cc = Turing.psample(itmod, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/italy_tv_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/italy_dhmc_2020-04-13.jld2\" cc; Error: SystemError: opening file \"/home/paul/.julia/dev/CovidSEIR/docs/jmd/ italy_dhmc_2020-04-13.jld2\": No such file or directory cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Error: UndefVarError: cc not defined","title":"Italy"},{"location":"italy/#estimates","text":"plot(cc) Error: UndefVarError: cc not defined describe(cc) Error: UndefVarError: cc not defined","title":"Estimates"},{"location":"italy/#fit","text":"sdf = simtrajectories(cc, italy, 1:200) Error: UndefVarError: cc not defined f = plotvars(sdf, italy) Error: UndefVarError: sdf not defined f.fit Error: UndefVarError: f not defined As with Canada, the fit is very good, and the posterior distribution of observables is very precise.","title":"Fit"},{"location":"italy/#implications","text":"for fig in f.trajectories display(fig) end Error: UndefVarError: f not defined","title":"Implications"},{"location":"korea/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License using CovidSEIR, Plots, DataFrames, JLD2, StatsPlots, MCMCChains Plots.pyplot() jmddir = normpath(joinpath(dirname(Base.find_package(\"CovidSEIR\")),\"..\",\"docs\",\"jmd\")) covdf = covidjhudata(); South Korea \u00b6 korea = CountryData(covdf, \"Korea, South\") CovidSEIR.CountryData{Float64,Int64}(5.1635256e7, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \u2026 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], [0.0, 0.0, 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0, 0.0 \u2026 192.0, 200.0, 204.0, 208.0, 211.0, 214.0, 217 .0, 222.0, 225.0, 229.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 \u2026 6694.0, 6776.0, 6973.0, 7117.0, 7243.0, 7368.0, 7447.0, 7534.0, 7616.0 , 7757.0], [1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 11.0 \u2026 3445.0, 3 408.0, 3246.0, 3125.0, 3026.0, 2930.0, 2873.0, 2808.0, 2750.0, 2627.0]) using Turing mdl = CovidSEIR.TimeVarying.countrymodel(korea) cc = Turing.psample(mdl, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/korea_tv_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/korea_dhmc_2020-04-13.jld2\" cc dayt0; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0146 0.0597 0.0004 0.0041 80.3213 1.3408 sigD 5.3642 2.4216 0.0171 0.1694 80.3213 5.0384 sigC 951.3287 978.9917 6.9225 69.0719 80.3213 2.2197 sigRc 845.4857 105.0627 0.7429 5.9862 80.3213 1.4793 a 0.5215 0.2690 0.0019 0.0176 80.3213 1.8935 pE0 0.0002 0.0005 0.0000 0.0000 80.3213 1.4380 p[1] 0.0316 0.0626 0.0004 0.0044 80.3213 2.4790 p[2] 0.0031 0.0089 0.0001 0.0006 80.3213 1.2621 \u03b2[1] 0.7778 0.8358 0.0059 0.0555 80.3213 1.4458 \u03b2[2] 0.6354 0.7074 0.0050 0.0398 80.3370 1.2070 \u03b2[3] 2.0175 1.3794 0.0098 0.0966 80.3213 3.3188 \u03b3[1] 1.5137 1.1407 0.0081 0.0801 80.3213 3.0029 \u03b3[2] 0.0515 0.0970 0.0007 0.0068 80.3213 1.3837 \u03c1[1] 0.5549 0.2274 0.0016 0.0136 80.3213 1.3732 \u03c1[2] 47.0605 11.1717 0.0790 0.7350 80.3213 1.2892 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.2457 sigD 2.4786 2.9594 5.5550 7.6868 8.8722 sigC 217.4268 265.3300 550.1108 1232.7812 4068.7156 sigRc 673.8938 765.5432 836.1810 916.0544 1064.8168 a 0.0746 0.3490 0.5506 0.7427 0.9411 pE0 0.0000 0.0000 0.0000 0.0000 0.0016 p[1] 0.0000 0.0001 0.0003 0.0240 0.2330 p[2] 0.0008 0.0008 0.0008 0.0009 0.0354 \u03b2[1] 0.0000 0.0026 0.5025 1.2954 2.8868 \u03b2[2] 0.0000 0.0583 0.3820 1.0063 2.4575 \u03b2[3] 0.0405 0.7791 1.7061 3.3934 4.2446 \u03b3[1] 0.0316 0.5668 1.1303 3.0000 3.0000 \u03b3[2] 0.0214 0.0264 0.0275 0.0286 0.4204 \u03c1[1] 0.1889 0.3367 0.5769 0.7514 0.9503 \u03c1[2] 28.7635 38.8180 46.5332 53.4753 75.3812 Estimates \u00b6 plot(cc) describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0146 0.0597 0.0004 0.0041 80.3213 1.3408 sigD 5.3642 2.4216 0.0171 0.1694 80.3213 5.0384 sigC 951.3287 978.9917 6.9225 69.0719 80.3213 2.2197 sigRc 845.4857 105.0627 0.7429 5.9862 80.3213 1.4793 a 0.5215 0.2690 0.0019 0.0176 80.3213 1.8935 pE0 0.0002 0.0005 0.0000 0.0000 80.3213 1.4380 p[1] 0.0316 0.0626 0.0004 0.0044 80.3213 2.4790 p[2] 0.0031 0.0089 0.0001 0.0006 80.3213 1.2621 \u03b2[1] 0.7778 0.8358 0.0059 0.0555 80.3213 1.4458 \u03b2[2] 0.6354 0.7074 0.0050 0.0398 80.3370 1.2070 \u03b2[3] 2.0175 1.3794 0.0098 0.0966 80.3213 3.3188 \u03b3[1] 1.5137 1.1407 0.0081 0.0801 80.3213 3.0029 \u03b3[2] 0.0515 0.0970 0.0007 0.0068 80.3213 1.3837 \u03c1[1] 0.5549 0.2274 0.0016 0.0136 80.3213 1.3732 \u03c1[2] 47.0605 11.1717 0.0790 0.7350 80.3213 1.2892 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.2457 sigD 2.4786 2.9594 5.5550 7.6868 8.8722 sigC 217.4268 265.3300 550.1108 1232.7812 4068.7156 sigRc 673.8938 765.5432 836.1810 916.0544 1064.8168 a 0.0746 0.3490 0.5506 0.7427 0.9411 pE0 0.0000 0.0000 0.0000 0.0000 0.0016 p[1] 0.0000 0.0001 0.0003 0.0240 0.2330 p[2] 0.0008 0.0008 0.0008 0.0009 0.0354 \u03b2[1] 0.0000 0.0026 0.5025 1.2954 2.8868 \u03b2[2] 0.0000 0.0583 0.3820 1.0063 2.4575 \u03b2[3] 0.0405 0.7791 1.7061 3.3934 4.2446 \u03b3[1] 0.0316 0.5668 1.1303 3.0000 3.0000 \u03b3[2] 0.0214 0.0264 0.0275 0.0286 0.4204 \u03c1[1] 0.1889 0.3367 0.5769 0.7514 0.9503 \u03c1[2] 28.7635 38.8180 46.5332 53.4753 75.3812 Fit \u00b6 sdf = simtrajectories(cc, korea, 1:150) f = plotvars(sdf, korea, dayt0=dayt0) plot!(f.fit, xlim=nothing) We see that the model does not fit the rapid drop in new cases in South Korea. This may be caused by the model\u2019s implausible assumption that transmission and testing rates are constant over time. Implications \u00b6 for fig in f.trajectories display(plot(fig, xlim=nothing)) end","title":"South Korea"},{"location":"korea/#south-korea","text":"korea = CountryData(covdf, \"Korea, South\") CovidSEIR.CountryData{Float64,Int64}(5.1635256e7, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \u2026 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], [0.0, 0.0, 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0, 0.0 \u2026 192.0, 200.0, 204.0, 208.0, 211.0, 214.0, 217 .0, 222.0, 225.0, 229.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 \u2026 6694.0, 6776.0, 6973.0, 7117.0, 7243.0, 7368.0, 7447.0, 7534.0, 7616.0 , 7757.0], [1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 11.0 \u2026 3445.0, 3 408.0, 3246.0, 3125.0, 3026.0, 2930.0, 2873.0, 2808.0, 2750.0, 2627.0]) using Turing mdl = CovidSEIR.TimeVarying.countrymodel(korea) cc = Turing.psample(mdl, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/korea_tv_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/korea_dhmc_2020-04-13.jld2\" cc dayt0; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0146 0.0597 0.0004 0.0041 80.3213 1.3408 sigD 5.3642 2.4216 0.0171 0.1694 80.3213 5.0384 sigC 951.3287 978.9917 6.9225 69.0719 80.3213 2.2197 sigRc 845.4857 105.0627 0.7429 5.9862 80.3213 1.4793 a 0.5215 0.2690 0.0019 0.0176 80.3213 1.8935 pE0 0.0002 0.0005 0.0000 0.0000 80.3213 1.4380 p[1] 0.0316 0.0626 0.0004 0.0044 80.3213 2.4790 p[2] 0.0031 0.0089 0.0001 0.0006 80.3213 1.2621 \u03b2[1] 0.7778 0.8358 0.0059 0.0555 80.3213 1.4458 \u03b2[2] 0.6354 0.7074 0.0050 0.0398 80.3370 1.2070 \u03b2[3] 2.0175 1.3794 0.0098 0.0966 80.3213 3.3188 \u03b3[1] 1.5137 1.1407 0.0081 0.0801 80.3213 3.0029 \u03b3[2] 0.0515 0.0970 0.0007 0.0068 80.3213 1.3837 \u03c1[1] 0.5549 0.2274 0.0016 0.0136 80.3213 1.3732 \u03c1[2] 47.0605 11.1717 0.0790 0.7350 80.3213 1.2892 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.2457 sigD 2.4786 2.9594 5.5550 7.6868 8.8722 sigC 217.4268 265.3300 550.1108 1232.7812 4068.7156 sigRc 673.8938 765.5432 836.1810 916.0544 1064.8168 a 0.0746 0.3490 0.5506 0.7427 0.9411 pE0 0.0000 0.0000 0.0000 0.0000 0.0016 p[1] 0.0000 0.0001 0.0003 0.0240 0.2330 p[2] 0.0008 0.0008 0.0008 0.0009 0.0354 \u03b2[1] 0.0000 0.0026 0.5025 1.2954 2.8868 \u03b2[2] 0.0000 0.0583 0.3820 1.0063 2.4575 \u03b2[3] 0.0405 0.7791 1.7061 3.3934 4.2446 \u03b3[1] 0.0316 0.5668 1.1303 3.0000 3.0000 \u03b3[2] 0.0214 0.0264 0.0275 0.0286 0.4204 \u03c1[1] 0.1889 0.3367 0.5769 0.7514 0.9503 \u03c1[2] 28.7635 38.8180 46.5332 53.4753 75.3812","title":"South Korea"},{"location":"korea/#estimates","text":"plot(cc) describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0146 0.0597 0.0004 0.0041 80.3213 1.3408 sigD 5.3642 2.4216 0.0171 0.1694 80.3213 5.0384 sigC 951.3287 978.9917 6.9225 69.0719 80.3213 2.2197 sigRc 845.4857 105.0627 0.7429 5.9862 80.3213 1.4793 a 0.5215 0.2690 0.0019 0.0176 80.3213 1.8935 pE0 0.0002 0.0005 0.0000 0.0000 80.3213 1.4380 p[1] 0.0316 0.0626 0.0004 0.0044 80.3213 2.4790 p[2] 0.0031 0.0089 0.0001 0.0006 80.3213 1.2621 \u03b2[1] 0.7778 0.8358 0.0059 0.0555 80.3213 1.4458 \u03b2[2] 0.6354 0.7074 0.0050 0.0398 80.3370 1.2070 \u03b2[3] 2.0175 1.3794 0.0098 0.0966 80.3213 3.3188 \u03b3[1] 1.5137 1.1407 0.0081 0.0801 80.3213 3.0029 \u03b3[2] 0.0515 0.0970 0.0007 0.0068 80.3213 1.3837 \u03c1[1] 0.5549 0.2274 0.0016 0.0136 80.3213 1.3732 \u03c1[2] 47.0605 11.1717 0.0790 0.7350 80.3213 1.2892 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.2457 sigD 2.4786 2.9594 5.5550 7.6868 8.8722 sigC 217.4268 265.3300 550.1108 1232.7812 4068.7156 sigRc 673.8938 765.5432 836.1810 916.0544 1064.8168 a 0.0746 0.3490 0.5506 0.7427 0.9411 pE0 0.0000 0.0000 0.0000 0.0000 0.0016 p[1] 0.0000 0.0001 0.0003 0.0240 0.2330 p[2] 0.0008 0.0008 0.0008 0.0009 0.0354 \u03b2[1] 0.0000 0.0026 0.5025 1.2954 2.8868 \u03b2[2] 0.0000 0.0583 0.3820 1.0063 2.4575 \u03b2[3] 0.0405 0.7791 1.7061 3.3934 4.2446 \u03b3[1] 0.0316 0.5668 1.1303 3.0000 3.0000 \u03b3[2] 0.0214 0.0264 0.0275 0.0286 0.4204 \u03c1[1] 0.1889 0.3367 0.5769 0.7514 0.9503 \u03c1[2] 28.7635 38.8180 46.5332 53.4753 75.3812","title":"Estimates"},{"location":"korea/#fit","text":"sdf = simtrajectories(cc, korea, 1:150) f = plotvars(sdf, korea, dayt0=dayt0) plot!(f.fit, xlim=nothing) We see that the model does not fit the rapid drop in new cases in South Korea. This may be caused by the model\u2019s implausible assumption that transmission and testing rates are constant over time.","title":"Fit"},{"location":"korea/#implications","text":"for fig in f.trajectories display(plot(fig, xlim=nothing)) end","title":"Implications"},{"location":"license/","text":"The model and results are licensed under a Creative Commons Attribution-ShareAlike 4.0 International License and were written by Paul Schrimpf. BibTeX citation. The license for the package source code is here.","title":"License"},{"location":"state/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License In this section we estimate a SEIR model using data from US States. Compared to the model in the introductory section , the state model introduces some additional components to incorporate additional data. Data \u00b6 The data combines information on Daily case counts and deaths from JHU CSSE Daily Hospitalizations, recoveries, and testing from the Covid Tracking Project Covid related policy changes from Raifman et al Movements from Google Mobility Reports Hourly workers from Hoembase Model \u00b6 For each each the epidemic is modeled as: \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\left(\\beta_1(t) I_1 + \\beta_2(t) C_1 + \\beta_3(t) C_3\\right) \\\\ \\dot{E} & = \\frac{S}{N} \\left(\\beta_1(t) I_1 + \\beta_2(t) C_1 + \\beta_3(t) C_3\\right) - a E \\\\ \\dot{I_1} & = a E - \\gamma_1 I_1 - p_1 I_1 - \\tau C_1 \\\\ \\dot{C_1} & = \\tau I - \\gamma_1 C_1 - p_1 C_1 \\\\ \\dot{C_2} & = p_1(I_1 + C_1) - \\gamma_2 C_2 - p_2 C_2 \\\\ \\dot{R_u} & = \\sum_i \\gamma_i I_i \\\\ \\dot{R_c} & = \\sum_i \\gamma_i C_i \\\\ \\dot{CC} & = (\\tau + p_1)I_1 \\\\ \\dot{X} & = p_2 C_2 \\end{align*} where variables are defined as in the introduction , except $CC$, which is new. $CC$ is cumulative confirmed cases. Our data does not contain recoveries for all states, so it is not possible to calculate active cases. Our data does contain cumulative confirmed cases for every state. Heterogeneity \u00b6 Some parameters are heterogenous across states and/or time. Specifically, we assume that for state $s$, \\beta_{j,s}(t) = \\beta_{j,0} \\exp( x_{s,t} \\alpha + \\epsilon_{\\beta,s}) where $x_{s,t}$ are observables that shift infection rates. In the estimates below, $x_{s,t}$ will be indicators for whether a state of emergency, stay-at-home order, or other related policy is in place, and measures of movement and business operations. 1 $\\epsilon_{\\beta,s}$ is an unobserved error term with mean $0$. Each of the components of $x$ are $0$ in a baseline, pre-epidemic world. Hence $\\beta_{j,0}$ is the (median across states) infection rate absent any policy or behavioral response. The model imposes that $\\beta_{j}(t)/\\beta_{k}(t)$ are constant across states and time. I have no opinion on whether this is a good assumption. Additionally, testing rates, $\\tau_s$, and the portion of people exposed at time $0$, $p_{0,s}$ vary with state. Analogous, to the way $\\beta$ is parameterized, we assume \\tau_{s} = \\tau e^{\\epsilon_{\\tau,s}} and p_{0,s} = p_0 e^{\\epsilon_{p,s}}. Finally, we assume that $a$, $p_1$, $p_2$, $\\gamma_1$, and $\\gamma_2$ are common across states and time. Arguably these could vary with state demographics (e.g. older populations have lower recovery and higher death rates), and over time with strain on the medical system. We abstract from these concerns for now. Least Squares estimates \u00b6 It is much faster to compute least squares point estimates than a full Bayesian posterior. Although the statistical properties of these estimates are unclear, they give some idea of how well the model can fit the data, and serve as good initial values for computing Bayesian posteriors. Let $\\theta = (a, p, \\gamma, \\tau, \\beta, \\alpha, \\epsilon)$ denote the parameters. We simply minimize \\begin{align*} Q(\\theta) = \\sum_{s, t} & (dead_{s,t} - X_s(t))^2 + (cases_{s,t} - CC_{s}(t))^2 + \\\\ & (hospitalized_{s,t} - C_{2,s}(t))^2 + (recovered_{s,t} - R_{c,s}(t)^2) \\end{align*} where $words$ are variables in the data, and capital letters are computed from the model (and implicitly depend on $\\theta$). Hospitalizations and recoveries are not observed for all states and days, in which case those terms are simply omitted from the objective function. Given the equal weights to all observables, the objective function will be dominated by the cumulative cases terms. Particularly in the states and days where it is large. Estimation \u00b6 using CovidSEIR, Plots, VegaLite, PrettyTables, DataFrames, JLD2 Plots.pyplot() df = CovidSEIR.statedata() ode = CovidSEIR.MultiRegion.odeSEIR() dat = CovidSEIR.RegionsData(df[df[!,:fips].<60,:], idvar=:fips ); out = CovidSEIR.LeastSquares.leastsquares(dat, ode) params = out.params @save \"jmd/states_$(Dates.today()).jld2\" params f Results \u00b6 Parameters \u00b6 @load \"jmd/states_2020-04-19.jld2\" params parms = DataFrame() for k in keys(params) if length(params[k])==1 global parms = vcat(parms, DataFrame(Parameter=string(k), Estimate=params[k])) elseif k == :\u03b1 \u03b1names = [\"Emergency\",\"K12 closed\",\"Stay at home\",\"Restaurants closed\",\"Non-essential businesses closed\", \"%/100 reduction workplaces\",\"%/100 reduction grocery\",\"%/100 reduction retail\", \"%/100 reduction hourly businesses open\"] global parms = vcat(parms, DataFrame(Parameter=string(k).*\u03b1names, Estimate=params[k])) else L = length(params[k]) global parms = vcat(parms, DataFrame(Parameter=string(k).*string.(1:L), Estimate=params[k])) end end pretty_table(parms[1:19,:], formatters=ft_printf(\"%5.3g\")) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Parameter \u2502 Estimate \u2502 \u2502 String \u2502 Float64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u03b21 \u2502 0.000354 \u2502 \u2502 \u03b22 \u2502 0.077 \u2502 \u2502 \u03b23 \u2502 1.04 \u2502 \u2502 \u03b31 \u2502 0.0451 \u2502 \u2502 \u03b32 \u2502 0.019 \u2502 \u2502 p1 \u2502 1e-08 \u2502 \u2502 p2 \u2502 0.0379 \u2502 \u2502 \u03c4 \u2502 2.21 \u2502 \u2502 a \u2502 0.0356 \u2502 \u2502 pE0 \u2502 6.14e-06 \u2502 \u2502 \u03b1Emergency \u2502 -0.098 \u2502 \u2502 \u03b1K12 closed \u2502 -3.13 \u2502 \u2502 \u03b1Stay at home \u2502 -0.836 \u2502 \u2502 \u03b1Restaurants closed \u2502 -2.33 \u2502 \u2502 \u03b1Non-essential businesses closed \u2502 -3.63 \u2502 \u2502 \u03b1%/100 reduction workplaces \u2502 -0.00287 \u2502 \u2502 \u03b1%/100 reduction grocery \u2502 -0.899 \u2502 \u2502 \u03b1%/100 reduction retail \u2502 -0.000107 \u2502 \u2502 \u03b1%/100 reduction hourly businesses open \u2502 -4.99 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The parameter estimates have some apparent problems. The estimate of $a$ is much smaller than expected. $1/a$ should be the period of time from infection to becoming contagious. This is generally believed to be around 5 days. $\\beta_{1,0}$ being the smallest means that undetected infectious people are less likely to infect others compared to confirmed mildr or severe cases. The value of $\\tau$ is very high. To avoid numeric difficulties in optimization, I restricted $-5 \\leq \\alpha \\leq 0$. These constraints sometimes bind. For the policy variables, it is strange that the coefficient on stay at home is not the largest. The magnitude of these are quite larege. For example, closing non-essential businesses reduces infection rate to $e^{-3.63} \\approx 0.026$ of what it is was. The combination of all policies cuts infection rates to about 1/20,000th of baseline. display(histogram(params.e\u03b2, label=\"\u03f5_\u03b2\")) display(histogram(params.e\u03c4, label=\"\u03f5_\u03c4\")) display(histogram(params.ep, label=\"\u03f5_p\")) Fit \u00b6 using TransformVariables trans = as( (\u03b2=as(Array, as\u211d, 3), \u03b3=as(Array, as\u211d, 2), p=as(Array, as\u211d, 2), \u03c4=as\u211d, a=as\u211d, pE0=as\u211d, \u03b1=as(Array, as\u211d, size(dat.X,1)), e\u03b2=as(Array, as\u211d, length(dat.population)-1), e\u03c4=as(Array, as\u211d, length(dat.population)-1), ep=as(Array, as\u211d, length(dat.population)-1)) ) f = CovidSEIR.LeastSquares.plotfits(dat, ode, inverse(trans, params), trans) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) for fig in f.figs display(fig) end Including movement and business operations in $x$ makes interpretation difficult. If we want to estimate policy effects, we should be using these auxillary measures in some other way. We should not be holding them constant or conditioning on them. \u21a9","title":"US States"},{"location":"state/#data","text":"The data combines information on Daily case counts and deaths from JHU CSSE Daily Hospitalizations, recoveries, and testing from the Covid Tracking Project Covid related policy changes from Raifman et al Movements from Google Mobility Reports Hourly workers from Hoembase","title":"Data"},{"location":"state/#model","text":"For each each the epidemic is modeled as: \\begin{align*} \\dot{S} & = -\\frac{S}{N} \\left(\\beta_1(t) I_1 + \\beta_2(t) C_1 + \\beta_3(t) C_3\\right) \\\\ \\dot{E} & = \\frac{S}{N} \\left(\\beta_1(t) I_1 + \\beta_2(t) C_1 + \\beta_3(t) C_3\\right) - a E \\\\ \\dot{I_1} & = a E - \\gamma_1 I_1 - p_1 I_1 - \\tau C_1 \\\\ \\dot{C_1} & = \\tau I - \\gamma_1 C_1 - p_1 C_1 \\\\ \\dot{C_2} & = p_1(I_1 + C_1) - \\gamma_2 C_2 - p_2 C_2 \\\\ \\dot{R_u} & = \\sum_i \\gamma_i I_i \\\\ \\dot{R_c} & = \\sum_i \\gamma_i C_i \\\\ \\dot{CC} & = (\\tau + p_1)I_1 \\\\ \\dot{X} & = p_2 C_2 \\end{align*} where variables are defined as in the introduction , except $CC$, which is new. $CC$ is cumulative confirmed cases. Our data does not contain recoveries for all states, so it is not possible to calculate active cases. Our data does contain cumulative confirmed cases for every state.","title":"Model"},{"location":"state/#heterogeneity","text":"Some parameters are heterogenous across states and/or time. Specifically, we assume that for state $s$, \\beta_{j,s}(t) = \\beta_{j,0} \\exp( x_{s,t} \\alpha + \\epsilon_{\\beta,s}) where $x_{s,t}$ are observables that shift infection rates. In the estimates below, $x_{s,t}$ will be indicators for whether a state of emergency, stay-at-home order, or other related policy is in place, and measures of movement and business operations. 1 $\\epsilon_{\\beta,s}$ is an unobserved error term with mean $0$. Each of the components of $x$ are $0$ in a baseline, pre-epidemic world. Hence $\\beta_{j,0}$ is the (median across states) infection rate absent any policy or behavioral response. The model imposes that $\\beta_{j}(t)/\\beta_{k}(t)$ are constant across states and time. I have no opinion on whether this is a good assumption. Additionally, testing rates, $\\tau_s$, and the portion of people exposed at time $0$, $p_{0,s}$ vary with state. Analogous, to the way $\\beta$ is parameterized, we assume \\tau_{s} = \\tau e^{\\epsilon_{\\tau,s}} and p_{0,s} = p_0 e^{\\epsilon_{p,s}}. Finally, we assume that $a$, $p_1$, $p_2$, $\\gamma_1$, and $\\gamma_2$ are common across states and time. Arguably these could vary with state demographics (e.g. older populations have lower recovery and higher death rates), and over time with strain on the medical system. We abstract from these concerns for now.","title":"Heterogeneity"},{"location":"state/#least-squares-estimates","text":"It is much faster to compute least squares point estimates than a full Bayesian posterior. Although the statistical properties of these estimates are unclear, they give some idea of how well the model can fit the data, and serve as good initial values for computing Bayesian posteriors. Let $\\theta = (a, p, \\gamma, \\tau, \\beta, \\alpha, \\epsilon)$ denote the parameters. We simply minimize \\begin{align*} Q(\\theta) = \\sum_{s, t} & (dead_{s,t} - X_s(t))^2 + (cases_{s,t} - CC_{s}(t))^2 + \\\\ & (hospitalized_{s,t} - C_{2,s}(t))^2 + (recovered_{s,t} - R_{c,s}(t)^2) \\end{align*} where $words$ are variables in the data, and capital letters are computed from the model (and implicitly depend on $\\theta$). Hospitalizations and recoveries are not observed for all states and days, in which case those terms are simply omitted from the objective function. Given the equal weights to all observables, the objective function will be dominated by the cumulative cases terms. Particularly in the states and days where it is large.","title":"Least Squares estimates"},{"location":"state/#estimation","text":"using CovidSEIR, Plots, VegaLite, PrettyTables, DataFrames, JLD2 Plots.pyplot() df = CovidSEIR.statedata() ode = CovidSEIR.MultiRegion.odeSEIR() dat = CovidSEIR.RegionsData(df[df[!,:fips].<60,:], idvar=:fips ); out = CovidSEIR.LeastSquares.leastsquares(dat, ode) params = out.params @save \"jmd/states_$(Dates.today()).jld2\" params f","title":"Estimation"},{"location":"state/#results","text":"","title":"Results"},{"location":"state/#parameters","text":"@load \"jmd/states_2020-04-19.jld2\" params parms = DataFrame() for k in keys(params) if length(params[k])==1 global parms = vcat(parms, DataFrame(Parameter=string(k), Estimate=params[k])) elseif k == :\u03b1 \u03b1names = [\"Emergency\",\"K12 closed\",\"Stay at home\",\"Restaurants closed\",\"Non-essential businesses closed\", \"%/100 reduction workplaces\",\"%/100 reduction grocery\",\"%/100 reduction retail\", \"%/100 reduction hourly businesses open\"] global parms = vcat(parms, DataFrame(Parameter=string(k).*\u03b1names, Estimate=params[k])) else L = length(params[k]) global parms = vcat(parms, DataFrame(Parameter=string(k).*string.(1:L), Estimate=params[k])) end end pretty_table(parms[1:19,:], formatters=ft_printf(\"%5.3g\")) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Parameter \u2502 Estimate \u2502 \u2502 String \u2502 Float64 \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 \u03b21 \u2502 0.000354 \u2502 \u2502 \u03b22 \u2502 0.077 \u2502 \u2502 \u03b23 \u2502 1.04 \u2502 \u2502 \u03b31 \u2502 0.0451 \u2502 \u2502 \u03b32 \u2502 0.019 \u2502 \u2502 p1 \u2502 1e-08 \u2502 \u2502 p2 \u2502 0.0379 \u2502 \u2502 \u03c4 \u2502 2.21 \u2502 \u2502 a \u2502 0.0356 \u2502 \u2502 pE0 \u2502 6.14e-06 \u2502 \u2502 \u03b1Emergency \u2502 -0.098 \u2502 \u2502 \u03b1K12 closed \u2502 -3.13 \u2502 \u2502 \u03b1Stay at home \u2502 -0.836 \u2502 \u2502 \u03b1Restaurants closed \u2502 -2.33 \u2502 \u2502 \u03b1Non-essential businesses closed \u2502 -3.63 \u2502 \u2502 \u03b1%/100 reduction workplaces \u2502 -0.00287 \u2502 \u2502 \u03b1%/100 reduction grocery \u2502 -0.899 \u2502 \u2502 \u03b1%/100 reduction retail \u2502 -0.000107 \u2502 \u2502 \u03b1%/100 reduction hourly businesses open \u2502 -4.99 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The parameter estimates have some apparent problems. The estimate of $a$ is much smaller than expected. $1/a$ should be the period of time from infection to becoming contagious. This is generally believed to be around 5 days. $\\beta_{1,0}$ being the smallest means that undetected infectious people are less likely to infect others compared to confirmed mildr or severe cases. The value of $\\tau$ is very high. To avoid numeric difficulties in optimization, I restricted $-5 \\leq \\alpha \\leq 0$. These constraints sometimes bind. For the policy variables, it is strange that the coefficient on stay at home is not the largest. The magnitude of these are quite larege. For example, closing non-essential businesses reduces infection rate to $e^{-3.63} \\approx 0.026$ of what it is was. The combination of all policies cuts infection rates to about 1/20,000th of baseline. display(histogram(params.e\u03b2, label=\"\u03f5_\u03b2\")) display(histogram(params.e\u03c4, label=\"\u03f5_\u03c4\")) display(histogram(params.ep, label=\"\u03f5_p\"))","title":"Parameters"},{"location":"state/#fit","text":"using TransformVariables trans = as( (\u03b2=as(Array, as\u211d, 3), \u03b3=as(Array, as\u211d, 2), p=as(Array, as\u211d, 2), \u03c4=as\u211d, a=as\u211d, pE0=as\u211d, \u03b1=as(Array, as\u211d, size(dat.X,1)), e\u03b2=as(Array, as\u211d, length(dat.population)-1), e\u03c4=as(Array, as\u211d, length(dat.population)-1), ep=as(Array, as\u211d, length(dat.population)-1)) ) f = CovidSEIR.LeastSquares.plotfits(dat, ode, inverse(trans, params), trans) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) (size(sol), size(tsave)) = ((9, 94), (94,)) for fig in f.figs display(fig) end Including movement and business operations in $x$ makes interpretation difficult. If we want to estimate policy effects, we should be using these auxillary measures in some other way. We should not be holding them constant or conditioning on them. \u21a9","title":"Fit"},{"location":"us/","text":"This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License using CovidSEIR, Plots, DataFrames, JLD2, StatsPlots, Dates, MCMCChains Plots.pyplot() jmddir = normpath(joinpath(dirname(Base.find_package(\"CovidSEIR\")),\"..\",\"docs\",\"jmd\")) covdf = covidjhudata(); United States \u00b6 us = CountryData(covdf, \"US\") CovidSEIR.CountryData{Float64,Int64}(3.2716743e8, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \u2026 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], [0.0, 0.0, 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0, 0.0 \u2026 12722.0, 14695.0, 16478.0, 18586.0, 20462.0, 22019.0, 23528.0, 25831.0, 28325.0, 32916.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0 \u2026 21763.0, 23559.0, 25410.0, 28790.0, 31270.0, 32988 .0, 43482.0, 47763.0, 52096.0, 54703.0], [1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 5.0 , 5.0, 5.0, 7.0 \u2026 361738.0, 390798.0, 419549.0, 449159.0, 474664.0, 50030 6.0, 513609.0, 534076.0, 555929.0, 580182.0]) using Turing mdl = CovidSEIR.TimeVarying.countrymodel(us) cc = Turing.psample(mdl, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/us_tv_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/us_dhmc_2020-04-13.jld2\" cc; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0001 0.0000 0.0000 0.0000 81.9924 1.2819 sigD 137.7127 8.0087 0.0566 0.3734 140.4813 1.0810 sigC 1334.2734 92.6313 0.6550 4.5797 97.6593 1.2625 sigRc 731.7612 43.2561 0.3059 2.2038 96.7621 1.2997 a 0.7609 0.1862 0.0013 0.0131 80.3213 3.9037 pE0 0.0000 0.0000 0.0000 0.0000 100.5049 1.1776 p[1] 0.0193 0.0021 0.0000 0.0001 80.3213 1.7318 p[2] 0.0045 0.0000 0.0000 0.0000 141.0271 1.0764 \u03b2[1] 0.8113 1.2418 0.0088 0.0876 80.3213 9.1362 \u03b2[2] 1.1373 0.6511 0.0046 0.0422 80.3213 1.5722 \u03b2[3] 3.9270 0.7566 0.0053 0.0529 80.3213 3.8765 \u03b3[1] 2.9379 0.1078 0.0008 0.0076 80.3213 7.4234 \u03b3[2] 0.0067 0.0003 0.0000 0.0000 80.3213 1.4663 \u03c1[1] 0.2486 0.0306 0.0002 0.0021 80.3213 2.2939 \u03c1[2] 61.2539 0.4053 0.0029 0.0241 80.3213 1.3951 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.0002 sigD 118.6077 135.2341 139.7070 141.1686 152.2954 sigC 1155.0157 1294.3130 1305.6873 1394.1663 1504.5102 sigRc 653.7688 701.9086 724.4422 762.5418 816.5018 a 0.3665 0.5791 0.7621 0.9520 0.9683 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0151 0.0178 0.0190 0.0216 0.0223 p[2] 0.0045 0.0045 0.0045 0.0045 0.0045 \u03b2[1] 0.0000 0.0000 0.1534 0.7802 3.2127 \u03b2[2] 0.0723 0.7875 1.1188 1.5326 2.6644 \u03b2[3] 2.4007 4.1450 4.1807 4.4108 4.7409 \u03b3[1] 2.7158 2.8516 3.0000 3.0000 3.0000 \u03b3[2] 0.0061 0.0064 0.0067 0.0070 0.0070 \u03c1[1] 0.2132 0.2236 0.2414 0.2667 0.3312 \u03c1[2] 60.5702 60.9084 61.1496 61.5801 62.0245 Estimates \u00b6 plot(cc) describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0001 0.0000 0.0000 0.0000 81.9924 1.2819 sigD 137.7127 8.0087 0.0566 0.3734 140.4813 1.0810 sigC 1334.2734 92.6313 0.6550 4.5797 97.6593 1.2625 sigRc 731.7612 43.2561 0.3059 2.2038 96.7621 1.2997 a 0.7609 0.1862 0.0013 0.0131 80.3213 3.9037 pE0 0.0000 0.0000 0.0000 0.0000 100.5049 1.1776 p[1] 0.0193 0.0021 0.0000 0.0001 80.3213 1.7318 p[2] 0.0045 0.0000 0.0000 0.0000 141.0271 1.0764 \u03b2[1] 0.8113 1.2418 0.0088 0.0876 80.3213 9.1362 \u03b2[2] 1.1373 0.6511 0.0046 0.0422 80.3213 1.5722 \u03b2[3] 3.9270 0.7566 0.0053 0.0529 80.3213 3.8765 \u03b3[1] 2.9379 0.1078 0.0008 0.0076 80.3213 7.4234 \u03b3[2] 0.0067 0.0003 0.0000 0.0000 80.3213 1.4663 \u03c1[1] 0.2486 0.0306 0.0002 0.0021 80.3213 2.2939 \u03c1[2] 61.2539 0.4053 0.0029 0.0241 80.3213 1.3951 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.0002 sigD 118.6077 135.2341 139.7070 141.1686 152.2954 sigC 1155.0157 1294.3130 1305.6873 1394.1663 1504.5102 sigRc 653.7688 701.9086 724.4422 762.5418 816.5018 a 0.3665 0.5791 0.7621 0.9520 0.9683 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0151 0.0178 0.0190 0.0216 0.0223 p[2] 0.0045 0.0045 0.0045 0.0045 0.0045 \u03b2[1] 0.0000 0.0000 0.1534 0.7802 3.2127 \u03b2[2] 0.0723 0.7875 1.1188 1.5326 2.6644 \u03b2[3] 2.4007 4.1450 4.1807 4.4108 4.7409 \u03b3[1] 2.7158 2.8516 3.0000 3.0000 3.0000 \u03b3[2] 0.0061 0.0064 0.0067 0.0070 0.0070 \u03c1[1] 0.2132 0.2236 0.2414 0.2667 0.3312 \u03c1[2] 60.5702 60.9084 61.1496 61.5801 62.0245 Fit \u00b6 sdf = simtrajectories(cc, us, 1:200) f = plotvars(sdf, us) plot(f.fit, ylim=(0, maximum(us.active)*1.3)) Implications \u00b6 for fig in f.trajectories display(plot(fig)) end","title":"United States"},{"location":"us/#united-states","text":"us = CountryData(covdf, \"US\") CovidSEIR.CountryData{Float64,Int64}(3.2716743e8, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 \u2026 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], [0.0, 0.0, 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0, 0.0 \u2026 12722.0, 14695.0, 16478.0, 18586.0, 20462.0, 22019.0, 23528.0, 25831.0, 28325.0, 32916.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0 \u2026 21763.0, 23559.0, 25410.0, 28790.0, 31270.0, 32988 .0, 43482.0, 47763.0, 52096.0, 54703.0], [1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 5.0 , 5.0, 5.0, 7.0 \u2026 361738.0, 390798.0, 419549.0, 449159.0, 474664.0, 50030 6.0, 513609.0, 534076.0, 555929.0, 580182.0]) using Turing mdl = CovidSEIR.TimeVarying.countrymodel(us) cc = Turing.psample(mdl, NUTS(0.65), 5000, 4) import JLD2 JLD2.@save \"$jmddir/us_tv_$(Dates.today()).jld2\" cc JLD2.@load \"$jmddir/us_dhmc_2020-04-13.jld2\" cc; cc = MCMCChains.Chains(collect(cc.value.data), replace.(cc.name_map.parameters, r\"([^\\[])([1-9])\" => s\"\\1[\\2]\")) Object of type Chains, with data of type 5000\u00d715\u00d74 Array{Float64,3} Iterations = 1:5000 Thinning interval = 1 Chains = 1, 2, 3, 4 Samples per chain = 5000 parameters = \u03c4, sigD, sigC, sigRc, a, pE0, p[1], p[2], \u03b2[1], \u03b2[2], \u03b2 [3], \u03b3[1], \u03b3[2], \u03c1[1], \u03c1[2] 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0001 0.0000 0.0000 0.0000 81.9924 1.2819 sigD 137.7127 8.0087 0.0566 0.3734 140.4813 1.0810 sigC 1334.2734 92.6313 0.6550 4.5797 97.6593 1.2625 sigRc 731.7612 43.2561 0.3059 2.2038 96.7621 1.2997 a 0.7609 0.1862 0.0013 0.0131 80.3213 3.9037 pE0 0.0000 0.0000 0.0000 0.0000 100.5049 1.1776 p[1] 0.0193 0.0021 0.0000 0.0001 80.3213 1.7318 p[2] 0.0045 0.0000 0.0000 0.0000 141.0271 1.0764 \u03b2[1] 0.8113 1.2418 0.0088 0.0876 80.3213 9.1362 \u03b2[2] 1.1373 0.6511 0.0046 0.0422 80.3213 1.5722 \u03b2[3] 3.9270 0.7566 0.0053 0.0529 80.3213 3.8765 \u03b3[1] 2.9379 0.1078 0.0008 0.0076 80.3213 7.4234 \u03b3[2] 0.0067 0.0003 0.0000 0.0000 80.3213 1.4663 \u03c1[1] 0.2486 0.0306 0.0002 0.0021 80.3213 2.2939 \u03c1[2] 61.2539 0.4053 0.0029 0.0241 80.3213 1.3951 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.0002 sigD 118.6077 135.2341 139.7070 141.1686 152.2954 sigC 1155.0157 1294.3130 1305.6873 1394.1663 1504.5102 sigRc 653.7688 701.9086 724.4422 762.5418 816.5018 a 0.3665 0.5791 0.7621 0.9520 0.9683 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0151 0.0178 0.0190 0.0216 0.0223 p[2] 0.0045 0.0045 0.0045 0.0045 0.0045 \u03b2[1] 0.0000 0.0000 0.1534 0.7802 3.2127 \u03b2[2] 0.0723 0.7875 1.1188 1.5326 2.6644 \u03b2[3] 2.4007 4.1450 4.1807 4.4108 4.7409 \u03b3[1] 2.7158 2.8516 3.0000 3.0000 3.0000 \u03b3[2] 0.0061 0.0064 0.0067 0.0070 0.0070 \u03c1[1] 0.2132 0.2236 0.2414 0.2667 0.3312 \u03c1[2] 60.5702 60.9084 61.1496 61.5801 62.0245","title":"United States"},{"location":"us/#estimates","text":"plot(cc) describe(cc) 2-element Array{MCMCChains.ChainDataFrame,1} Summary Statistics parameters mean std naive_se mcse ess r_hat \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0001 0.0000 0.0000 0.0000 81.9924 1.2819 sigD 137.7127 8.0087 0.0566 0.3734 140.4813 1.0810 sigC 1334.2734 92.6313 0.6550 4.5797 97.6593 1.2625 sigRc 731.7612 43.2561 0.3059 2.2038 96.7621 1.2997 a 0.7609 0.1862 0.0013 0.0131 80.3213 3.9037 pE0 0.0000 0.0000 0.0000 0.0000 100.5049 1.1776 p[1] 0.0193 0.0021 0.0000 0.0001 80.3213 1.7318 p[2] 0.0045 0.0000 0.0000 0.0000 141.0271 1.0764 \u03b2[1] 0.8113 1.2418 0.0088 0.0876 80.3213 9.1362 \u03b2[2] 1.1373 0.6511 0.0046 0.0422 80.3213 1.5722 \u03b2[3] 3.9270 0.7566 0.0053 0.0529 80.3213 3.8765 \u03b3[1] 2.9379 0.1078 0.0008 0.0076 80.3213 7.4234 \u03b3[2] 0.0067 0.0003 0.0000 0.0000 80.3213 1.4663 \u03c1[1] 0.2486 0.0306 0.0002 0.0021 80.3213 2.2939 \u03c1[2] 61.2539 0.4053 0.0029 0.0241 80.3213 1.3951 Quantiles parameters 2.5% 25.0% 50.0% 75.0% 97.5% \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u03c4 0.0000 0.0000 0.0000 0.0001 0.0002 sigD 118.6077 135.2341 139.7070 141.1686 152.2954 sigC 1155.0157 1294.3130 1305.6873 1394.1663 1504.5102 sigRc 653.7688 701.9086 724.4422 762.5418 816.5018 a 0.3665 0.5791 0.7621 0.9520 0.9683 pE0 0.0000 0.0000 0.0000 0.0000 0.0000 p[1] 0.0151 0.0178 0.0190 0.0216 0.0223 p[2] 0.0045 0.0045 0.0045 0.0045 0.0045 \u03b2[1] 0.0000 0.0000 0.1534 0.7802 3.2127 \u03b2[2] 0.0723 0.7875 1.1188 1.5326 2.6644 \u03b2[3] 2.4007 4.1450 4.1807 4.4108 4.7409 \u03b3[1] 2.7158 2.8516 3.0000 3.0000 3.0000 \u03b3[2] 0.0061 0.0064 0.0067 0.0070 0.0070 \u03c1[1] 0.2132 0.2236 0.2414 0.2667 0.3312 \u03c1[2] 60.5702 60.9084 61.1496 61.5801 62.0245","title":"Estimates"},{"location":"us/#fit","text":"sdf = simtrajectories(cc, us, 1:200) f = plotvars(sdf, us) plot(f.fit, ylim=(0, maximum(us.active)*1.3))","title":"Fit"},{"location":"us/#implications","text":"for fig in f.trajectories display(plot(fig)) end","title":"Implications"}]}